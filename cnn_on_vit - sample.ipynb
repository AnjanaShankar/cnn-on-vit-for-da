{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 11282076,
          "sourceType": "datasetVersion",
          "datasetId": 7053693
        },
        {
          "sourceId": 11439462,
          "sourceType": "datasetVersion",
          "datasetId": 7062843
        },
        {
          "sourceId": 11479262,
          "sourceType": "datasetVersion",
          "datasetId": 7194705
        },
        {
          "sourceId": 11483523,
          "sourceType": "datasetVersion",
          "datasetId": 7073539
        },
        {
          "sourceId": 11625968,
          "sourceType": "datasetVersion",
          "datasetId": 7053892
        },
        {
          "sourceId": 11636953,
          "sourceType": "datasetVersion",
          "datasetId": 7063998
        },
        {
          "sourceId": 11637018,
          "sourceType": "datasetVersion",
          "datasetId": 7058850
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Environment Preparation**"
      ],
      "metadata": {
        "id": "Zeq8tNLCqHd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\n",
        "!bash miniconda.sh -b -p /opt/conda\n",
        "!rm miniconda.sh"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-01T07:22:34.420293Z",
          "iopub.status.busy": "2025-05-01T07:22:34.419965Z",
          "iopub.status.idle": "2025-05-01T07:22:47.863856Z",
          "shell.execute_reply": "2025-05-01T07:22:47.862750Z",
          "shell.execute_reply.started": "2025-05-01T07:22:34.420270Z"
        },
        "id": "bVNTOUJFBC0u",
        "trusted": true,
        "outputId": "461a78b6-d934-4ccd-d77c-561fe60cfb7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-05-01 07:22:34--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.191.158, 104.16.32.241, 2606:4700::6810:bf9e, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.191.158|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 155472915 (148M) [application/octet-stream]\n",
            "Saving to: ‘miniconda.sh’\n",
            "\n",
            "miniconda.sh        100%[===================>] 148.27M   238MB/s    in 0.6s    \n",
            "\n",
            "2025-05-01 07:22:35 (238 MB/s) - ‘miniconda.sh’ saved [155472915/155472915]\n",
            "\n",
            "PREFIX=/opt/conda\n",
            "Unpacking payload ...\n",
            "entry_point.py:256: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "entry_point.py:256: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "\n",
            "Installing base environment...\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "entry_point.py:256: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /opt/conda\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PATH'] = \"/opt/conda/bin:\" + os.environ['PATH']\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-01T07:22:47.865626Z",
          "iopub.status.busy": "2025-05-01T07:22:47.865256Z",
          "iopub.status.idle": "2025-05-01T07:22:47.869520Z",
          "shell.execute_reply": "2025-05-01T07:22:47.868766Z",
          "shell.execute_reply.started": "2025-05-01T07:22:47.865592Z"
        },
        "id": "H-3hnMtaBHat",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!conda --version"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-01T07:22:47.871158Z",
          "iopub.status.busy": "2025-05-01T07:22:47.870946Z",
          "iopub.status.idle": "2025-05-01T07:22:49.758226Z",
          "shell.execute_reply": "2025-05-01T07:22:49.757361Z",
          "shell.execute_reply.started": "2025-05-01T07:22:47.871139Z"
        },
        "id": "54Ug-gBFA-Gn",
        "outputId": "81e975a1-3421-470d-f614-11ac3091d8e3",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "conda 25.3.1\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/dotrannhattuong/ECB.git"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-01T07:22:49.760245Z",
          "iopub.status.busy": "2025-05-01T07:22:49.759916Z",
          "iopub.status.idle": "2025-05-01T07:22:51.834377Z",
          "shell.execute_reply": "2025-05-01T07:22:51.833577Z",
          "shell.execute_reply.started": "2025-05-01T07:22:49.760210Z"
        },
        "id": "M4Q4yXGB7XKz",
        "outputId": "7d2e8fc7-88e4-4a35-e783-9b49253d9b12",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'ECB'...\n",
            "remote: Enumerating objects: 377, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 377 (delta 23), reused 20 (delta 20), pack-reused 347 (from 1)\u001b[K\n",
            "Receiving objects: 100% (377/377), 32.35 MiB | 36.56 MiB/s, done.\n",
            "Resolving deltas: 100% (161/161), done.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ECB/"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-01T07:22:51.835562Z",
          "iopub.status.busy": "2025-05-01T07:22:51.835308Z",
          "iopub.status.idle": "2025-05-01T07:22:51.841932Z",
          "shell.execute_reply": "2025-05-01T07:22:51.841199Z",
          "shell.execute_reply.started": "2025-05-01T07:22:51.835538Z"
        },
        "id": "kCoUkwM07dxP",
        "outputId": "ac10c22c-397e-4c0e-9b9e-e6d21d04c3ba",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/kaggle/working/ECB\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-01T07:22:51.842838Z",
          "iopub.status.busy": "2025-05-01T07:22:51.842641Z",
          "iopub.status.idle": "2025-05-01T07:22:51.969128Z",
          "shell.execute_reply": "2025-05-01T07:22:51.968290Z",
          "shell.execute_reply.started": "2025-05-01T07:22:51.842820Z"
        },
        "id": "pnhBVeRFKIhq",
        "outputId": "855c0988-ab8a-415c-ebd3-4174a5de506f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/kaggle/working/ECB\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la | grep environment.yml\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-01T07:22:51.970503Z",
          "iopub.status.busy": "2025-05-01T07:22:51.970171Z",
          "iopub.status.idle": "2025-05-01T07:22:52.092405Z",
          "shell.execute_reply": "2025-05-01T07:22:52.091644Z",
          "shell.execute_reply.started": "2025-05-01T07:22:51.970472Z"
        },
        "id": "PCVOiM0OKV5z",
        "outputId": "9c27e05f-040d-46a3-8c42-c64892e2c4a0",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rw-r--r--  1 root root    3989 May  1 07:22 environment.yml\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!conda env create -f environment.yml"
      ],
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-05-01T07:22:52.095027Z",
          "iopub.status.busy": "2025-05-01T07:22:52.094813Z",
          "iopub.status.idle": "2025-05-01T07:29:16.817086Z",
          "shell.execute_reply": "2025-05-01T07:29:16.815990Z",
          "shell.execute_reply.started": "2025-05-01T07:22:52.095008Z"
        },
        "id": "qYMDIvCrAb0S",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "de703021-4a31-4a52-de79-933cefe9aec2",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Channels:\n",
            " - pytorch\n",
            " - nvidia\n",
            " - defaults\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): done\n",
            "Solving environment: done\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "pytorch-2.0.0        | 1.41 GB   |                                       |   0% \n",
            "libcublas-11.11.3.6  | 364.0 MB  |                                       |   0% \u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  |                                       |   0% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.0.0    | 62.5 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.3.141 | 51.6 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.18        | 25.1 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "intel-openmp-2023.1. | 17.1 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sympy-1.13.3         | 11.2 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-4.3           | 9.9 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchaudio-2.0.0     | 7.5 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-base-1.25.2    | 7.1 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.0.10       | 5.2 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tk-8.6.12            | 3.0 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "networkx-3.1         | 2.7 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pip-23.2.1           | 2.6 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnvjpeg-11.9.0.86  | 2.4 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cryptography-41.0.3  | 2.0 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  |                                       |   0% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | 1                                     |   0% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  |                                       |   0% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | 2                                     |   1% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | 8                                     |   2% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | 7                                     |   2% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | 5                                     |   2% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | #5                                    |   4% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | #3                                    |   4% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | 1                                     |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | 8                                     |   2% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ##2                                   |   6% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ##                                    |   5% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | 2                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | #1                                    |   3% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ##8                                   |   8% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ##6                                   |   7% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | 2                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | #4                                    |   4% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ###4                                  |   9% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ###3                                  |   9% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | 3                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | #7                                    |   5% \u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ###9                                  |  11% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ####                                  |  11% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | 4                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | ##                                    |   6% \u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ####5                                 |  12% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ####7                                 |  13% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | 5                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | ##3                                   |   6% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | #####3                                |  15% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | #####2                                |  14% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | 6                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | ##6                                   |   7% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ######                                |  16% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | #####8                                |  16% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | 6                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | ##9                                   |   8% \u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ######4                               |  18% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ######6                               |  18% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | 7                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | ###2                                  |   9% \u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | #######1                              |  19% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | #######3                              |  20% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | 8                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | ###5                                  |  10% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | #######9                              |  22% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | #########                             |  24% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | 9                                     |   2% \u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | ###8                                  |  11% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ########6                             |  23% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | #########7                            |  26% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #                                     |   3% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | #########2                            |  25% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | ##########5                           |  28% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | ####1                                 |  11% \u001b[A\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #                                     |   3% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | #########9                            |  27% \u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | ####5                                 |  12% \u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | #########6                            |  26% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #1                                    |   3% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ##########5                           |  29% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ##########2                           |  28% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | ############                          |  33% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | #2                                    |   3% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ###########2                          |  30% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ##########8                           |  29% \u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | #####1                                |  14% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #3                                    |   4% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ###########8                          |  32% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ###########4                          |  31% \u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | #####3                                |  15% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #3                                    |   4% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ############4                         |  34% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ############                          |  33% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | ##############3                       |  39% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | #4                                    |   4% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | #############1                        |  36% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ############6                         |  34% \u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | #####9                                |  16% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #5                                    |   4% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | #############7                        |  37% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | #############2                        |  36% \u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | ######3                               |  17% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #6                                    |   4% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | #############8                        |  38% \u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | ######6                               |  18% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ##############4                       |  39% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #6                                    |   5% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ##############5                       |  39% \u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | ######9                               |  19% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ###############1                      |  41% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #7                                    |   5% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ###############1                      |  41% \u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | #######2                              |  20% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ###############7                      |  43% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #8                                    |   5% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ###############8                      |  43% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ################4                     |  44% \u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | #######5                              |  20% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #9                                    |   5% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ################4                     |  44% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | #################                     |  46% \u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | #######8                              |  21% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ##                                    |   5% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | #################                     |  46% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | #################7                    |  48% \u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | ########1                             |  22% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ##                                    |   6% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | #################6                    |  48% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ##################4                   |  50% \u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | ########4                             |  23% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ##1                                   |   6% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ##################3                   |  49% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ###################                   |  52% \u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | ########7                             |  24% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ##2                                   |   6% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ##################9                   |  51% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ###################7                  |  53% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | ######################6               |  61% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ##3                                   |   6% \u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ###################5                  |  53% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ####################4                 |  55% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | #######################4              |  63% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ##4                                   |   6% \u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ####################2                 |  55% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | #####################1                |  57% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | ########################2             |  65% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ##4                                   |   7% \u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ####################8                 |  56% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | #####################8                |  59% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | ########################9             |  68% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ##5                                   |   7% \u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | #####################4                |  58% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ######################5               |  61% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | #########################7            |  70% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ##6                                   |   7% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | #######################2              |  63% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ######################1               |  60% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | ##########################5           |  72% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ##7                                   |   7% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | #######################9              |  65% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ######################7               |  61% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | ###########################2          |  74% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ##7                                   |   8% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ########################6             |  67% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | #######################3              |  63% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | ############################          |  76% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ##8                                   |   8% \u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | #######################9              |  65% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | #########################3            |  68% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | ############################8         |  78% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ##9                                   |   8% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ##########################            |  70% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | #############################6        |  80% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ########################6             |  67% \u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ###                                   |   8% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | ##############################4       |  82% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ##########################7           |  72% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | #########################2            |  68% \u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ###1                                  |   8% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | ###############################1      |  84% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ###########################4          |  74% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | #########################8            |  70% \u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ###1                                  |   9% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | ###############################9      |  86% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ############################          |  76% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ##########################4           |  72% \u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ###2                                  |   9% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | ################################7     |  88% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ############################7         |  78% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ###########################           |  73% \u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ###3                                  |   9% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | #################################5    |  91% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | #############################4        |  80% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ###########################7          |  75% \u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ###4                                  |   9% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | ##################################2   |  93% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ##############################1       |  82% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ############################3         |  77% \u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ###5                                  |  10% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ##############################8       |  83% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | #############################         |  78% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | ###################################   |  95% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ###6                                  |  10% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ###############################5      |  85% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | ###################################8  |  97% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | #############################6        |  80% \u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ###6                                  |  10% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ################################2     |  87% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | ####################################5 |  99% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ##############################2       |  82% \u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ###7                                  |  10% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ################################8     |  89% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ##############################9       |  84% \u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ###8                                  |  10% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | #################################6    |  91% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ###############################6      |  86% \u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ###9                                  |  11% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ##################################4   |  93% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ################################3     |  88% \u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ####                                  |  11% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ###################################2  |  95% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | #################################     |  89% \u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ####1                                 |  11% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ####################################  |  97% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | #################################8    |  91% \u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ####2                                 |  11% \u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ####################################8 | 100% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ##################################6   |  94% \u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ####3                                 |  12% \u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ###################################4  |  96% \u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ####4                                 |  12% \u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ####################################3 |  98% \u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ####5                                 |  12% \u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ####6                                 |  13% \u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ####7                                 |  13% \u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ####8                                 |  13% \u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | #####                                 |  14% \u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | #####1                                |  14% \u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | #####2                                |  14% \u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | #####3                                |  15% \u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | #####5                                |  15% \u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | #####6                                |  15% \u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | #####7                                |  16% \u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | #####8                                |  16% \u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ######                                |  16% \u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ######1                               |  17% \u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ######2                               |  17% \u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ######4                               |  17% \u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ######5                               |  18% \u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ######6                               |  18% \u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ######7                               |  18% \u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ######9                               |  19% \u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | #######                               |  19% \u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | #######1                              |  19% \u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | #######3                              |  20% \u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | #######4                              |  20% \u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | #######5                              |  20% \u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | #######7                              |  21% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | #######8                              |  21% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | 8                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | ###############################6      |  85% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #######9                              |  22% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | ################################      |  87% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ########                              |  22% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | ###5                                  |  10% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ########1                             |  22% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | ####5                                 |  12% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ########2                             |  22% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | #####4                                |  15% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ########3                             |  23% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | ######3                               |  17% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ########4                             |  23% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | #######3                              |  20% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.6 MB  | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ########5                             |  23% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | ########2                             |  22% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ########6                             |  23% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | #########                             |  25% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ########7                             |  24% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | #3                                    |   4% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | #########8                            |  27% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.0.0        | 1.41 GB   | ########8                             |  24% \u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ##################################### | 100% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ##3                                   |   6% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | ##########6                           |  29% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | ###################################2  |  95% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.0.0    | 62.5 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ########9                             |  24% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.0.0    | 62.5 MB   | #1                                    |   3% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | ###########4                          |  31% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | ###################################5  |  96% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ########9                             |  24% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.0.0    | 62.5 MB   | ##2                                   |   6% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | ############                          |  33% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | ###################################8  |  97% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #########                             |  24% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.0.0    | 62.5 MB   | ###3                                  |   9% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | ####################################  |  98% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | #####8                                |  16% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | ############7                         |  34% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #########1                            |  25% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ######7                               |  18% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | ####################################3 |  98% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | #############2                        |  36% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.0.0    | 62.5 MB   | #####3                                |  15% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.0.0    | 62.5 MB   | ######5                               |  18% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | #############8                        |  37% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | ####################################5 |  99% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #########1                            |  25% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.0.0    | 62.5 MB   | #######6                              |  21% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | ##############3                       |  39% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | ####################################8 |  99% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #########2                            |  25% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.0.0    | 62.5 MB   | ########7                             |  24% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | ##############8                       |  40% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | #########                             |  24% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #########3                            |  25% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | ###############3                      |  41% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | #########7                            |  26% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #########3                            |  25% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.0.0    | 62.5 MB   | ##########9                           |  30% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ##########4                           |  28% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #########4                            |  25% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.0.0    | 62.5 MB   | ############                          |  33% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ###########                           |  30% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #########4                            |  26% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.0.0    | 62.5 MB   | #############1                        |  35% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ###########8                          |  32% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #########4                            |  26% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.0.0    | 62.5 MB   | ##############                        |  38% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ############4                         |  34% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | ##################1                   |  49% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #########5                            |  26% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | #############1                        |  35% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | ##################7                   |  51% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #########6                            |  26% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ##############                        |  38% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | ###################3                  |  52% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #########6                            |  26% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ##############9                       |  40% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | ###################9                  |  54% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #########7                            |  26% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ###############7                      |  43% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | ####################5                 |  55% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #########7                            |  26% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ################5                     |  45% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | #####################1                |  57% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #########8                            |  27% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | #################3                    |  47% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.0.0    | 62.5 MB   | #######################3              |  63% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #########8                            |  27% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ##################2                   |  49% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | ######################4               |  61% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #########9                            |  27% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ###################1                  |  52% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | #######################               |  62% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ##########                            |  27% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ####################                  |  54% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | #######################6              |  64% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ##########                            |  27% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ####################8                 |  56% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | ########################2             |  66% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ##########1                           |  27% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | #####################6                |  59% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | ########################8             |  67% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ##########1                           |  27% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ######################5               |  61% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | #########################4            |  69% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ##########2                           |  28% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | #######################5              |  64% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | #########################9            |  70% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ##########2                           |  28% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ########################4             |  66% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | ##########################5           |  72% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ##########3                           |  28% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | #########################2            |  68% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | ###########################1          |  73% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ##########3                           |  28% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ##########################1           |  71% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | ###########################7          |  75% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ##########4                           |  28% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ###########################           |  73% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ##########5                           |  28% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ###########################9          |  76% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ##########5                           |  29% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ############################8         |  78% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ##########6                           |  29% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | #############################7        |  80% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ##########7                           |  29% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ##############################6       |  83% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ##########7                           |  29% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ###############################4      |  85% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ##########8                           |  29% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ################################3     |  87% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ##########8                           |  29% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | #################################2    |  90% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ##########9                           |  30% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ##################################    |  92% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ###########                           |  30% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ##################################9   |  95% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ###########                           |  30% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ###################################8  |  97% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ###########1                          |  30% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ####################################7 |  99% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ###########2                          |  30% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ###########2                          |  30% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ###############6                      |  42% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | ##################################### | 100% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ###############8                      |  43% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.3.141 | 51.6 MB   | ##9                                   |   8% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.0.0    | 62.5 MB   | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.18        | 25.1 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ###############9                      |  43% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | ###4                                  |   9% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | ####1                                 |  11% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.18        | 25.1 MB   | ##4                                   |   7% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | ######7                               |  18% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.3.141 | 51.6 MB   | ########2                             |  22% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | ########3                             |  23% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.18        | 25.1 MB   | #####5                                |  15% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ################1                     |  44% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | ############8                         |  35% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.3.141 | 51.6 MB   | ##########1                           |  27% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.18        | 25.1 MB   | ########4                             |  23% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | #############1                        |  35% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | #################                     |  46% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.18        | 25.1 MB   | ###########5                          |  31% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.3.141 | 51.6 MB   | ###########8                          |  32% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ################2                     |  44% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.18        | 25.1 MB   | ##############6                       |  39% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | #####################3                |  58% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.3.141 | 51.6 MB   | #############5                        |  37% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | ###################5                  |  53% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.18        | 25.1 MB   | ##################2                   |  49% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | ##########################            |  71% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ################3                     |  44% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | ######################6               |  61% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | ###############################       |  84% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.18        | 25.1 MB   | #####################4                |  58% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.3.141 | 51.6 MB   | ################8                     |  45% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ################4                     |  44% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.18        | 25.1 MB   | ########################7             |  67% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.3.141 | 51.6 MB   | ##################4                   |  50% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | ###################################6  |  96% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ################4                     |  45% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.18        | 25.1 MB   | ###########################9          |  76% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.3.141 | 51.6 MB   | ####################                  |  54% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | ################################4     |  88% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ################5                     |  45% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.3.141 | 51.6 MB   | #####################6                |  58% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | ###################################6  |  96% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.18        | 25.1 MB   | ##################################8   |  94% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ################6                     |  45% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ################6                     |  45% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ################7                     |  45% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.3.141 | 51.6 MB   | ############################5         |  77% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ################8                     |  45% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.3.141 | 51.6 MB   | ##############################1       |  81% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ################8                     |  46% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "intel-openmp-2023.1. | 17.1 MB   | #########3                            |  25% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ################9                     |  46% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "intel-openmp-2023.1. | 17.1 MB   | ##############9                       |  40% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ################9                     |  46% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "intel-openmp-2023.1. | 17.1 MB   | ###################9                  |  54% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #################                     |  46% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sympy-1.13.3         | 11.2 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "intel-openmp-2023.1. | 17.1 MB   | #########################             |  68% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #################1                    |  46% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.18        | 25.1 MB   | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sympy-1.13.3         | 11.2 MB   | #####1                                |  14% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-4.3           | 9.9 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #################1                    |  46% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sympy-1.13.3         | 11.2 MB   | #############                         |  35% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-4.3           | 9.9 MB    | ########5                             |  23% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #################2                    |  47% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sympy-1.13.3         | 11.2 MB   | ###################8                  |  54% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #################3                    |  47% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sympy-1.13.3         | 11.2 MB   | ############################8         |  78% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #################3                    |  47% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #################5                    |  47% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-4.3           | 9.9 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #################5                    |  47% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "intel-openmp-2023.1. | 17.1 MB   | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchaudio-2.0.0     | 7.5 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.0.10       | 5.2 MB    | 1                                     |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #################6                    |  48% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchaudio-2.0.0     | 7.5 MB    | #############1                        |  36% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.0.10       | 5.2 MB    | ################3                     |  44% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #################7                    |  48% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.0.10       | 5.2 MB    | ################################5     |  88% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchaudio-2.0.0     | 7.5 MB    | ##########################2           |  71% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #################7                    |  48% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #################8                    |  48% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.0.10       | 5.2 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #################9                    |  48% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchaudio-2.0.0     | 7.5 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchaudio-2.0.0     | 7.5 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tk-8.6.12            | 3.0 MB    | ########################8             |  67% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "networkx-3.1         | 2.7 MB    | 2                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #################9                    |  49% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pip-23.2.1           | 2.6 MB    | 2                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "networkx-3.1         | 2.7 MB    | ###############################       |  84% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ##################                    |  49% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pip-23.2.1           | 2.6 MB    | #############################5        |  80% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnvjpeg-11.9.0.86  | 2.4 MB    | 2                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.3.141 | 51.6 MB   | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "networkx-3.1         | 2.7 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ##################1                   |  49% [A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cryptography-41.0.3  | 2.0 MB    | 2                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pip-23.2.1           | 2.6 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnvjpeg-11.9.0.86  | 2.4 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ##################1                   |  49% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cryptography-41.0.3  | 2.0 MB    | ######################5               |  61% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | #####################7                |  59% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | ##################################### | 100% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.0.0    | 62.5 MB   | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.18        | 25.1 MB   | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sympy-1.13.3         | 11.2 MB   | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-4.3           | 9.9 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.0.10       | 5.2 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "intel-openmp-2023.1. | 17.1 MB   | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-base-1.25.2    | 7.1 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tk-8.6.12            | 3.0 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchaudio-2.0.0     | 7.5 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "networkx-3.1         | 2.7 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pip-23.2.1           | 2.6 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnvjpeg-11.9.0.86  | 2.4 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cryptography-41.0.3  | 2.0 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | ##################################### | 100% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.0.0        | 1.41 GB   | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \n",
            "                                                                                \u001b[A\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: done\n",
            "Verifying transaction: done\n",
            "Executing transaction: done\n",
            "Installing pip dependencies: \\ Ran pip subprocess with arguments:\n",
            "['/opt/conda/envs/ecb/bin/python', '-m', 'pip', 'install', '-U', '-r', '/kaggle/working/ECB/condaenv.d35w94n4.requirements.txt', '--exists-action=b']\n",
            "Pip subprocess output:\n",
            "Collecting chardet==5.2.0 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 1))\n",
            "  Obtaining dependency information for chardet==5.2.0 from https://files.pythonhosted.org/packages/38/6f/f5fbc992a329ee4e0f288c1fe0e2ad9485ed064cac731ed2fe47dcc38cbf/chardet-5.2.0-py3-none-any.whl.metadata\n",
            "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting charset-normalizer==3.2.0 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 2))\n",
            "  Obtaining dependency information for charset-normalizer==3.2.0 from https://files.pythonhosted.org/packages/f9/0d/514be8597d7a96243e5467a37d337b9399cec117a513fcf9328405d911c0/charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
            "Collecting clip==0.2.0 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 3))\n",
            "  Downloading clip-0.2.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting cmake==3.27.4.1 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 4))\n",
            "  Obtaining dependency information for cmake==3.27.4.1 from https://files.pythonhosted.org/packages/94/87/68536d2dde5acec492742c63bb71f43534eb7d3d83122cce3067c4abca2b/cmake-3.27.4.1-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
            "  Downloading cmake-3.27.4.1-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting contourpy==1.1.0 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 5))\n",
            "  Obtaining dependency information for contourpy==1.1.0 from https://files.pythonhosted.org/packages/38/6f/5382bdff9dda60cb17cef6dfa2bad3e6edacffd5c2243e282e851c63f721/contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting cycler==0.11.0 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 6))\n",
            "  Obtaining dependency information for cycler==0.11.0 from https://files.pythonhosted.org/packages/5c/f9/695d6bedebd747e5eb0fe8fad57b72fdf25411273a39791cde838d5a8f51/cycler-0.11.0-py3-none-any.whl.metadata\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl.metadata (785 bytes)\n",
            "Collecting filelock==3.12.3 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 7))\n",
            "  Obtaining dependency information for filelock==3.12.3 from https://files.pythonhosted.org/packages/52/90/45223db4e1df30ff14e8aebf9a1bf0222da2e7b49e53692c968f36817812/filelock-3.12.3-py3-none-any.whl.metadata\n",
            "  Downloading filelock-3.12.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting fonttools==4.42.1 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 8))\n",
            "  Obtaining dependency information for fonttools==4.42.1 from https://files.pythonhosted.org/packages/49/50/2e31753c088d364756daa5bed0dab6a5928ebfd6e6d26f975c8b6d6f754a/fonttools-4.42.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading fonttools-4.42.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (150 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.0/151.0 kB 5.9 MB/s eta 0:00:00\n",
            "Collecting fsspec==2023.9.0 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 9))\n",
            "  Obtaining dependency information for fsspec==2023.9.0 from https://files.pythonhosted.org/packages/3a/9f/b40e8e5be886143379000af5fc0c675352d59e82fd869d24bf784161dc77/fsspec-2023.9.0-py3-none-any.whl.metadata\n",
            "  Downloading fsspec-2023.9.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting ftfy==6.1.1 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 10))\n",
            "  Obtaining dependency information for ftfy==6.1.1 from https://files.pythonhosted.org/packages/e1/1e/bf736f9576a8979752b826b75cbd83663ff86634ea3055a766e2d8ad3ee5/ftfy-6.1.1-py3-none-any.whl.metadata\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting huggingface-hub==0.17.1 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 11))\n",
            "  Obtaining dependency information for huggingface-hub==0.17.1 from https://files.pythonhosted.org/packages/50/9d/5eac2733606df7d164b951b14cd76b056e530af96c881aaec89383bdbe45/huggingface_hub-0.17.1-py3-none-any.whl.metadata\n",
            "  Downloading huggingface_hub-0.17.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting importlib-resources==6.0.1 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 12))\n",
            "  Obtaining dependency information for importlib-resources==6.0.1 from https://files.pythonhosted.org/packages/25/d4/592f53ce2f8dde8be5720851bd0ab71cc2e76c55978e4163ef1ab7e389bb/importlib_resources-6.0.1-py3-none-any.whl.metadata\n",
            "  Downloading importlib_resources-6.0.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting kiwisolver==1.4.5 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 13))\n",
            "  Obtaining dependency information for kiwisolver==1.4.5 from https://files.pythonhosted.org/packages/c0/a8/841594f11d0b88d8aeb26991bc4dac38baa909dc58d0c4262a4f7893bcbf/kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata\n",
            "  Downloading kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting lit==16.0.6 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 14))\n",
            "  Downloading lit-16.0.6.tar.gz (153 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 153.7/153.7 kB 7.0 MB/s eta 0:00:00\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting markupsafe==2.1.3 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 15))\n",
            "  Obtaining dependency information for markupsafe==2.1.3 from https://files.pythonhosted.org/packages/de/63/cb7e71984e9159ec5f45b5e81e896c8bdd0e45fe3fc6ce02ab497f0d790e/MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting matplotlib==3.7.3 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 16))\n",
            "  Obtaining dependency information for matplotlib==3.7.3 from https://files.pythonhosted.org/packages/ae/13/e2e86809b8d080a346aaaae78c89005b142683ec0af04acc4311837fc1c6/matplotlib-3.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading matplotlib-3.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 17))\n",
            "  Obtaining dependency information for nvidia-cublas-cu11==11.10.3.66 from https://files.pythonhosted.org/packages/ce/41/fdeb62b5437996e841d83d7d2714ca75b886547ee8017ee2fe6ea409d983/nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 18))\n",
            "  Obtaining dependency information for nvidia-cuda-cupti-cu11==11.7.101 from https://files.pythonhosted.org/packages/e6/9d/dd0cdcd800e642e3c82ee3b5987c751afd4f3fb9cc2752517f42c3bc6e49/nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 19))\n",
            "  Obtaining dependency information for nvidia-cuda-nvrtc-cu11==11.7.99 from https://files.pythonhosted.org/packages/ef/25/922c5996aada6611b79b53985af7999fc629aee1d5d001b6a22431e18fec/nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 20))\n",
            "  Obtaining dependency information for nvidia-cuda-runtime-cu11==11.7.99 from https://files.pythonhosted.org/packages/36/92/89cf558b514125d2ebd8344dd2f0533404b416486ff681d5434a5832a019/nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 21))\n",
            "  Obtaining dependency information for nvidia-cudnn-cu11==8.5.0.96 from https://files.pythonhosted.org/packages/dc/30/66d4347d6e864334da5bb1c7571305e501dcb11b9155971421bb7bb5315f/nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 22))\n",
            "  Obtaining dependency information for nvidia-cufft-cu11==10.9.0.58 from https://files.pythonhosted.org/packages/64/c8/133717b43182ba063803e983e7680a94826a9f4ff5734af0ca315803f1b3/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 23))\n",
            "  Obtaining dependency information for nvidia-curand-cu11==10.2.10.91 from https://files.pythonhosted.org/packages/8f/11/af78d54b2420e64a4dd19e704f5bb69dcb5a6a3138b4465d6a48cdf59a21/nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 24))\n",
            "  Obtaining dependency information for nvidia-cusolver-cu11==11.4.0.1 from https://files.pythonhosted.org/packages/3e/77/66149e3153b19312fb782ea367f3f950123b93916a45538b573fe373570a/nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 25))\n",
            "  Obtaining dependency information for nvidia-cusparse-cu11==11.7.4.91 from https://files.pythonhosted.org/packages/ea/6f/6d032cc1bb7db88a989ddce3f4968419a7edeafda362847f42f614b1f845/nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 26))\n",
            "  Obtaining dependency information for nvidia-nccl-cu11==2.14.3 from https://files.pythonhosted.org/packages/55/92/914cdb650b6a5d1478f83148597a25e90ea37d739bd563c5096b0e8a5f43/nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 27))\n",
            "  Obtaining dependency information for nvidia-nvtx-cu11==11.7.91 from https://files.pythonhosted.org/packages/23/d5/09493ff0e64fd77523afbbb075108f27a13790479efe86b9ffb4587671b5/nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting opencv-python==4.8.0.76 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 28))\n",
            "  Obtaining dependency information for opencv-python==4.8.0.76 from https://files.pythonhosted.org/packages/f5/d0/2e455d894ec0d6527e662ad55e70c04f421ad83a6fd0a54c3dd73c411282/opencv_python-4.8.0.76-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading opencv_python-4.8.0.76-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting packaging==23.1 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 29))\n",
            "  Obtaining dependency information for packaging==23.1 from https://files.pythonhosted.org/packages/ab/c3/57f0601a2d4fe15de7a553c00adbc901425661bf048f2a22dfc500caf121/packaging-23.1-py3-none-any.whl.metadata\n",
            "  Downloading packaging-23.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting pillow==10.0.0 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 30))\n",
            "  Obtaining dependency information for pillow==10.0.0 from https://files.pythonhosted.org/packages/50/e5/0d484d1ac71b934638f91b7156203ba5bf3eb12f596b616a68a85c123808/Pillow-10.0.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata\n",
            "  Downloading Pillow-10.0.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
            "Collecting pyparsing==3.1.1 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 31))\n",
            "  Obtaining dependency information for pyparsing==3.1.1 from https://files.pythonhosted.org/packages/39/92/8486ede85fcc088f1b3dba4ce92dd29d126fd96b0008ea213167940a2475/pyparsing-3.1.1-py3-none-any.whl.metadata\n",
            "  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting python-dateutil==2.8.2 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 32))\n",
            "  Obtaining dependency information for python-dateutil==2.8.2 from https://files.pythonhosted.org/packages/36/7a/87837f39d0296e723bb9b62bbb257d0355c7f6128853c78955f57342a56d/python_dateutil-2.8.2-py2.py3-none-any.whl.metadata\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting pyyaml==6.0.1 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 33))\n",
            "  Obtaining dependency information for pyyaml==6.0.1 from https://files.pythonhosted.org/packages/7d/39/472f2554a0f1e825bd7c5afc11c817cd7a2f3657460f7159f691fbb37c51/PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting regex==2023.8.8 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 34))\n",
            "  Obtaining dependency information for regex==2023.8.8 from https://files.pythonhosted.org/packages/c0/f4/278e305e02245937579a7952b8a3205116b4d2480a3c03fa11e599b773d6/regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.9/40.9 kB 4.1 MB/s eta 0:00:00\n",
            "Collecting safetensors==0.3.3 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 35))\n",
            "  Obtaining dependency information for safetensors==0.3.3 from https://files.pythonhosted.org/packages/4c/49/d41e7f524bff04e51ebe560ecedb28127d8f4e424f9d250c106c3b7fb637/safetensors-0.3.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading safetensors-0.3.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Collecting scipy==1.11.2 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 36))\n",
            "  Obtaining dependency information for scipy==1.11.2 from https://files.pythonhosted.org/packages/a3/d3/f88285098505c8e5d141678a24bb9620d902c683f11edc1eb9532b02624e/scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.1/59.1 kB 4.8 MB/s eta 0:00:00\n",
            "Collecting six==1.16.0 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 37))\n",
            "  Obtaining dependency information for six==1.16.0 from https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl.metadata\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting sympy==1.12 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 38))\n",
            "  Obtaining dependency information for sympy==1.12 from https://files.pythonhosted.org/packages/d2/05/e6600db80270777c4a64238a98d442f0fd07cc8915be2a1c16da7f2b9e74/sympy-1.12-py3-none-any.whl.metadata\n",
            "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting termcolor==2.3.0 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 39))\n",
            "  Obtaining dependency information for termcolor==2.3.0 from https://files.pythonhosted.org/packages/67/e1/434566ffce04448192369c1a282931cf4ae593e91907558eaecd2e9f2801/termcolor-2.3.0-py3-none-any.whl.metadata\n",
            "  Downloading termcolor-2.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting timm==0.9.7 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 40))\n",
            "  Obtaining dependency information for timm==0.9.7 from https://files.pythonhosted.org/packages/7a/bd/2c56be7a3b5bc71cf85a405246b89d5359f942c9f7fb6db6306d9d056092/timm-0.9.7-py3-none-any.whl.metadata\n",
            "  Downloading timm-0.9.7-py3-none-any.whl.metadata (58 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.8/58.8 kB 5.2 MB/s eta 0:00:00\n",
            "Collecting torch==2.0.1 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 41))\n",
            "  Obtaining dependency information for torch==2.0.1 from https://files.pythonhosted.org/packages/e5/9a/ce0fe125f226ffce8deba6a18bd8d0b9f589aa236780a83a6d70b5525f56/torch-2.0.1-cp39-cp39-manylinux1_x86_64.whl.metadata\n",
            "  Downloading torch-2.0.1-cp39-cp39-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting torchvision==0.15.2 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 42))\n",
            "  Obtaining dependency information for torchvision==0.15.2 from https://files.pythonhosted.org/packages/41/9e/8809e45a084680394e8d219fcf8a2c0eed2dddf1ec0a7968f4052826a6e9/torchvision-0.15.2-cp39-cp39-manylinux1_x86_64.whl.metadata\n",
            "  Downloading torchvision-0.15.2-cp39-cp39-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "Collecting tqdm==4.66.1 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 43))\n",
            "  Obtaining dependency information for tqdm==4.66.1 from https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl.metadata\n",
            "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.6/57.6 kB 4.6 MB/s eta 0:00:00\n",
            "Requirement already satisfied: triton==2.0.0 in /opt/conda/envs/ecb/lib/python3.9/site-packages (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 44)) (2.0.0)\n",
            "Collecting urllib3==2.0.4 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 45))\n",
            "  Obtaining dependency information for urllib3==2.0.4 from https://files.pythonhosted.org/packages/9b/81/62fd61001fa4b9d0df6e31d47ff49cfa9de4af03adecf339c7bc30656b37/urllib3-2.0.4-py3-none-any.whl.metadata\n",
            "  Downloading urllib3-2.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting wcwidth==0.2.6 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 46))\n",
            "  Obtaining dependency information for wcwidth==0.2.6 from https://files.pythonhosted.org/packages/20/f4/c0584a25144ce20bfcf1aecd041768b8c762c1eb0aa77502a3f0baa83f11/wcwidth-0.2.6-py2.py3-none-any.whl.metadata\n",
            "  Downloading wcwidth-0.2.6-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting zipp==3.16.2 (from -r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 47))\n",
            "  Obtaining dependency information for zipp==3.16.2 from https://files.pythonhosted.org/packages/8c/08/d3006317aefe25ea79d3b76c9650afabaf6d63d1c8443b236e7405447503/zipp-3.16.2-py3-none-any.whl.metadata\n",
            "  Downloading zipp-3.16.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: numpy>=1.16 in /opt/conda/envs/ecb/lib/python3.9/site-packages (from contourpy==1.1.0->-r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 5)) (1.25.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7.1 in /opt/conda/envs/ecb/lib/python3.9/site-packages (from filelock==3.12.3->-r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 7)) (4.7.1)\n",
            "Requirement already satisfied: requests in /opt/conda/envs/ecb/lib/python3.9/site-packages (from huggingface-hub==0.17.1->-r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 11)) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /opt/conda/envs/ecb/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->-r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 17)) (68.0.0)\n",
            "Requirement already satisfied: wheel in /opt/conda/envs/ecb/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->-r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 17)) (0.38.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /opt/conda/envs/ecb/lib/python3.9/site-packages (from sympy==1.12->-r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 38)) (1.3.0)\n",
            "Requirement already satisfied: networkx in /opt/conda/envs/ecb/lib/python3.9/site-packages (from torch==2.0.1->-r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 41)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /opt/conda/envs/ecb/lib/python3.9/site-packages (from torch==2.0.1->-r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 41)) (3.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/ecb/lib/python3.9/site-packages (from requests->huggingface-hub==0.17.1->-r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 11)) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/ecb/lib/python3.9/site-packages (from requests->huggingface-hub==0.17.1->-r /kaggle/working/ECB/condaenv.d35w94n4.requirements.txt (line 11)) (2023.7.22)\n",
            "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 199.4/199.4 kB 8.2 MB/s eta 0:00:00\n",
            "Downloading charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (202 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 202.1/202.1 kB 8.9 MB/s eta 0:00:00\n",
            "Downloading cmake-3.27.4.1-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 26.1/26.1 MB 52.1 MB/s eta 0:00:00\n",
            "Downloading contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 300.4/300.4 kB 29.1 MB/s eta 0:00:00\n",
            "Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Downloading filelock-3.12.3-py3-none-any.whl (11 kB)\n",
            "Downloading fonttools-4.42.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 88.2 MB/s eta 0:00:00\n",
            "Downloading fsspec-2023.9.0-py3-none-any.whl (173 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 173.2/173.2 kB 19.0 MB/s eta 0:00:00\n",
            "Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.1/53.1 kB 5.4 MB/s eta 0:00:00\n",
            "Downloading huggingface_hub-0.17.1-py3-none-any.whl (294 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 294.8/294.8 kB 28.3 MB/s eta 0:00:00\n",
            "Downloading importlib_resources-6.0.1-py3-none-any.whl (34 kB)\n",
            "Downloading kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 76.6 MB/s eta 0:00:00\n",
            "Downloading MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading matplotlib-3.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.6/11.6 MB 98.6 MB/s eta 0:00:00\n",
            "Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 317.1/317.1 MB 3.7 MB/s eta 0:00:00\n",
            "Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.8/11.8 MB 101.2 MB/s eta 0:00:00\n",
            "Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.0/21.0 MB 78.5 MB/s eta 0:00:00\n",
            "Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 849.3/849.3 kB 58.9 MB/s eta 0:00:00\n",
            "Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 557.1/557.1 MB 932.5 kB/s eta 0:00:00\n",
            "Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 168.4/168.4 MB 4.7 MB/s eta 0:00:00\n",
            "Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.6/54.6 MB 25.1 MB/s eta 0:00:00\n",
            "Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 102.6/102.6 MB 13.1 MB/s eta 0:00:00\n",
            "Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 173.2/173.2 MB 7.3 MB/s eta 0:00:00\n",
            "Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 177.1/177.1 MB 7.3 MB/s eta 0:00:00\n",
            "Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 98.6/98.6 kB 9.5 MB/s eta 0:00:00\n",
            "Downloading opencv_python-4.8.0.76-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.7/61.7 MB 21.4 MB/s eta 0:00:00\n",
            "Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.9/48.9 kB 4.2 MB/s eta 0:00:00\n",
            "Downloading Pillow-10.0.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 90.7 MB/s eta 0:00:00\n",
            "Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 103.1/103.1 kB 10.3 MB/s eta 0:00:00\n",
            "Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 247.7/247.7 kB 21.8 MB/s eta 0:00:00\n",
            "Downloading PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 738.9/738.9 kB 52.9 MB/s eta 0:00:00\n",
            "Downloading regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 771.4/771.4 kB 53.7 MB/s eta 0:00:00\n",
            "Downloading safetensors-0.3.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 65.8 MB/s eta 0:00:00\n",
            "Downloading scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 36.5/36.5 MB 41.9 MB/s eta 0:00:00\n",
            "Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 99.2 MB/s eta 0:00:00\n",
            "Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
            "Downloading timm-0.9.7-py3-none-any.whl (2.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 78.3 MB/s eta 0:00:00\n",
            "Downloading torch-2.0.1-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 619.9/619.9 MB 1.5 MB/s eta 0:00:00\n",
            "Downloading torchvision-0.15.2-cp39-cp39-manylinux1_x86_64.whl (6.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.0/6.0 MB 105.1 MB/s eta 0:00:00\n",
            "Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.3/78.3 kB 9.2 MB/s eta 0:00:00\n",
            "Downloading urllib3-2.0.4-py3-none-any.whl (123 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 123.9/123.9 kB 9.0 MB/s eta 0:00:00\n",
            "Downloading wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\n",
            "Downloading zipp-3.16.2-py3-none-any.whl (7.2 kB)\n",
            "Building wheels for collected packages: clip, lit\n",
            "  Building wheel for clip (setup.py): started\n",
            "  Building wheel for clip (setup.py): finished with status 'done'\n",
            "  Created wheel for clip: filename=clip-0.2.0-py3-none-any.whl size=6989 sha256=2e02bcb30dfd12dc5cbbdd5fafb66aed547aaa484ef3a8c8778a745d65167cf2\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/99/44/ceb6f1b57fd1a1d7241d886a4074ffbd552937ed87ccf479d6\n",
            "  Building wheel for lit (pyproject.toml): started\n",
            "  Building wheel for lit (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for lit: filename=lit-16.0.6-py3-none-any.whl size=93662 sha256=c93a3d7235686eba466669b529130b21b2bd93d47198f957242b3dca76d2f958\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/36/d6/cac2e6fb891889b33a548f2fddb8b4b7726399aaa2ed32b188\n",
            "Successfully built clip lit\n",
            "Installing collected packages: wcwidth, safetensors, lit, cmake, clip, zipp, urllib3, tqdm, termcolor, sympy, six, scipy, regex, pyyaml, pyparsing, pillow, packaging, opencv-python, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, markupsafe, kiwisolver, ftfy, fsspec, fonttools, filelock, cycler, contourpy, charset-normalizer, chardet, python-dateutil, nvidia-cusolver-cu11, nvidia-cudnn-cu11, importlib-resources, matplotlib, huggingface-hub, torch, torchvision, timm\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.19\n",
            "    Uninstalling urllib3-1.26.19:\n",
            "      Successfully uninstalled urllib3-1.26.19\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.3\n",
            "    Uninstalling sympy-1.13.3:\n",
            "      Successfully uninstalled sympy-1.13.3\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.17.0\n",
            "    Uninstalling filelock-3.17.0:\n",
            "      Successfully uninstalled filelock-3.17.0\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.3.2\n",
            "    Uninstalling charset-normalizer-3.3.2:\n",
            "      Successfully uninstalled charset-normalizer-3.3.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0\n",
            "    Uninstalling torch-2.0.0:\n",
            "      Successfully uninstalled torch-2.0.0\n",
            "Successfully installed chardet-5.2.0 charset-normalizer-3.2.0 clip-0.2.0 cmake-3.27.4.1 contourpy-1.1.0 cycler-0.11.0 filelock-3.12.3 fonttools-4.42.1 fsspec-2023.9.0 ftfy-6.1.1 huggingface-hub-0.17.1 importlib-resources-6.0.1 kiwisolver-1.4.5 lit-16.0.6 markupsafe-2.1.3 matplotlib-3.7.3 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 opencv-python-4.8.0.76 packaging-23.1 pillow-10.0.0 pyparsing-3.1.1 python-dateutil-2.8.2 pyyaml-6.0.1 regex-2023.8.8 safetensors-0.3.3 scipy-1.11.2 six-1.16.0 sympy-1.12 termcolor-2.3.0 timm-0.9.7 torch-2.0.1 torchvision-0.15.2 tqdm-4.66.1 urllib3-2.0.4 wcwidth-0.2.6 zipp-3.16.2\n",
            "\n",
            "done\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate ecb\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!source activate ecb && echo $CONDA_DEFAULT_ENV && python -c \"import torch; print(torch.__version__)\""
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-01T07:29:16.819093Z",
          "iopub.status.busy": "2025-05-01T07:29:16.818736Z",
          "iopub.status.idle": "2025-05-01T07:29:19.910914Z",
          "shell.execute_reply": "2025-05-01T07:29:19.909784Z",
          "shell.execute_reply.started": "2025-05-01T07:29:16.819065Z"
        },
        "id": "frk4IeFfkPMN",
        "trusted": true,
        "outputId": "3f17a0ef-37fc-44bf-b458-dcdfb44be545"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ecb\n",
            "2.0.1+cu117\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Preparation**"
      ],
      "metadata": {
        "id": "52gifjb3o9_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-01T07:53:26.154099Z",
          "iopub.status.busy": "2025-05-01T07:53:26.153667Z",
          "iopub.status.idle": "2025-05-01T07:53:26.270781Z",
          "shell.execute_reply": "2025-05-01T07:53:26.269762Z",
          "shell.execute_reply.started": "2025-05-01T07:53:26.154075Z"
        },
        "id": "KkOMhaENrt1S",
        "trusted": true,
        "outputId": "dce73696-993c-44dd-a344-07ca0e363b2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/kaggle/working/ECB\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-01T07:53:29.718847Z",
          "iopub.status.busy": "2025-05-01T07:53:29.718513Z",
          "iopub.status.idle": "2025-05-01T07:53:29.724663Z",
          "shell.execute_reply": "2025-05-01T07:53:29.724015Z",
          "shell.execute_reply.started": "2025-05-01T07:53:29.718819Z"
        },
        "id": "mugzk88QO4LQ",
        "trusted": true,
        "outputId": "027d1c38-c71f-4aa1-8a98-1ef2864d04fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/kaggle/working\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p Dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-01T07:29:24.141176Z",
          "iopub.status.busy": "2025-05-01T07:29:24.140880Z",
          "iopub.status.idle": "2025-05-01T07:29:24.268631Z",
          "shell.execute_reply": "2025-05-01T07:29:24.267608Z",
          "shell.execute_reply.started": "2025-05-01T07:29:24.141141Z"
        },
        "id": "ygflQ3mlcTQL",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-01T07:53:35.448616Z",
          "iopub.status.busy": "2025-05-01T07:53:35.448315Z",
          "iopub.status.idle": "2025-05-01T07:53:35.454114Z",
          "shell.execute_reply": "2025-05-01T07:53:35.453243Z",
          "shell.execute_reply.started": "2025-05-01T07:53:35.448593Z"
        },
        "id": "FXjKX38occZ3",
        "trusted": true,
        "outputId": "8b8b2d18-f04d-4212-ed82-a875f61ff2d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/kaggle/working/Dataset\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "OfficeHome dataset"
      ],
      "metadata": {
        "id": "EfLjpmJU8dhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "source_folder = \"/kaggle/input/officehome/OfficeHomeDataset_10072016\"\n",
        "target_folder = \"/kaggle/working/Dataset/office_home/\"\n",
        "\n",
        "\n",
        "# Copy the folder (and its contents)\n",
        "shutil.copytree(source_folder, target_folder)\n",
        "\n",
        "print(\"✅ Folder copied and renamed successfully!\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-01T07:29:24.275933Z",
          "iopub.status.busy": "2025-05-01T07:29:24.275727Z",
          "iopub.status.idle": "2025-05-01T07:31:39.216076Z",
          "shell.execute_reply": "2025-05-01T07:31:39.215333Z",
          "shell.execute_reply.started": "2025-05-01T07:29:24.275914Z"
        },
        "trusted": true,
        "id": "LYCcxdDvRkxQ",
        "outputId": "e5d4b83f-9f85-47c1-b8f9-6ebebb5987eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Folder copied and renamed successfully!\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Rename folder\n",
        "old_folder = \"/kaggle/working/Dataset/office_home/Real World\"\n",
        "new_folder = \"/kaggle/working/Dataset/office_home/Real\"\n",
        "\n",
        "os.rename(old_folder, new_folder)\n",
        "print(\"Folder renamed successfully!\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-01T07:31:39.217175Z",
          "iopub.status.busy": "2025-05-01T07:31:39.216930Z",
          "iopub.status.idle": "2025-05-01T07:31:39.221631Z",
          "shell.execute_reply": "2025-05-01T07:31:39.220819Z",
          "shell.execute_reply.started": "2025-05-01T07:31:39.217153Z"
        },
        "id": "7A_NcWDH4IDD",
        "outputId": "bb25696e-e828-47d7-eec6-e016018229f1",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folder renamed successfully!\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Office31 dataset"
      ],
      "metadata": {
        "id": "ZQIQK6xr8glc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p office31"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-01T07:53:45.428056Z",
          "iopub.status.busy": "2025-05-01T07:53:45.427759Z",
          "iopub.status.idle": "2025-05-01T07:53:45.546408Z",
          "shell.execute_reply": "2025-05-01T07:53:45.545479Z",
          "shell.execute_reply.started": "2025-05-01T07:53:45.428033Z"
        },
        "id": "ZDv2-xKirsJx",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U --no-cache-dir gdown --pre\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-01T07:53:46.731068Z",
          "iopub.status.busy": "2025-05-01T07:53:46.730666Z",
          "iopub.status.idle": "2025-05-01T07:53:48.484542Z",
          "shell.execute_reply": "2025-05-01T07:53:48.483746Z",
          "shell.execute_reply.started": "2025-05-01T07:53:46.731037Z"
        },
        "id": "2F9UPK_K8iVB",
        "outputId": "d13d9d60-4268-43f1-986c-ec9edd375388",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gdown\n",
            "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting beautifulsoup4 (from gdown)\n",
            "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting filelock (from gdown)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.13/site-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.13/site-packages (from gdown) (4.67.1)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4->gdown)\n",
            "  Downloading soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.13/site-packages (from beautifulsoup4->gdown) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.13/site-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.13/site-packages (from requests[socks]->gdown) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.13/site-packages (from requests[socks]->gdown) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.13/site-packages (from requests[socks]->gdown) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.13/site-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
            "Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
            "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading soupsieve-2.7-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: soupsieve, filelock, beautifulsoup4, gdown\n",
            "Successfully installed beautifulsoup4-4.13.4 filelock-3.18.0 gdown-5.2.0 soupsieve-2.7\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 0B4IapRTv9pJ1WGZVd1VDMmhwdlE\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-01T07:53:48.486291Z",
          "iopub.status.busy": "2025-05-01T07:53:48.485978Z",
          "iopub.status.idle": "2025-05-01T07:53:55.565658Z",
          "shell.execute_reply": "2025-05-01T07:53:55.564832Z",
          "shell.execute_reply.started": "2025-05-01T07:53:48.486256Z"
        },
        "id": "NFsJ9EIO8l74",
        "outputId": "91968dd2-376e-4423-ab8e-5b5d21368497",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.13/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=0B4IapRTv9pJ1WGZVd1VDMmhwdlE\n",
            "From (redirected): https://drive.google.com/uc?id=0B4IapRTv9pJ1WGZVd1VDMmhwdlE&confirm=t&uuid=0c02e17e-38fa-4712-b01e-87071ba918ff\n",
            "To: /kaggle/working/Dataset/domain_adaptation_images.tar.gz\n",
            "100%|██████████████████████████████████████| 77.2M/77.2M [00:02<00:00, 34.4MB/s]\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvf domain_adaptation_images.tar.gz -C /kaggle/working/Dataset/office31"
      ],
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-05-01T07:53:55.567255Z",
          "iopub.status.busy": "2025-05-01T07:53:55.567043Z",
          "iopub.status.idle": "2025-05-01T07:53:56.479209Z",
          "shell.execute_reply": "2025-05-01T07:53:56.478409Z",
          "shell.execute_reply.started": "2025-05-01T07:53:55.567235Z"
        },
        "id": "EYuNgTDh8oBx",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "21dd58c1-8097-4ab5-bc41-2dbf3e4f1f55",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "amazon/images/back_pack/frame_0001.jpg\n",
            "amazon/images/back_pack/frame_0002.jpg\n",
            "amazon/images/back_pack/frame_0003.jpg\n",
            "amazon/images/back_pack/frame_0004.jpg\n",
            "amazon/images/back_pack/frame_0005.jpg\n",
            "amazon/images/back_pack/frame_0006.jpg\n",
            "amazon/images/back_pack/frame_0007.jpg\n",
            "amazon/images/back_pack/frame_0008.jpg\n",
            "amazon/images/back_pack/frame_0009.jpg\n",
            "amazon/images/back_pack/frame_0010.jpg\n",
            "amazon/images/back_pack/frame_0011.jpg\n",
            "amazon/images/back_pack/frame_0012.jpg\n",
            "amazon/images/back_pack/frame_0013.jpg\n",
            "amazon/images/back_pack/frame_0014.jpg\n",
            "amazon/images/back_pack/frame_0015.jpg\n",
            "amazon/images/back_pack/frame_0016.jpg\n",
            "amazon/images/back_pack/frame_0017.jpg\n",
            "amazon/images/back_pack/frame_0018.jpg\n",
            "amazon/images/back_pack/frame_0019.jpg\n",
            "amazon/images/back_pack/frame_0020.jpg\n",
            "amazon/images/back_pack/frame_0021.jpg\n",
            "amazon/images/back_pack/frame_0022.jpg\n",
            "amazon/images/back_pack/frame_0023.jpg\n",
            "amazon/images/back_pack/frame_0024.jpg\n",
            "amazon/images/back_pack/frame_0025.jpg\n",
            "amazon/images/back_pack/frame_0026.jpg\n",
            "amazon/images/back_pack/frame_0027.jpg\n",
            "amazon/images/back_pack/frame_0028.jpg\n",
            "amazon/images/back_pack/frame_0029.jpg\n",
            "amazon/images/back_pack/frame_0030.jpg\n",
            "amazon/images/back_pack/frame_0031.jpg\n",
            "amazon/images/back_pack/frame_0032.jpg\n",
            "amazon/images/back_pack/frame_0033.jpg\n",
            "amazon/images/back_pack/frame_0034.jpg\n",
            "amazon/images/back_pack/frame_0035.jpg\n",
            "amazon/images/back_pack/frame_0036.jpg\n",
            "amazon/images/back_pack/frame_0037.jpg\n",
            "amazon/images/back_pack/frame_0038.jpg\n",
            "amazon/images/back_pack/frame_0039.jpg\n",
            "amazon/images/back_pack/frame_0040.jpg\n",
            "amazon/images/back_pack/frame_0041.jpg\n",
            "amazon/images/back_pack/frame_0042.jpg\n",
            "amazon/images/back_pack/frame_0043.jpg\n",
            "amazon/images/back_pack/frame_0044.jpg\n",
            "amazon/images/back_pack/frame_0045.jpg\n",
            "amazon/images/back_pack/frame_0046.jpg\n",
            "amazon/images/back_pack/frame_0047.jpg\n",
            "amazon/images/back_pack/frame_0048.jpg\n",
            "amazon/images/back_pack/frame_0049.jpg\n",
            "amazon/images/back_pack/frame_0050.jpg\n",
            "amazon/images/back_pack/frame_0051.jpg\n",
            "amazon/images/back_pack/frame_0052.jpg\n",
            "amazon/images/back_pack/frame_0053.jpg\n",
            "amazon/images/back_pack/frame_0054.jpg\n",
            "amazon/images/back_pack/frame_0055.jpg\n",
            "amazon/images/back_pack/frame_0056.jpg\n",
            "amazon/images/back_pack/frame_0057.jpg\n",
            "amazon/images/back_pack/frame_0058.jpg\n",
            "amazon/images/back_pack/frame_0059.jpg\n",
            "amazon/images/back_pack/frame_0060.jpg\n",
            "amazon/images/back_pack/frame_0061.jpg\n",
            "amazon/images/back_pack/frame_0062.jpg\n",
            "amazon/images/back_pack/frame_0063.jpg\n",
            "amazon/images/back_pack/frame_0064.jpg\n",
            "amazon/images/back_pack/frame_0065.jpg\n",
            "amazon/images/back_pack/frame_0066.jpg\n",
            "amazon/images/back_pack/frame_0067.jpg\n",
            "amazon/images/back_pack/frame_0068.jpg\n",
            "amazon/images/back_pack/frame_0069.jpg\n",
            "amazon/images/back_pack/frame_0070.jpg\n",
            "amazon/images/back_pack/frame_0071.jpg\n",
            "amazon/images/back_pack/frame_0072.jpg\n",
            "amazon/images/back_pack/frame_0073.jpg\n",
            "amazon/images/back_pack/frame_0074.jpg\n",
            "amazon/images/back_pack/frame_0075.jpg\n",
            "amazon/images/back_pack/frame_0076.jpg\n",
            "amazon/images/back_pack/frame_0077.jpg\n",
            "amazon/images/back_pack/frame_0078.jpg\n",
            "amazon/images/back_pack/frame_0079.jpg\n",
            "amazon/images/back_pack/frame_0080.jpg\n",
            "amazon/images/back_pack/frame_0081.jpg\n",
            "amazon/images/back_pack/frame_0082.jpg\n",
            "amazon/images/back_pack/frame_0083.jpg\n",
            "amazon/images/back_pack/frame_0084.jpg\n",
            "amazon/images/back_pack/frame_0085.jpg\n",
            "amazon/images/back_pack/frame_0086.jpg\n",
            "amazon/images/back_pack/frame_0087.jpg\n",
            "amazon/images/back_pack/frame_0088.jpg\n",
            "amazon/images/back_pack/frame_0089.jpg\n",
            "amazon/images/back_pack/frame_0090.jpg\n",
            "amazon/images/back_pack/frame_0091.jpg\n",
            "amazon/images/back_pack/frame_0092.jpg\n",
            "amazon/images/bike/frame_0001.jpg\n",
            "amazon/images/bike/frame_0002.jpg\n",
            "amazon/images/bike/frame_0003.jpg\n",
            "amazon/images/bike/frame_0004.jpg\n",
            "amazon/images/bike/frame_0005.jpg\n",
            "amazon/images/bike/frame_0006.jpg\n",
            "amazon/images/bike/frame_0007.jpg\n",
            "amazon/images/bike/frame_0008.jpg\n",
            "amazon/images/bike/frame_0009.jpg\n",
            "amazon/images/bike/frame_0010.jpg\n",
            "amazon/images/bike/frame_0011.jpg\n",
            "amazon/images/bike/frame_0012.jpg\n",
            "amazon/images/bike/frame_0013.jpg\n",
            "amazon/images/bike/frame_0014.jpg\n",
            "amazon/images/bike/frame_0015.jpg\n",
            "amazon/images/bike/frame_0016.jpg\n",
            "amazon/images/bike/frame_0017.jpg\n",
            "amazon/images/bike/frame_0018.jpg\n",
            "amazon/images/bike/frame_0019.jpg\n",
            "amazon/images/bike/frame_0020.jpg\n",
            "amazon/images/bike/frame_0021.jpg\n",
            "amazon/images/bike/frame_0022.jpg\n",
            "amazon/images/bike/frame_0023.jpg\n",
            "amazon/images/bike/frame_0024.jpg\n",
            "amazon/images/bike/frame_0025.jpg\n",
            "amazon/images/bike/frame_0026.jpg\n",
            "amazon/images/bike/frame_0027.jpg\n",
            "amazon/images/bike/frame_0028.jpg\n",
            "amazon/images/bike/frame_0029.jpg\n",
            "amazon/images/bike/frame_0030.jpg\n",
            "amazon/images/bike/frame_0031.jpg\n",
            "amazon/images/bike/frame_0032.jpg\n",
            "amazon/images/bike/frame_0033.jpg\n",
            "amazon/images/bike/frame_0034.jpg\n",
            "amazon/images/bike/frame_0035.jpg\n",
            "amazon/images/bike/frame_0036.jpg\n",
            "amazon/images/bike/frame_0037.jpg\n",
            "amazon/images/bike/frame_0038.jpg\n",
            "amazon/images/bike/frame_0039.jpg\n",
            "amazon/images/bike/frame_0040.jpg\n",
            "amazon/images/bike/frame_0041.jpg\n",
            "amazon/images/bike/frame_0042.jpg\n",
            "amazon/images/bike/frame_0043.jpg\n",
            "amazon/images/bike/frame_0044.jpg\n",
            "amazon/images/bike/frame_0045.jpg\n",
            "amazon/images/bike/frame_0046.jpg\n",
            "amazon/images/bike/frame_0047.jpg\n",
            "amazon/images/bike/frame_0048.jpg\n",
            "amazon/images/bike/frame_0049.jpg\n",
            "amazon/images/bike/frame_0050.jpg\n",
            "amazon/images/bike/frame_0051.jpg\n",
            "amazon/images/bike/frame_0052.jpg\n",
            "amazon/images/bike/frame_0053.jpg\n",
            "amazon/images/bike/frame_0054.jpg\n",
            "amazon/images/bike/frame_0055.jpg\n",
            "amazon/images/bike/frame_0056.jpg\n",
            "amazon/images/bike/frame_0057.jpg\n",
            "amazon/images/bike/frame_0058.jpg\n",
            "amazon/images/bike/frame_0059.jpg\n",
            "amazon/images/bike/frame_0060.jpg\n",
            "amazon/images/bike/frame_0061.jpg\n",
            "amazon/images/bike/frame_0062.jpg\n",
            "amazon/images/bike/frame_0063.jpg\n",
            "amazon/images/bike/frame_0064.jpg\n",
            "amazon/images/bike/frame_0065.jpg\n",
            "amazon/images/bike/frame_0066.jpg\n",
            "amazon/images/bike/frame_0067.jpg\n",
            "amazon/images/bike/frame_0068.jpg\n",
            "amazon/images/bike/frame_0069.jpg\n",
            "amazon/images/bike/frame_0070.jpg\n",
            "amazon/images/bike/frame_0071.jpg\n",
            "amazon/images/bike/frame_0072.jpg\n",
            "amazon/images/bike/frame_0073.jpg\n",
            "amazon/images/bike/frame_0074.jpg\n",
            "amazon/images/bike/frame_0075.jpg\n",
            "amazon/images/bike/frame_0076.jpg\n",
            "amazon/images/bike/frame_0077.jpg\n",
            "amazon/images/bike/frame_0078.jpg\n",
            "amazon/images/bike/frame_0079.jpg\n",
            "amazon/images/bike/frame_0080.jpg\n",
            "amazon/images/bike/frame_0081.jpg\n",
            "amazon/images/bike/frame_0082.jpg\n",
            "amazon/images/bike_helmet/frame_0001.jpg\n",
            "amazon/images/bike_helmet/frame_0002.jpg\n",
            "amazon/images/bike_helmet/frame_0003.jpg\n",
            "amazon/images/bike_helmet/frame_0004.jpg\n",
            "amazon/images/bike_helmet/frame_0005.jpg\n",
            "amazon/images/bike_helmet/frame_0006.jpg\n",
            "amazon/images/bike_helmet/frame_0007.jpg\n",
            "amazon/images/bike_helmet/frame_0008.jpg\n",
            "amazon/images/bike_helmet/frame_0009.jpg\n",
            "amazon/images/bike_helmet/frame_0010.jpg\n",
            "amazon/images/bike_helmet/frame_0011.jpg\n",
            "amazon/images/bike_helmet/frame_0012.jpg\n",
            "amazon/images/bike_helmet/frame_0013.jpg\n",
            "amazon/images/bike_helmet/frame_0014.jpg\n",
            "amazon/images/bike_helmet/frame_0015.jpg\n",
            "amazon/images/bike_helmet/frame_0016.jpg\n",
            "amazon/images/bike_helmet/frame_0017.jpg\n",
            "amazon/images/bike_helmet/frame_0018.jpg\n",
            "amazon/images/bike_helmet/frame_0019.jpg\n",
            "amazon/images/bike_helmet/frame_0020.jpg\n",
            "amazon/images/bike_helmet/frame_0021.jpg\n",
            "amazon/images/bike_helmet/frame_0022.jpg\n",
            "amazon/images/bike_helmet/frame_0023.jpg\n",
            "amazon/images/bike_helmet/frame_0024.jpg\n",
            "amazon/images/bike_helmet/frame_0025.jpg\n",
            "amazon/images/bike_helmet/frame_0026.jpg\n",
            "amazon/images/bike_helmet/frame_0027.jpg\n",
            "amazon/images/bike_helmet/frame_0028.jpg\n",
            "amazon/images/bike_helmet/frame_0029.jpg\n",
            "amazon/images/bike_helmet/frame_0030.jpg\n",
            "amazon/images/bike_helmet/frame_0031.jpg\n",
            "amazon/images/bike_helmet/frame_0032.jpg\n",
            "amazon/images/bike_helmet/frame_0033.jpg\n",
            "amazon/images/bike_helmet/frame_0034.jpg\n",
            "amazon/images/bike_helmet/frame_0035.jpg\n",
            "amazon/images/bike_helmet/frame_0036.jpg\n",
            "amazon/images/bike_helmet/frame_0037.jpg\n",
            "amazon/images/bike_helmet/frame_0038.jpg\n",
            "amazon/images/bike_helmet/frame_0039.jpg\n",
            "amazon/images/bike_helmet/frame_0040.jpg\n",
            "amazon/images/bike_helmet/frame_0041.jpg\n",
            "amazon/images/bike_helmet/frame_0042.jpg\n",
            "amazon/images/bike_helmet/frame_0043.jpg\n",
            "amazon/images/bike_helmet/frame_0044.jpg\n",
            "amazon/images/bike_helmet/frame_0045.jpg\n",
            "amazon/images/bike_helmet/frame_0046.jpg\n",
            "amazon/images/bike_helmet/frame_0047.jpg\n",
            "amazon/images/bike_helmet/frame_0048.jpg\n",
            "amazon/images/bike_helmet/frame_0049.jpg\n",
            "amazon/images/bike_helmet/frame_0050.jpg\n",
            "amazon/images/bike_helmet/frame_0051.jpg\n",
            "amazon/images/bike_helmet/frame_0052.jpg\n",
            "amazon/images/bike_helmet/frame_0053.jpg\n",
            "amazon/images/bike_helmet/frame_0054.jpg\n",
            "amazon/images/bike_helmet/frame_0055.jpg\n",
            "amazon/images/bike_helmet/frame_0056.jpg\n",
            "amazon/images/bike_helmet/frame_0057.jpg\n",
            "amazon/images/bike_helmet/frame_0058.jpg\n",
            "amazon/images/bike_helmet/frame_0059.jpg\n",
            "amazon/images/bike_helmet/frame_0060.jpg\n",
            "amazon/images/bike_helmet/frame_0061.jpg\n",
            "amazon/images/bike_helmet/frame_0062.jpg\n",
            "amazon/images/bike_helmet/frame_0063.jpg\n",
            "amazon/images/bike_helmet/frame_0064.jpg\n",
            "amazon/images/bike_helmet/frame_0065.jpg\n",
            "amazon/images/bike_helmet/frame_0066.jpg\n",
            "amazon/images/bike_helmet/frame_0067.jpg\n",
            "amazon/images/bike_helmet/frame_0068.jpg\n",
            "amazon/images/bike_helmet/frame_0069.jpg\n",
            "amazon/images/bike_helmet/frame_0070.jpg\n",
            "amazon/images/bike_helmet/frame_0071.jpg\n",
            "amazon/images/bike_helmet/frame_0072.jpg\n",
            "amazon/images/bookcase/frame_0001.jpg\n",
            "amazon/images/bookcase/frame_0002.jpg\n",
            "amazon/images/bookcase/frame_0003.jpg\n",
            "amazon/images/bookcase/frame_0004.jpg\n",
            "amazon/images/bookcase/frame_0005.jpg\n",
            "amazon/images/bookcase/frame_0006.jpg\n",
            "amazon/images/bookcase/frame_0007.jpg\n",
            "amazon/images/bookcase/frame_0008.jpg\n",
            "amazon/images/bookcase/frame_0009.jpg\n",
            "amazon/images/bookcase/frame_0010.jpg\n",
            "amazon/images/bookcase/frame_0011.jpg\n",
            "amazon/images/bookcase/frame_0012.jpg\n",
            "amazon/images/bookcase/frame_0013.jpg\n",
            "amazon/images/bookcase/frame_0014.jpg\n",
            "amazon/images/bookcase/frame_0015.jpg\n",
            "amazon/images/bookcase/frame_0016.jpg\n",
            "amazon/images/bookcase/frame_0017.jpg\n",
            "amazon/images/bookcase/frame_0018.jpg\n",
            "amazon/images/bookcase/frame_0019.jpg\n",
            "amazon/images/bookcase/frame_0020.jpg\n",
            "amazon/images/bookcase/frame_0021.jpg\n",
            "amazon/images/bookcase/frame_0022.jpg\n",
            "amazon/images/bookcase/frame_0023.jpg\n",
            "amazon/images/bookcase/frame_0024.jpg\n",
            "amazon/images/bookcase/frame_0025.jpg\n",
            "amazon/images/bookcase/frame_0026.jpg\n",
            "amazon/images/bookcase/frame_0027.jpg\n",
            "amazon/images/bookcase/frame_0028.jpg\n",
            "amazon/images/bookcase/frame_0029.jpg\n",
            "amazon/images/bookcase/frame_0030.jpg\n",
            "amazon/images/bookcase/frame_0031.jpg\n",
            "amazon/images/bookcase/frame_0032.jpg\n",
            "amazon/images/bookcase/frame_0033.jpg\n",
            "amazon/images/bookcase/frame_0034.jpg\n",
            "amazon/images/bookcase/frame_0035.jpg\n",
            "amazon/images/bookcase/frame_0036.jpg\n",
            "amazon/images/bookcase/frame_0037.jpg\n",
            "amazon/images/bookcase/frame_0038.jpg\n",
            "amazon/images/bookcase/frame_0039.jpg\n",
            "amazon/images/bookcase/frame_0040.jpg\n",
            "amazon/images/bookcase/frame_0041.jpg\n",
            "amazon/images/bookcase/frame_0042.jpg\n",
            "amazon/images/bookcase/frame_0043.jpg\n",
            "amazon/images/bookcase/frame_0044.jpg\n",
            "amazon/images/bookcase/frame_0045.jpg\n",
            "amazon/images/bookcase/frame_0046.jpg\n",
            "amazon/images/bookcase/frame_0047.jpg\n",
            "amazon/images/bookcase/frame_0048.jpg\n",
            "amazon/images/bookcase/frame_0049.jpg\n",
            "amazon/images/bookcase/frame_0050.jpg\n",
            "amazon/images/bookcase/frame_0051.jpg\n",
            "amazon/images/bookcase/frame_0052.jpg\n",
            "amazon/images/bookcase/frame_0053.jpg\n",
            "amazon/images/bookcase/frame_0054.jpg\n",
            "amazon/images/bookcase/frame_0055.jpg\n",
            "amazon/images/bookcase/frame_0056.jpg\n",
            "amazon/images/bookcase/frame_0057.jpg\n",
            "amazon/images/bookcase/frame_0058.jpg\n",
            "amazon/images/bookcase/frame_0059.jpg\n",
            "amazon/images/bookcase/frame_0060.jpg\n",
            "amazon/images/bookcase/frame_0061.jpg\n",
            "amazon/images/bookcase/frame_0062.jpg\n",
            "amazon/images/bookcase/frame_0063.jpg\n",
            "amazon/images/bookcase/frame_0064.jpg\n",
            "amazon/images/bookcase/frame_0065.jpg\n",
            "amazon/images/bookcase/frame_0066.jpg\n",
            "amazon/images/bookcase/frame_0067.jpg\n",
            "amazon/images/bookcase/frame_0068.jpg\n",
            "amazon/images/bookcase/frame_0069.jpg\n",
            "amazon/images/bookcase/frame_0070.jpg\n",
            "amazon/images/bookcase/frame_0071.jpg\n",
            "amazon/images/bookcase/frame_0072.jpg\n",
            "amazon/images/bookcase/frame_0073.jpg\n",
            "amazon/images/bookcase/frame_0074.jpg\n",
            "amazon/images/bookcase/frame_0075.jpg\n",
            "amazon/images/bookcase/frame_0076.jpg\n",
            "amazon/images/bookcase/frame_0077.jpg\n",
            "amazon/images/bookcase/frame_0078.jpg\n",
            "amazon/images/bookcase/frame_0079.jpg\n",
            "amazon/images/bookcase/frame_0080.jpg\n",
            "amazon/images/bookcase/frame_0081.jpg\n",
            "amazon/images/bookcase/frame_0082.jpg\n",
            "amazon/images/bottle/frame_0001.jpg\n",
            "amazon/images/bottle/frame_0002.jpg\n",
            "amazon/images/bottle/frame_0003.jpg\n",
            "amazon/images/bottle/frame_0004.jpg\n",
            "amazon/images/bottle/frame_0005.jpg\n",
            "amazon/images/bottle/frame_0006.jpg\n",
            "amazon/images/bottle/frame_0007.jpg\n",
            "amazon/images/bottle/frame_0008.jpg\n",
            "amazon/images/bottle/frame_0009.jpg\n",
            "amazon/images/bottle/frame_0010.jpg\n",
            "amazon/images/bottle/frame_0011.jpg\n",
            "amazon/images/bottle/frame_0012.jpg\n",
            "amazon/images/bottle/frame_0013.jpg\n",
            "amazon/images/bottle/frame_0014.jpg\n",
            "amazon/images/bottle/frame_0015.jpg\n",
            "amazon/images/bottle/frame_0016.jpg\n",
            "amazon/images/bottle/frame_0017.jpg\n",
            "amazon/images/bottle/frame_0018.jpg\n",
            "amazon/images/bottle/frame_0019.jpg\n",
            "amazon/images/bottle/frame_0020.jpg\n",
            "amazon/images/bottle/frame_0021.jpg\n",
            "amazon/images/bottle/frame_0022.jpg\n",
            "amazon/images/bottle/frame_0023.jpg\n",
            "amazon/images/bottle/frame_0024.jpg\n",
            "amazon/images/bottle/frame_0025.jpg\n",
            "amazon/images/bottle/frame_0026.jpg\n",
            "amazon/images/bottle/frame_0027.jpg\n",
            "amazon/images/bottle/frame_0028.jpg\n",
            "amazon/images/bottle/frame_0029.jpg\n",
            "amazon/images/bottle/frame_0030.jpg\n",
            "amazon/images/bottle/frame_0031.jpg\n",
            "amazon/images/bottle/frame_0032.jpg\n",
            "amazon/images/bottle/frame_0033.jpg\n",
            "amazon/images/bottle/frame_0034.jpg\n",
            "amazon/images/bottle/frame_0035.jpg\n",
            "amazon/images/bottle/frame_0036.jpg\n",
            "amazon/images/calculator/frame_0001.jpg\n",
            "amazon/images/calculator/frame_0002.jpg\n",
            "amazon/images/calculator/frame_0003.jpg\n",
            "amazon/images/calculator/frame_0004.jpg\n",
            "amazon/images/calculator/frame_0005.jpg\n",
            "amazon/images/calculator/frame_0006.jpg\n",
            "amazon/images/calculator/frame_0007.jpg\n",
            "amazon/images/calculator/frame_0008.jpg\n",
            "amazon/images/calculator/frame_0009.jpg\n",
            "amazon/images/calculator/frame_0010.jpg\n",
            "amazon/images/calculator/frame_0011.jpg\n",
            "amazon/images/calculator/frame_0012.jpg\n",
            "amazon/images/calculator/frame_0013.jpg\n",
            "amazon/images/calculator/frame_0014.jpg\n",
            "amazon/images/calculator/frame_0015.jpg\n",
            "amazon/images/calculator/frame_0016.jpg\n",
            "amazon/images/calculator/frame_0017.jpg\n",
            "amazon/images/calculator/frame_0018.jpg\n",
            "amazon/images/calculator/frame_0019.jpg\n",
            "amazon/images/calculator/frame_0020.jpg\n",
            "amazon/images/calculator/frame_0021.jpg\n",
            "amazon/images/calculator/frame_0022.jpg\n",
            "amazon/images/calculator/frame_0023.jpg\n",
            "amazon/images/calculator/frame_0024.jpg\n",
            "amazon/images/calculator/frame_0025.jpg\n",
            "amazon/images/calculator/frame_0026.jpg\n",
            "amazon/images/calculator/frame_0027.jpg\n",
            "amazon/images/calculator/frame_0028.jpg\n",
            "amazon/images/calculator/frame_0029.jpg\n",
            "amazon/images/calculator/frame_0030.jpg\n",
            "amazon/images/calculator/frame_0031.jpg\n",
            "amazon/images/calculator/frame_0032.jpg\n",
            "amazon/images/calculator/frame_0033.jpg\n",
            "amazon/images/calculator/frame_0034.jpg\n",
            "amazon/images/calculator/frame_0035.jpg\n",
            "amazon/images/calculator/frame_0036.jpg\n",
            "amazon/images/calculator/frame_0037.jpg\n",
            "amazon/images/calculator/frame_0038.jpg\n",
            "amazon/images/calculator/frame_0039.jpg\n",
            "amazon/images/calculator/frame_0040.jpg\n",
            "amazon/images/calculator/frame_0041.jpg\n",
            "amazon/images/calculator/frame_0042.jpg\n",
            "amazon/images/calculator/frame_0043.jpg\n",
            "amazon/images/calculator/frame_0044.jpg\n",
            "amazon/images/calculator/frame_0045.jpg\n",
            "amazon/images/calculator/frame_0046.jpg\n",
            "amazon/images/calculator/frame_0047.jpg\n",
            "amazon/images/calculator/frame_0048.jpg\n",
            "amazon/images/calculator/frame_0049.jpg\n",
            "amazon/images/calculator/frame_0050.jpg\n",
            "amazon/images/calculator/frame_0051.jpg\n",
            "amazon/images/calculator/frame_0052.jpg\n",
            "amazon/images/calculator/frame_0053.jpg\n",
            "amazon/images/calculator/frame_0054.jpg\n",
            "amazon/images/calculator/frame_0055.jpg\n",
            "amazon/images/calculator/frame_0056.jpg\n",
            "amazon/images/calculator/frame_0057.jpg\n",
            "amazon/images/calculator/frame_0058.jpg\n",
            "amazon/images/calculator/frame_0059.jpg\n",
            "amazon/images/calculator/frame_0060.jpg\n",
            "amazon/images/calculator/frame_0061.jpg\n",
            "amazon/images/calculator/frame_0062.jpg\n",
            "amazon/images/calculator/frame_0063.jpg\n",
            "amazon/images/calculator/frame_0064.jpg\n",
            "amazon/images/calculator/frame_0065.jpg\n",
            "amazon/images/calculator/frame_0066.jpg\n",
            "amazon/images/calculator/frame_0067.jpg\n",
            "amazon/images/calculator/frame_0068.jpg\n",
            "amazon/images/calculator/frame_0069.jpg\n",
            "amazon/images/calculator/frame_0070.jpg\n",
            "amazon/images/calculator/frame_0071.jpg\n",
            "amazon/images/calculator/frame_0072.jpg\n",
            "amazon/images/calculator/frame_0073.jpg\n",
            "amazon/images/calculator/frame_0074.jpg\n",
            "amazon/images/calculator/frame_0075.jpg\n",
            "amazon/images/calculator/frame_0076.jpg\n",
            "amazon/images/calculator/frame_0077.jpg\n",
            "amazon/images/calculator/frame_0078.jpg\n",
            "amazon/images/calculator/frame_0079.jpg\n",
            "amazon/images/calculator/frame_0080.jpg\n",
            "amazon/images/calculator/frame_0081.jpg\n",
            "amazon/images/calculator/frame_0082.jpg\n",
            "amazon/images/calculator/frame_0083.jpg\n",
            "amazon/images/calculator/frame_0084.jpg\n",
            "amazon/images/calculator/frame_0085.jpg\n",
            "amazon/images/calculator/frame_0086.jpg\n",
            "amazon/images/calculator/frame_0087.jpg\n",
            "amazon/images/calculator/frame_0088.jpg\n",
            "amazon/images/calculator/frame_0089.jpg\n",
            "amazon/images/calculator/frame_0090.jpg\n",
            "amazon/images/calculator/frame_0091.jpg\n",
            "amazon/images/calculator/frame_0092.jpg\n",
            "amazon/images/calculator/frame_0093.jpg\n",
            "amazon/images/calculator/frame_0094.jpg\n",
            "amazon/images/desk_chair/frame_0001.jpg\n",
            "amazon/images/desk_chair/frame_0002.jpg\n",
            "amazon/images/desk_chair/frame_0003.jpg\n",
            "amazon/images/desk_chair/frame_0004.jpg\n",
            "amazon/images/desk_chair/frame_0005.jpg\n",
            "amazon/images/desk_chair/frame_0006.jpg\n",
            "amazon/images/desk_chair/frame_0007.jpg\n",
            "amazon/images/desk_chair/frame_0008.jpg\n",
            "amazon/images/desk_chair/frame_0009.jpg\n",
            "amazon/images/desk_chair/frame_0010.jpg\n",
            "amazon/images/desk_chair/frame_0011.jpg\n",
            "amazon/images/desk_chair/frame_0012.jpg\n",
            "amazon/images/desk_chair/frame_0013.jpg\n",
            "amazon/images/desk_chair/frame_0014.jpg\n",
            "amazon/images/desk_chair/frame_0015.jpg\n",
            "amazon/images/desk_chair/frame_0016.jpg\n",
            "amazon/images/desk_chair/frame_0017.jpg\n",
            "amazon/images/desk_chair/frame_0018.jpg\n",
            "amazon/images/desk_chair/frame_0019.jpg\n",
            "amazon/images/desk_chair/frame_0020.jpg\n",
            "amazon/images/desk_chair/frame_0021.jpg\n",
            "amazon/images/desk_chair/frame_0022.jpg\n",
            "amazon/images/desk_chair/frame_0023.jpg\n",
            "amazon/images/desk_chair/frame_0024.jpg\n",
            "amazon/images/desk_chair/frame_0025.jpg\n",
            "amazon/images/desk_chair/frame_0026.jpg\n",
            "amazon/images/desk_chair/frame_0027.jpg\n",
            "amazon/images/desk_chair/frame_0028.jpg\n",
            "amazon/images/desk_chair/frame_0029.jpg\n",
            "amazon/images/desk_chair/frame_0030.jpg\n",
            "amazon/images/desk_chair/frame_0031.jpg\n",
            "amazon/images/desk_chair/frame_0032.jpg\n",
            "amazon/images/desk_chair/frame_0033.jpg\n",
            "amazon/images/desk_chair/frame_0034.jpg\n",
            "amazon/images/desk_chair/frame_0035.jpg\n",
            "amazon/images/desk_chair/frame_0036.jpg\n",
            "amazon/images/desk_chair/frame_0037.jpg\n",
            "amazon/images/desk_chair/frame_0038.jpg\n",
            "amazon/images/desk_chair/frame_0039.jpg\n",
            "amazon/images/desk_chair/frame_0040.jpg\n",
            "amazon/images/desk_chair/frame_0041.jpg\n",
            "amazon/images/desk_chair/frame_0042.jpg\n",
            "amazon/images/desk_chair/frame_0043.jpg\n",
            "amazon/images/desk_chair/frame_0044.jpg\n",
            "amazon/images/desk_chair/frame_0045.jpg\n",
            "amazon/images/desk_chair/frame_0046.jpg\n",
            "amazon/images/desk_chair/frame_0047.jpg\n",
            "amazon/images/desk_chair/frame_0048.jpg\n",
            "amazon/images/desk_chair/frame_0049.jpg\n",
            "amazon/images/desk_chair/frame_0050.jpg\n",
            "amazon/images/desk_chair/frame_0051.jpg\n",
            "amazon/images/desk_chair/frame_0052.jpg\n",
            "amazon/images/desk_chair/frame_0053.jpg\n",
            "amazon/images/desk_chair/frame_0054.jpg\n",
            "amazon/images/desk_chair/frame_0055.jpg\n",
            "amazon/images/desk_chair/frame_0056.jpg\n",
            "amazon/images/desk_chair/frame_0057.jpg\n",
            "amazon/images/desk_chair/frame_0058.jpg\n",
            "amazon/images/desk_chair/frame_0059.jpg\n",
            "amazon/images/desk_chair/frame_0060.jpg\n",
            "amazon/images/desk_chair/frame_0061.jpg\n",
            "amazon/images/desk_chair/frame_0062.jpg\n",
            "amazon/images/desk_chair/frame_0063.jpg\n",
            "amazon/images/desk_chair/frame_0064.jpg\n",
            "amazon/images/desk_chair/frame_0065.jpg\n",
            "amazon/images/desk_chair/frame_0066.jpg\n",
            "amazon/images/desk_chair/frame_0067.jpg\n",
            "amazon/images/desk_chair/frame_0068.jpg\n",
            "amazon/images/desk_chair/frame_0069.jpg\n",
            "amazon/images/desk_chair/frame_0070.jpg\n",
            "amazon/images/desk_chair/frame_0071.jpg\n",
            "amazon/images/desk_chair/frame_0072.jpg\n",
            "amazon/images/desk_chair/frame_0073.jpg\n",
            "amazon/images/desk_chair/frame_0074.jpg\n",
            "amazon/images/desk_chair/frame_0075.jpg\n",
            "amazon/images/desk_chair/frame_0076.jpg\n",
            "amazon/images/desk_chair/frame_0077.jpg\n",
            "amazon/images/desk_chair/frame_0078.jpg\n",
            "amazon/images/desk_chair/frame_0079.jpg\n",
            "amazon/images/desk_chair/frame_0080.jpg\n",
            "amazon/images/desk_chair/frame_0081.jpg\n",
            "amazon/images/desk_chair/frame_0082.jpg\n",
            "amazon/images/desk_chair/frame_0083.jpg\n",
            "amazon/images/desk_chair/frame_0084.jpg\n",
            "amazon/images/desk_chair/frame_0085.jpg\n",
            "amazon/images/desk_chair/frame_0086.jpg\n",
            "amazon/images/desk_chair/frame_0087.jpg\n",
            "amazon/images/desk_chair/frame_0088.jpg\n",
            "amazon/images/desk_chair/frame_0089.jpg\n",
            "amazon/images/desk_chair/frame_0090.jpg\n",
            "amazon/images/desk_chair/frame_0091.jpg\n",
            "amazon/images/desk_lamp/frame_0001.jpg\n",
            "amazon/images/desk_lamp/frame_0002.jpg\n",
            "amazon/images/desk_lamp/frame_0003.jpg\n",
            "amazon/images/desk_lamp/frame_0004.jpg\n",
            "amazon/images/desk_lamp/frame_0005.jpg\n",
            "amazon/images/desk_lamp/frame_0006.jpg\n",
            "amazon/images/desk_lamp/frame_0007.jpg\n",
            "amazon/images/desk_lamp/frame_0008.jpg\n",
            "amazon/images/desk_lamp/frame_0009.jpg\n",
            "amazon/images/desk_lamp/frame_0010.jpg\n",
            "amazon/images/desk_lamp/frame_0011.jpg\n",
            "amazon/images/desk_lamp/frame_0012.jpg\n",
            "amazon/images/desk_lamp/frame_0013.jpg\n",
            "amazon/images/desk_lamp/frame_0014.jpg\n",
            "amazon/images/desk_lamp/frame_0015.jpg\n",
            "amazon/images/desk_lamp/frame_0016.jpg\n",
            "amazon/images/desk_lamp/frame_0017.jpg\n",
            "amazon/images/desk_lamp/frame_0018.jpg\n",
            "amazon/images/desk_lamp/frame_0019.jpg\n",
            "amazon/images/desk_lamp/frame_0020.jpg\n",
            "amazon/images/desk_lamp/frame_0021.jpg\n",
            "amazon/images/desk_lamp/frame_0022.jpg\n",
            "amazon/images/desk_lamp/frame_0023.jpg\n",
            "amazon/images/desk_lamp/frame_0024.jpg\n",
            "amazon/images/desk_lamp/frame_0025.jpg\n",
            "amazon/images/desk_lamp/frame_0026.jpg\n",
            "amazon/images/desk_lamp/frame_0027.jpg\n",
            "amazon/images/desk_lamp/frame_0028.jpg\n",
            "amazon/images/desk_lamp/frame_0029.jpg\n",
            "amazon/images/desk_lamp/frame_0030.jpg\n",
            "amazon/images/desk_lamp/frame_0031.jpg\n",
            "amazon/images/desk_lamp/frame_0032.jpg\n",
            "amazon/images/desk_lamp/frame_0033.jpg\n",
            "amazon/images/desk_lamp/frame_0034.jpg\n",
            "amazon/images/desk_lamp/frame_0035.jpg\n",
            "amazon/images/desk_lamp/frame_0036.jpg\n",
            "amazon/images/desk_lamp/frame_0037.jpg\n",
            "amazon/images/desk_lamp/frame_0038.jpg\n",
            "amazon/images/desk_lamp/frame_0039.jpg\n",
            "amazon/images/desk_lamp/frame_0040.jpg\n",
            "amazon/images/desk_lamp/frame_0041.jpg\n",
            "amazon/images/desk_lamp/frame_0042.jpg\n",
            "amazon/images/desk_lamp/frame_0043.jpg\n",
            "amazon/images/desk_lamp/frame_0044.jpg\n",
            "amazon/images/desk_lamp/frame_0045.jpg\n",
            "amazon/images/desk_lamp/frame_0046.jpg\n",
            "amazon/images/desk_lamp/frame_0047.jpg\n",
            "amazon/images/desk_lamp/frame_0048.jpg\n",
            "amazon/images/desk_lamp/frame_0049.jpg\n",
            "amazon/images/desk_lamp/frame_0050.jpg\n",
            "amazon/images/desk_lamp/frame_0051.jpg\n",
            "amazon/images/desk_lamp/frame_0052.jpg\n",
            "amazon/images/desk_lamp/frame_0053.jpg\n",
            "amazon/images/desk_lamp/frame_0054.jpg\n",
            "amazon/images/desk_lamp/frame_0055.jpg\n",
            "amazon/images/desk_lamp/frame_0056.jpg\n",
            "amazon/images/desk_lamp/frame_0057.jpg\n",
            "amazon/images/desk_lamp/frame_0058.jpg\n",
            "amazon/images/desk_lamp/frame_0059.jpg\n",
            "amazon/images/desk_lamp/frame_0060.jpg\n",
            "amazon/images/desk_lamp/frame_0061.jpg\n",
            "amazon/images/desk_lamp/frame_0062.jpg\n",
            "amazon/images/desk_lamp/frame_0063.jpg\n",
            "amazon/images/desk_lamp/frame_0064.jpg\n",
            "amazon/images/desk_lamp/frame_0065.jpg\n",
            "amazon/images/desk_lamp/frame_0066.jpg\n",
            "amazon/images/desk_lamp/frame_0067.jpg\n",
            "amazon/images/desk_lamp/frame_0068.jpg\n",
            "amazon/images/desk_lamp/frame_0069.jpg\n",
            "amazon/images/desk_lamp/frame_0070.jpg\n",
            "amazon/images/desk_lamp/frame_0071.jpg\n",
            "amazon/images/desk_lamp/frame_0072.jpg\n",
            "amazon/images/desk_lamp/frame_0073.jpg\n",
            "amazon/images/desk_lamp/frame_0074.jpg\n",
            "amazon/images/desk_lamp/frame_0075.jpg\n",
            "amazon/images/desk_lamp/frame_0076.jpg\n",
            "amazon/images/desk_lamp/frame_0077.jpg\n",
            "amazon/images/desk_lamp/frame_0078.jpg\n",
            "amazon/images/desk_lamp/frame_0079.jpg\n",
            "amazon/images/desk_lamp/frame_0080.jpg\n",
            "amazon/images/desk_lamp/frame_0081.jpg\n",
            "amazon/images/desk_lamp/frame_0082.jpg\n",
            "amazon/images/desk_lamp/frame_0083.jpg\n",
            "amazon/images/desk_lamp/frame_0084.jpg\n",
            "amazon/images/desk_lamp/frame_0085.jpg\n",
            "amazon/images/desk_lamp/frame_0086.jpg\n",
            "amazon/images/desk_lamp/frame_0087.jpg\n",
            "amazon/images/desk_lamp/frame_0088.jpg\n",
            "amazon/images/desk_lamp/frame_0089.jpg\n",
            "amazon/images/desk_lamp/frame_0090.jpg\n",
            "amazon/images/desk_lamp/frame_0091.jpg\n",
            "amazon/images/desk_lamp/frame_0092.jpg\n",
            "amazon/images/desk_lamp/frame_0093.jpg\n",
            "amazon/images/desk_lamp/frame_0094.jpg\n",
            "amazon/images/desk_lamp/frame_0095.jpg\n",
            "amazon/images/desk_lamp/frame_0096.jpg\n",
            "amazon/images/desk_lamp/frame_0097.jpg\n",
            "amazon/images/desktop_computer/frame_0001.jpg\n",
            "amazon/images/desktop_computer/frame_0002.jpg\n",
            "amazon/images/desktop_computer/frame_0003.jpg\n",
            "amazon/images/desktop_computer/frame_0004.jpg\n",
            "amazon/images/desktop_computer/frame_0005.jpg\n",
            "amazon/images/desktop_computer/frame_0006.jpg\n",
            "amazon/images/desktop_computer/frame_0007.jpg\n",
            "amazon/images/desktop_computer/frame_0008.jpg\n",
            "amazon/images/desktop_computer/frame_0009.jpg\n",
            "amazon/images/desktop_computer/frame_0010.jpg\n",
            "amazon/images/desktop_computer/frame_0011.jpg\n",
            "amazon/images/desktop_computer/frame_0012.jpg\n",
            "amazon/images/desktop_computer/frame_0013.jpg\n",
            "amazon/images/desktop_computer/frame_0014.jpg\n",
            "amazon/images/desktop_computer/frame_0015.jpg\n",
            "amazon/images/desktop_computer/frame_0016.jpg\n",
            "amazon/images/desktop_computer/frame_0017.jpg\n",
            "amazon/images/desktop_computer/frame_0018.jpg\n",
            "amazon/images/desktop_computer/frame_0019.jpg\n",
            "amazon/images/desktop_computer/frame_0020.jpg\n",
            "amazon/images/desktop_computer/frame_0021.jpg\n",
            "amazon/images/desktop_computer/frame_0022.jpg\n",
            "amazon/images/desktop_computer/frame_0023.jpg\n",
            "amazon/images/desktop_computer/frame_0024.jpg\n",
            "amazon/images/desktop_computer/frame_0025.jpg\n",
            "amazon/images/desktop_computer/frame_0026.jpg\n",
            "amazon/images/desktop_computer/frame_0027.jpg\n",
            "amazon/images/desktop_computer/frame_0028.jpg\n",
            "amazon/images/desktop_computer/frame_0029.jpg\n",
            "amazon/images/desktop_computer/frame_0030.jpg\n",
            "amazon/images/desktop_computer/frame_0031.jpg\n",
            "amazon/images/desktop_computer/frame_0032.jpg\n",
            "amazon/images/desktop_computer/frame_0033.jpg\n",
            "amazon/images/desktop_computer/frame_0034.jpg\n",
            "amazon/images/desktop_computer/frame_0035.jpg\n",
            "amazon/images/desktop_computer/frame_0036.jpg\n",
            "amazon/images/desktop_computer/frame_0037.jpg\n",
            "amazon/images/desktop_computer/frame_0038.jpg\n",
            "amazon/images/desktop_computer/frame_0039.jpg\n",
            "amazon/images/desktop_computer/frame_0040.jpg\n",
            "amazon/images/desktop_computer/frame_0041.jpg\n",
            "amazon/images/desktop_computer/frame_0042.jpg\n",
            "amazon/images/desktop_computer/frame_0043.jpg\n",
            "amazon/images/desktop_computer/frame_0044.jpg\n",
            "amazon/images/desktop_computer/frame_0045.jpg\n",
            "amazon/images/desktop_computer/frame_0046.jpg\n",
            "amazon/images/desktop_computer/frame_0047.jpg\n",
            "amazon/images/desktop_computer/frame_0048.jpg\n",
            "amazon/images/desktop_computer/frame_0049.jpg\n",
            "amazon/images/desktop_computer/frame_0050.jpg\n",
            "amazon/images/desktop_computer/frame_0051.jpg\n",
            "amazon/images/desktop_computer/frame_0052.jpg\n",
            "amazon/images/desktop_computer/frame_0053.jpg\n",
            "amazon/images/desktop_computer/frame_0054.jpg\n",
            "amazon/images/desktop_computer/frame_0055.jpg\n",
            "amazon/images/desktop_computer/frame_0056.jpg\n",
            "amazon/images/desktop_computer/frame_0057.jpg\n",
            "amazon/images/desktop_computer/frame_0058.jpg\n",
            "amazon/images/desktop_computer/frame_0059.jpg\n",
            "amazon/images/desktop_computer/frame_0060.jpg\n",
            "amazon/images/desktop_computer/frame_0061.jpg\n",
            "amazon/images/desktop_computer/frame_0062.jpg\n",
            "amazon/images/desktop_computer/frame_0063.jpg\n",
            "amazon/images/desktop_computer/frame_0064.jpg\n",
            "amazon/images/desktop_computer/frame_0065.jpg\n",
            "amazon/images/desktop_computer/frame_0066.jpg\n",
            "amazon/images/desktop_computer/frame_0067.jpg\n",
            "amazon/images/desktop_computer/frame_0068.jpg\n",
            "amazon/images/desktop_computer/frame_0069.jpg\n",
            "amazon/images/desktop_computer/frame_0070.jpg\n",
            "amazon/images/desktop_computer/frame_0071.jpg\n",
            "amazon/images/desktop_computer/frame_0072.jpg\n",
            "amazon/images/desktop_computer/frame_0073.jpg\n",
            "amazon/images/desktop_computer/frame_0074.jpg\n",
            "amazon/images/desktop_computer/frame_0075.jpg\n",
            "amazon/images/desktop_computer/frame_0076.jpg\n",
            "amazon/images/desktop_computer/frame_0077.jpg\n",
            "amazon/images/desktop_computer/frame_0078.jpg\n",
            "amazon/images/desktop_computer/frame_0079.jpg\n",
            "amazon/images/desktop_computer/frame_0080.jpg\n",
            "amazon/images/desktop_computer/frame_0081.jpg\n",
            "amazon/images/desktop_computer/frame_0082.jpg\n",
            "amazon/images/desktop_computer/frame_0083.jpg\n",
            "amazon/images/desktop_computer/frame_0084.jpg\n",
            "amazon/images/desktop_computer/frame_0085.jpg\n",
            "amazon/images/desktop_computer/frame_0086.jpg\n",
            "amazon/images/desktop_computer/frame_0087.jpg\n",
            "amazon/images/desktop_computer/frame_0088.jpg\n",
            "amazon/images/desktop_computer/frame_0089.jpg\n",
            "amazon/images/desktop_computer/frame_0090.jpg\n",
            "amazon/images/desktop_computer/frame_0091.jpg\n",
            "amazon/images/desktop_computer/frame_0092.jpg\n",
            "amazon/images/desktop_computer/frame_0093.jpg\n",
            "amazon/images/desktop_computer/frame_0094.jpg\n",
            "amazon/images/desktop_computer/frame_0095.jpg\n",
            "amazon/images/desktop_computer/frame_0096.jpg\n",
            "amazon/images/desktop_computer/frame_0097.jpg\n",
            "amazon/images/file_cabinet/frame_0001.jpg\n",
            "amazon/images/file_cabinet/frame_0002.jpg\n",
            "amazon/images/file_cabinet/frame_0003.jpg\n",
            "amazon/images/file_cabinet/frame_0004.jpg\n",
            "amazon/images/file_cabinet/frame_0005.jpg\n",
            "amazon/images/file_cabinet/frame_0006.jpg\n",
            "amazon/images/file_cabinet/frame_0007.jpg\n",
            "amazon/images/file_cabinet/frame_0008.jpg\n",
            "amazon/images/file_cabinet/frame_0009.jpg\n",
            "amazon/images/file_cabinet/frame_0010.jpg\n",
            "amazon/images/file_cabinet/frame_0011.jpg\n",
            "amazon/images/file_cabinet/frame_0012.jpg\n",
            "amazon/images/file_cabinet/frame_0013.jpg\n",
            "amazon/images/file_cabinet/frame_0014.jpg\n",
            "amazon/images/file_cabinet/frame_0015.jpg\n",
            "amazon/images/file_cabinet/frame_0016.jpg\n",
            "amazon/images/file_cabinet/frame_0017.jpg\n",
            "amazon/images/file_cabinet/frame_0018.jpg\n",
            "amazon/images/file_cabinet/frame_0019.jpg\n",
            "amazon/images/file_cabinet/frame_0020.jpg\n",
            "amazon/images/file_cabinet/frame_0021.jpg\n",
            "amazon/images/file_cabinet/frame_0022.jpg\n",
            "amazon/images/file_cabinet/frame_0023.jpg\n",
            "amazon/images/file_cabinet/frame_0024.jpg\n",
            "amazon/images/file_cabinet/frame_0025.jpg\n",
            "amazon/images/file_cabinet/frame_0026.jpg\n",
            "amazon/images/file_cabinet/frame_0027.jpg\n",
            "amazon/images/file_cabinet/frame_0028.jpg\n",
            "amazon/images/file_cabinet/frame_0029.jpg\n",
            "amazon/images/file_cabinet/frame_0030.jpg\n",
            "amazon/images/file_cabinet/frame_0031.jpg\n",
            "amazon/images/file_cabinet/frame_0032.jpg\n",
            "amazon/images/file_cabinet/frame_0033.jpg\n",
            "amazon/images/file_cabinet/frame_0034.jpg\n",
            "amazon/images/file_cabinet/frame_0035.jpg\n",
            "amazon/images/file_cabinet/frame_0036.jpg\n",
            "amazon/images/file_cabinet/frame_0037.jpg\n",
            "amazon/images/file_cabinet/frame_0038.jpg\n",
            "amazon/images/file_cabinet/frame_0039.jpg\n",
            "amazon/images/file_cabinet/frame_0040.jpg\n",
            "amazon/images/file_cabinet/frame_0041.jpg\n",
            "amazon/images/file_cabinet/frame_0042.jpg\n",
            "amazon/images/file_cabinet/frame_0043.jpg\n",
            "amazon/images/file_cabinet/frame_0044.jpg\n",
            "amazon/images/file_cabinet/frame_0045.jpg\n",
            "amazon/images/file_cabinet/frame_0046.jpg\n",
            "amazon/images/file_cabinet/frame_0047.jpg\n",
            "amazon/images/file_cabinet/frame_0048.jpg\n",
            "amazon/images/file_cabinet/frame_0049.jpg\n",
            "amazon/images/file_cabinet/frame_0050.jpg\n",
            "amazon/images/file_cabinet/frame_0051.jpg\n",
            "amazon/images/file_cabinet/frame_0052.jpg\n",
            "amazon/images/file_cabinet/frame_0053.jpg\n",
            "amazon/images/file_cabinet/frame_0054.jpg\n",
            "amazon/images/file_cabinet/frame_0055.jpg\n",
            "amazon/images/file_cabinet/frame_0056.jpg\n",
            "amazon/images/file_cabinet/frame_0057.jpg\n",
            "amazon/images/file_cabinet/frame_0058.jpg\n",
            "amazon/images/file_cabinet/frame_0059.jpg\n",
            "amazon/images/file_cabinet/frame_0060.jpg\n",
            "amazon/images/file_cabinet/frame_0061.jpg\n",
            "amazon/images/file_cabinet/frame_0062.jpg\n",
            "amazon/images/file_cabinet/frame_0063.jpg\n",
            "amazon/images/file_cabinet/frame_0064.jpg\n",
            "amazon/images/file_cabinet/frame_0065.jpg\n",
            "amazon/images/file_cabinet/frame_0066.jpg\n",
            "amazon/images/file_cabinet/frame_0067.jpg\n",
            "amazon/images/file_cabinet/frame_0068.jpg\n",
            "amazon/images/file_cabinet/frame_0069.jpg\n",
            "amazon/images/file_cabinet/frame_0070.jpg\n",
            "amazon/images/file_cabinet/frame_0071.jpg\n",
            "amazon/images/file_cabinet/frame_0072.jpg\n",
            "amazon/images/file_cabinet/frame_0073.jpg\n",
            "amazon/images/file_cabinet/frame_0074.jpg\n",
            "amazon/images/file_cabinet/frame_0075.jpg\n",
            "amazon/images/file_cabinet/frame_0076.jpg\n",
            "amazon/images/file_cabinet/frame_0077.jpg\n",
            "amazon/images/file_cabinet/frame_0078.jpg\n",
            "amazon/images/file_cabinet/frame_0079.jpg\n",
            "amazon/images/file_cabinet/frame_0080.jpg\n",
            "amazon/images/file_cabinet/frame_0081.jpg\n",
            "amazon/images/headphones/frame_0001.jpg\n",
            "amazon/images/headphones/frame_0002.jpg\n",
            "amazon/images/headphones/frame_0003.jpg\n",
            "amazon/images/headphones/frame_0004.jpg\n",
            "amazon/images/headphones/frame_0005.jpg\n",
            "amazon/images/headphones/frame_0006.jpg\n",
            "amazon/images/headphones/frame_0007.jpg\n",
            "amazon/images/headphones/frame_0008.jpg\n",
            "amazon/images/headphones/frame_0009.jpg\n",
            "amazon/images/headphones/frame_0010.jpg\n",
            "amazon/images/headphones/frame_0011.jpg\n",
            "amazon/images/headphones/frame_0012.jpg\n",
            "amazon/images/headphones/frame_0013.jpg\n",
            "amazon/images/headphones/frame_0014.jpg\n",
            "amazon/images/headphones/frame_0015.jpg\n",
            "amazon/images/headphones/frame_0016.jpg\n",
            "amazon/images/headphones/frame_0017.jpg\n",
            "amazon/images/headphones/frame_0018.jpg\n",
            "amazon/images/headphones/frame_0019.jpg\n",
            "amazon/images/headphones/frame_0020.jpg\n",
            "amazon/images/headphones/frame_0021.jpg\n",
            "amazon/images/headphones/frame_0022.jpg\n",
            "amazon/images/headphones/frame_0023.jpg\n",
            "amazon/images/headphones/frame_0024.jpg\n",
            "amazon/images/headphones/frame_0025.jpg\n",
            "amazon/images/headphones/frame_0026.jpg\n",
            "amazon/images/headphones/frame_0027.jpg\n",
            "amazon/images/headphones/frame_0028.jpg\n",
            "amazon/images/headphones/frame_0029.jpg\n",
            "amazon/images/headphones/frame_0030.jpg\n",
            "amazon/images/headphones/frame_0031.jpg\n",
            "amazon/images/headphones/frame_0032.jpg\n",
            "amazon/images/headphones/frame_0033.jpg\n",
            "amazon/images/headphones/frame_0034.jpg\n",
            "amazon/images/headphones/frame_0035.jpg\n",
            "amazon/images/headphones/frame_0036.jpg\n",
            "amazon/images/headphones/frame_0037.jpg\n",
            "amazon/images/headphones/frame_0038.jpg\n",
            "amazon/images/headphones/frame_0039.jpg\n",
            "amazon/images/headphones/frame_0040.jpg\n",
            "amazon/images/headphones/frame_0041.jpg\n",
            "amazon/images/headphones/frame_0042.jpg\n",
            "amazon/images/headphones/frame_0043.jpg\n",
            "amazon/images/headphones/frame_0044.jpg\n",
            "amazon/images/headphones/frame_0045.jpg\n",
            "amazon/images/headphones/frame_0046.jpg\n",
            "amazon/images/headphones/frame_0047.jpg\n",
            "amazon/images/headphones/frame_0048.jpg\n",
            "amazon/images/headphones/frame_0049.jpg\n",
            "amazon/images/headphones/frame_0050.jpg\n",
            "amazon/images/headphones/frame_0051.jpg\n",
            "amazon/images/headphones/frame_0052.jpg\n",
            "amazon/images/headphones/frame_0053.jpg\n",
            "amazon/images/headphones/frame_0054.jpg\n",
            "amazon/images/headphones/frame_0055.jpg\n",
            "amazon/images/headphones/frame_0056.jpg\n",
            "amazon/images/headphones/frame_0057.jpg\n",
            "amazon/images/headphones/frame_0058.jpg\n",
            "amazon/images/headphones/frame_0059.jpg\n",
            "amazon/images/headphones/frame_0060.jpg\n",
            "amazon/images/headphones/frame_0061.jpg\n",
            "amazon/images/headphones/frame_0062.jpg\n",
            "amazon/images/headphones/frame_0063.jpg\n",
            "amazon/images/headphones/frame_0064.jpg\n",
            "amazon/images/headphones/frame_0065.jpg\n",
            "amazon/images/headphones/frame_0066.jpg\n",
            "amazon/images/headphones/frame_0067.jpg\n",
            "amazon/images/headphones/frame_0068.jpg\n",
            "amazon/images/headphones/frame_0069.jpg\n",
            "amazon/images/headphones/frame_0070.jpg\n",
            "amazon/images/headphones/frame_0071.jpg\n",
            "amazon/images/headphones/frame_0072.jpg\n",
            "amazon/images/headphones/frame_0073.jpg\n",
            "amazon/images/headphones/frame_0074.jpg\n",
            "amazon/images/headphones/frame_0075.jpg\n",
            "amazon/images/headphones/frame_0076.jpg\n",
            "amazon/images/headphones/frame_0077.jpg\n",
            "amazon/images/headphones/frame_0078.jpg\n",
            "amazon/images/headphones/frame_0079.jpg\n",
            "amazon/images/headphones/frame_0080.jpg\n",
            "amazon/images/headphones/frame_0081.jpg\n",
            "amazon/images/headphones/frame_0082.jpg\n",
            "amazon/images/headphones/frame_0083.jpg\n",
            "amazon/images/headphones/frame_0084.jpg\n",
            "amazon/images/headphones/frame_0085.jpg\n",
            "amazon/images/headphones/frame_0086.jpg\n",
            "amazon/images/headphones/frame_0087.jpg\n",
            "amazon/images/headphones/frame_0088.jpg\n",
            "amazon/images/headphones/frame_0089.jpg\n",
            "amazon/images/headphones/frame_0090.jpg\n",
            "amazon/images/headphones/frame_0091.jpg\n",
            "amazon/images/headphones/frame_0092.jpg\n",
            "amazon/images/headphones/frame_0093.jpg\n",
            "amazon/images/headphones/frame_0094.jpg\n",
            "amazon/images/headphones/frame_0095.jpg\n",
            "amazon/images/headphones/frame_0096.jpg\n",
            "amazon/images/headphones/frame_0097.jpg\n",
            "amazon/images/headphones/frame_0098.jpg\n",
            "amazon/images/headphones/frame_0099.jpg\n",
            "amazon/images/keyboard/frame_0001.jpg\n",
            "amazon/images/keyboard/frame_0002.jpg\n",
            "amazon/images/keyboard/frame_0003.jpg\n",
            "amazon/images/keyboard/frame_0004.jpg\n",
            "amazon/images/keyboard/frame_0005.jpg\n",
            "amazon/images/keyboard/frame_0006.jpg\n",
            "amazon/images/keyboard/frame_0007.jpg\n",
            "amazon/images/keyboard/frame_0008.jpg\n",
            "amazon/images/keyboard/frame_0009.jpg\n",
            "amazon/images/keyboard/frame_0010.jpg\n",
            "amazon/images/keyboard/frame_0011.jpg\n",
            "amazon/images/keyboard/frame_0012.jpg\n",
            "amazon/images/keyboard/frame_0013.jpg\n",
            "amazon/images/keyboard/frame_0014.jpg\n",
            "amazon/images/keyboard/frame_0015.jpg\n",
            "amazon/images/keyboard/frame_0016.jpg\n",
            "amazon/images/keyboard/frame_0017.jpg\n",
            "amazon/images/keyboard/frame_0018.jpg\n",
            "amazon/images/keyboard/frame_0019.jpg\n",
            "amazon/images/keyboard/frame_0020.jpg\n",
            "amazon/images/keyboard/frame_0021.jpg\n",
            "amazon/images/keyboard/frame_0022.jpg\n",
            "amazon/images/keyboard/frame_0023.jpg\n",
            "amazon/images/keyboard/frame_0024.jpg\n",
            "amazon/images/keyboard/frame_0025.jpg\n",
            "amazon/images/keyboard/frame_0026.jpg\n",
            "amazon/images/keyboard/frame_0027.jpg\n",
            "amazon/images/keyboard/frame_0028.jpg\n",
            "amazon/images/keyboard/frame_0029.jpg\n",
            "amazon/images/keyboard/frame_0030.jpg\n",
            "amazon/images/keyboard/frame_0031.jpg\n",
            "amazon/images/keyboard/frame_0032.jpg\n",
            "amazon/images/keyboard/frame_0033.jpg\n",
            "amazon/images/keyboard/frame_0034.jpg\n",
            "amazon/images/keyboard/frame_0035.jpg\n",
            "amazon/images/keyboard/frame_0036.jpg\n",
            "amazon/images/keyboard/frame_0037.jpg\n",
            "amazon/images/keyboard/frame_0038.jpg\n",
            "amazon/images/keyboard/frame_0039.jpg\n",
            "amazon/images/keyboard/frame_0040.jpg\n",
            "amazon/images/keyboard/frame_0041.jpg\n",
            "amazon/images/keyboard/frame_0042.jpg\n",
            "amazon/images/keyboard/frame_0043.jpg\n",
            "amazon/images/keyboard/frame_0044.jpg\n",
            "amazon/images/keyboard/frame_0045.jpg\n",
            "amazon/images/keyboard/frame_0046.jpg\n",
            "amazon/images/keyboard/frame_0047.jpg\n",
            "amazon/images/keyboard/frame_0048.jpg\n",
            "amazon/images/keyboard/frame_0049.jpg\n",
            "amazon/images/keyboard/frame_0050.jpg\n",
            "amazon/images/keyboard/frame_0051.jpg\n",
            "amazon/images/keyboard/frame_0052.jpg\n",
            "amazon/images/keyboard/frame_0053.jpg\n",
            "amazon/images/keyboard/frame_0054.jpg\n",
            "amazon/images/keyboard/frame_0055.jpg\n",
            "amazon/images/keyboard/frame_0056.jpg\n",
            "amazon/images/keyboard/frame_0057.jpg\n",
            "amazon/images/keyboard/frame_0058.jpg\n",
            "amazon/images/keyboard/frame_0059.jpg\n",
            "amazon/images/keyboard/frame_0060.jpg\n",
            "amazon/images/keyboard/frame_0061.jpg\n",
            "amazon/images/keyboard/frame_0062.jpg\n",
            "amazon/images/keyboard/frame_0063.jpg\n",
            "amazon/images/keyboard/frame_0064.jpg\n",
            "amazon/images/keyboard/frame_0065.jpg\n",
            "amazon/images/keyboard/frame_0066.jpg\n",
            "amazon/images/keyboard/frame_0067.jpg\n",
            "amazon/images/keyboard/frame_0068.jpg\n",
            "amazon/images/keyboard/frame_0069.jpg\n",
            "amazon/images/keyboard/frame_0070.jpg\n",
            "amazon/images/keyboard/frame_0071.jpg\n",
            "amazon/images/keyboard/frame_0072.jpg\n",
            "amazon/images/keyboard/frame_0073.jpg\n",
            "amazon/images/keyboard/frame_0074.jpg\n",
            "amazon/images/keyboard/frame_0075.jpg\n",
            "amazon/images/keyboard/frame_0076.jpg\n",
            "amazon/images/keyboard/frame_0077.jpg\n",
            "amazon/images/keyboard/frame_0078.jpg\n",
            "amazon/images/keyboard/frame_0079.jpg\n",
            "amazon/images/keyboard/frame_0080.jpg\n",
            "amazon/images/keyboard/frame_0081.jpg\n",
            "amazon/images/keyboard/frame_0082.jpg\n",
            "amazon/images/keyboard/frame_0083.jpg\n",
            "amazon/images/keyboard/frame_0084.jpg\n",
            "amazon/images/keyboard/frame_0085.jpg\n",
            "amazon/images/keyboard/frame_0086.jpg\n",
            "amazon/images/keyboard/frame_0087.jpg\n",
            "amazon/images/keyboard/frame_0088.jpg\n",
            "amazon/images/keyboard/frame_0089.jpg\n",
            "amazon/images/keyboard/frame_0090.jpg\n",
            "amazon/images/keyboard/frame_0091.jpg\n",
            "amazon/images/keyboard/frame_0092.jpg\n",
            "amazon/images/keyboard/frame_0093.jpg\n",
            "amazon/images/keyboard/frame_0094.jpg\n",
            "amazon/images/keyboard/frame_0095.jpg\n",
            "amazon/images/keyboard/frame_0096.jpg\n",
            "amazon/images/keyboard/frame_0097.jpg\n",
            "amazon/images/keyboard/frame_0098.jpg\n",
            "amazon/images/keyboard/frame_0099.jpg\n",
            "amazon/images/keyboard/frame_0100.jpg\n",
            "amazon/images/laptop_computer/frame_0001.jpg\n",
            "amazon/images/laptop_computer/frame_0002.jpg\n",
            "amazon/images/laptop_computer/frame_0003.jpg\n",
            "amazon/images/laptop_computer/frame_0004.jpg\n",
            "amazon/images/laptop_computer/frame_0005.jpg\n",
            "amazon/images/laptop_computer/frame_0006.jpg\n",
            "amazon/images/laptop_computer/frame_0007.jpg\n",
            "amazon/images/laptop_computer/frame_0008.jpg\n",
            "amazon/images/laptop_computer/frame_0009.jpg\n",
            "amazon/images/laptop_computer/frame_0010.jpg\n",
            "amazon/images/laptop_computer/frame_0011.jpg\n",
            "amazon/images/laptop_computer/frame_0012.jpg\n",
            "amazon/images/laptop_computer/frame_0013.jpg\n",
            "amazon/images/laptop_computer/frame_0014.jpg\n",
            "amazon/images/laptop_computer/frame_0015.jpg\n",
            "amazon/images/laptop_computer/frame_0016.jpg\n",
            "amazon/images/laptop_computer/frame_0017.jpg\n",
            "amazon/images/laptop_computer/frame_0018.jpg\n",
            "amazon/images/laptop_computer/frame_0019.jpg\n",
            "amazon/images/laptop_computer/frame_0020.jpg\n",
            "amazon/images/laptop_computer/frame_0021.jpg\n",
            "amazon/images/laptop_computer/frame_0022.jpg\n",
            "amazon/images/laptop_computer/frame_0023.jpg\n",
            "amazon/images/laptop_computer/frame_0024.jpg\n",
            "amazon/images/laptop_computer/frame_0025.jpg\n",
            "amazon/images/laptop_computer/frame_0026.jpg\n",
            "amazon/images/laptop_computer/frame_0027.jpg\n",
            "amazon/images/laptop_computer/frame_0028.jpg\n",
            "amazon/images/laptop_computer/frame_0029.jpg\n",
            "amazon/images/laptop_computer/frame_0030.jpg\n",
            "amazon/images/laptop_computer/frame_0031.jpg\n",
            "amazon/images/laptop_computer/frame_0032.jpg\n",
            "amazon/images/laptop_computer/frame_0033.jpg\n",
            "amazon/images/laptop_computer/frame_0034.jpg\n",
            "amazon/images/laptop_computer/frame_0035.jpg\n",
            "amazon/images/laptop_computer/frame_0036.jpg\n",
            "amazon/images/laptop_computer/frame_0037.jpg\n",
            "amazon/images/laptop_computer/frame_0038.jpg\n",
            "amazon/images/laptop_computer/frame_0039.jpg\n",
            "amazon/images/laptop_computer/frame_0040.jpg\n",
            "amazon/images/laptop_computer/frame_0041.jpg\n",
            "amazon/images/laptop_computer/frame_0042.jpg\n",
            "amazon/images/laptop_computer/frame_0043.jpg\n",
            "amazon/images/laptop_computer/frame_0044.jpg\n",
            "amazon/images/laptop_computer/frame_0045.jpg\n",
            "amazon/images/laptop_computer/frame_0046.jpg\n",
            "amazon/images/laptop_computer/frame_0047.jpg\n",
            "amazon/images/laptop_computer/frame_0048.jpg\n",
            "amazon/images/laptop_computer/frame_0049.jpg\n",
            "amazon/images/laptop_computer/frame_0050.jpg\n",
            "amazon/images/laptop_computer/frame_0051.jpg\n",
            "amazon/images/laptop_computer/frame_0052.jpg\n",
            "amazon/images/laptop_computer/frame_0053.jpg\n",
            "amazon/images/laptop_computer/frame_0054.jpg\n",
            "amazon/images/laptop_computer/frame_0055.jpg\n",
            "amazon/images/laptop_computer/frame_0056.jpg\n",
            "amazon/images/laptop_computer/frame_0057.jpg\n",
            "amazon/images/laptop_computer/frame_0058.jpg\n",
            "amazon/images/laptop_computer/frame_0059.jpg\n",
            "amazon/images/laptop_computer/frame_0060.jpg\n",
            "amazon/images/laptop_computer/frame_0061.jpg\n",
            "amazon/images/laptop_computer/frame_0062.jpg\n",
            "amazon/images/laptop_computer/frame_0063.jpg\n",
            "amazon/images/laptop_computer/frame_0064.jpg\n",
            "amazon/images/laptop_computer/frame_0065.jpg\n",
            "amazon/images/laptop_computer/frame_0066.jpg\n",
            "amazon/images/laptop_computer/frame_0067.jpg\n",
            "amazon/images/laptop_computer/frame_0068.jpg\n",
            "amazon/images/laptop_computer/frame_0069.jpg\n",
            "amazon/images/laptop_computer/frame_0070.jpg\n",
            "amazon/images/laptop_computer/frame_0071.jpg\n",
            "amazon/images/laptop_computer/frame_0072.jpg\n",
            "amazon/images/laptop_computer/frame_0073.jpg\n",
            "amazon/images/laptop_computer/frame_0074.jpg\n",
            "amazon/images/laptop_computer/frame_0075.jpg\n",
            "amazon/images/laptop_computer/frame_0076.jpg\n",
            "amazon/images/laptop_computer/frame_0077.jpg\n",
            "amazon/images/laptop_computer/frame_0078.jpg\n",
            "amazon/images/laptop_computer/frame_0079.jpg\n",
            "amazon/images/laptop_computer/frame_0080.jpg\n",
            "amazon/images/laptop_computer/frame_0081.jpg\n",
            "amazon/images/laptop_computer/frame_0082.jpg\n",
            "amazon/images/laptop_computer/frame_0083.jpg\n",
            "amazon/images/laptop_computer/frame_0084.jpg\n",
            "amazon/images/laptop_computer/frame_0085.jpg\n",
            "amazon/images/laptop_computer/frame_0086.jpg\n",
            "amazon/images/laptop_computer/frame_0087.jpg\n",
            "amazon/images/laptop_computer/frame_0088.jpg\n",
            "amazon/images/laptop_computer/frame_0089.jpg\n",
            "amazon/images/laptop_computer/frame_0090.jpg\n",
            "amazon/images/laptop_computer/frame_0091.jpg\n",
            "amazon/images/laptop_computer/frame_0092.jpg\n",
            "amazon/images/laptop_computer/frame_0093.jpg\n",
            "amazon/images/laptop_computer/frame_0094.jpg\n",
            "amazon/images/laptop_computer/frame_0095.jpg\n",
            "amazon/images/laptop_computer/frame_0096.jpg\n",
            "amazon/images/laptop_computer/frame_0097.jpg\n",
            "amazon/images/laptop_computer/frame_0098.jpg\n",
            "amazon/images/laptop_computer/frame_0099.jpg\n",
            "amazon/images/laptop_computer/frame_0100.jpg\n",
            "amazon/images/letter_tray/frame_0001.jpg\n",
            "amazon/images/letter_tray/frame_0002.jpg\n",
            "amazon/images/letter_tray/frame_0003.jpg\n",
            "amazon/images/letter_tray/frame_0004.jpg\n",
            "amazon/images/letter_tray/frame_0005.jpg\n",
            "amazon/images/letter_tray/frame_0006.jpg\n",
            "amazon/images/letter_tray/frame_0007.jpg\n",
            "amazon/images/letter_tray/frame_0008.jpg\n",
            "amazon/images/letter_tray/frame_0009.jpg\n",
            "amazon/images/letter_tray/frame_0010.jpg\n",
            "amazon/images/letter_tray/frame_0011.jpg\n",
            "amazon/images/letter_tray/frame_0012.jpg\n",
            "amazon/images/letter_tray/frame_0013.jpg\n",
            "amazon/images/letter_tray/frame_0014.jpg\n",
            "amazon/images/letter_tray/frame_0015.jpg\n",
            "amazon/images/letter_tray/frame_0016.jpg\n",
            "amazon/images/letter_tray/frame_0017.jpg\n",
            "amazon/images/letter_tray/frame_0018.jpg\n",
            "amazon/images/letter_tray/frame_0019.jpg\n",
            "amazon/images/letter_tray/frame_0020.jpg\n",
            "amazon/images/letter_tray/frame_0021.jpg\n",
            "amazon/images/letter_tray/frame_0022.jpg\n",
            "amazon/images/letter_tray/frame_0023.jpg\n",
            "amazon/images/letter_tray/frame_0024.jpg\n",
            "amazon/images/letter_tray/frame_0025.jpg\n",
            "amazon/images/letter_tray/frame_0026.jpg\n",
            "amazon/images/letter_tray/frame_0027.jpg\n",
            "amazon/images/letter_tray/frame_0028.jpg\n",
            "amazon/images/letter_tray/frame_0029.jpg\n",
            "amazon/images/letter_tray/frame_0030.jpg\n",
            "amazon/images/letter_tray/frame_0031.jpg\n",
            "amazon/images/letter_tray/frame_0032.jpg\n",
            "amazon/images/letter_tray/frame_0033.jpg\n",
            "amazon/images/letter_tray/frame_0034.jpg\n",
            "amazon/images/letter_tray/frame_0035.jpg\n",
            "amazon/images/letter_tray/frame_0036.jpg\n",
            "amazon/images/letter_tray/frame_0037.jpg\n",
            "amazon/images/letter_tray/frame_0038.jpg\n",
            "amazon/images/letter_tray/frame_0039.jpg\n",
            "amazon/images/letter_tray/frame_0040.jpg\n",
            "amazon/images/letter_tray/frame_0041.jpg\n",
            "amazon/images/letter_tray/frame_0042.jpg\n",
            "amazon/images/letter_tray/frame_0043.jpg\n",
            "amazon/images/letter_tray/frame_0044.jpg\n",
            "amazon/images/letter_tray/frame_0045.jpg\n",
            "amazon/images/letter_tray/frame_0046.jpg\n",
            "amazon/images/letter_tray/frame_0047.jpg\n",
            "amazon/images/letter_tray/frame_0048.jpg\n",
            "amazon/images/letter_tray/frame_0049.jpg\n",
            "amazon/images/letter_tray/frame_0050.jpg\n",
            "amazon/images/letter_tray/frame_0051.jpg\n",
            "amazon/images/letter_tray/frame_0052.jpg\n",
            "amazon/images/letter_tray/frame_0053.jpg\n",
            "amazon/images/letter_tray/frame_0054.jpg\n",
            "amazon/images/letter_tray/frame_0055.jpg\n",
            "amazon/images/letter_tray/frame_0056.jpg\n",
            "amazon/images/letter_tray/frame_0057.jpg\n",
            "amazon/images/letter_tray/frame_0058.jpg\n",
            "amazon/images/letter_tray/frame_0059.jpg\n",
            "amazon/images/letter_tray/frame_0060.jpg\n",
            "amazon/images/letter_tray/frame_0061.jpg\n",
            "amazon/images/letter_tray/frame_0062.jpg\n",
            "amazon/images/letter_tray/frame_0063.jpg\n",
            "amazon/images/letter_tray/frame_0064.jpg\n",
            "amazon/images/letter_tray/frame_0065.jpg\n",
            "amazon/images/letter_tray/frame_0066.jpg\n",
            "amazon/images/letter_tray/frame_0067.jpg\n",
            "amazon/images/letter_tray/frame_0068.jpg\n",
            "amazon/images/letter_tray/frame_0069.jpg\n",
            "amazon/images/letter_tray/frame_0070.jpg\n",
            "amazon/images/letter_tray/frame_0071.jpg\n",
            "amazon/images/letter_tray/frame_0072.jpg\n",
            "amazon/images/letter_tray/frame_0073.jpg\n",
            "amazon/images/letter_tray/frame_0074.jpg\n",
            "amazon/images/letter_tray/frame_0075.jpg\n",
            "amazon/images/letter_tray/frame_0076.jpg\n",
            "amazon/images/letter_tray/frame_0077.jpg\n",
            "amazon/images/letter_tray/frame_0078.jpg\n",
            "amazon/images/letter_tray/frame_0079.jpg\n",
            "amazon/images/letter_tray/frame_0080.jpg\n",
            "amazon/images/letter_tray/frame_0081.jpg\n",
            "amazon/images/letter_tray/frame_0082.jpg\n",
            "amazon/images/letter_tray/frame_0083.jpg\n",
            "amazon/images/letter_tray/frame_0084.jpg\n",
            "amazon/images/letter_tray/frame_0085.jpg\n",
            "amazon/images/letter_tray/frame_0086.jpg\n",
            "amazon/images/letter_tray/frame_0087.jpg\n",
            "amazon/images/letter_tray/frame_0088.jpg\n",
            "amazon/images/letter_tray/frame_0089.jpg\n",
            "amazon/images/letter_tray/frame_0090.jpg\n",
            "amazon/images/letter_tray/frame_0091.jpg\n",
            "amazon/images/letter_tray/frame_0092.jpg\n",
            "amazon/images/letter_tray/frame_0093.jpg\n",
            "amazon/images/letter_tray/frame_0094.jpg\n",
            "amazon/images/letter_tray/frame_0095.jpg\n",
            "amazon/images/letter_tray/frame_0096.jpg\n",
            "amazon/images/letter_tray/frame_0097.jpg\n",
            "amazon/images/letter_tray/frame_0098.jpg\n",
            "amazon/images/mobile_phone/frame_0001.jpg\n",
            "amazon/images/mobile_phone/frame_0002.jpg\n",
            "amazon/images/mobile_phone/frame_0003.jpg\n",
            "amazon/images/mobile_phone/frame_0004.jpg\n",
            "amazon/images/mobile_phone/frame_0005.jpg\n",
            "amazon/images/mobile_phone/frame_0006.jpg\n",
            "amazon/images/mobile_phone/frame_0007.jpg\n",
            "amazon/images/mobile_phone/frame_0008.jpg\n",
            "amazon/images/mobile_phone/frame_0009.jpg\n",
            "amazon/images/mobile_phone/frame_0010.jpg\n",
            "amazon/images/mobile_phone/frame_0011.jpg\n",
            "amazon/images/mobile_phone/frame_0012.jpg\n",
            "amazon/images/mobile_phone/frame_0013.jpg\n",
            "amazon/images/mobile_phone/frame_0014.jpg\n",
            "amazon/images/mobile_phone/frame_0015.jpg\n",
            "amazon/images/mobile_phone/frame_0016.jpg\n",
            "amazon/images/mobile_phone/frame_0017.jpg\n",
            "amazon/images/mobile_phone/frame_0018.jpg\n",
            "amazon/images/mobile_phone/frame_0019.jpg\n",
            "amazon/images/mobile_phone/frame_0020.jpg\n",
            "amazon/images/mobile_phone/frame_0021.jpg\n",
            "amazon/images/mobile_phone/frame_0022.jpg\n",
            "amazon/images/mobile_phone/frame_0023.jpg\n",
            "amazon/images/mobile_phone/frame_0024.jpg\n",
            "amazon/images/mobile_phone/frame_0025.jpg\n",
            "amazon/images/mobile_phone/frame_0026.jpg\n",
            "amazon/images/mobile_phone/frame_0027.jpg\n",
            "amazon/images/mobile_phone/frame_0028.jpg\n",
            "amazon/images/mobile_phone/frame_0029.jpg\n",
            "amazon/images/mobile_phone/frame_0030.jpg\n",
            "amazon/images/mobile_phone/frame_0031.jpg\n",
            "amazon/images/mobile_phone/frame_0032.jpg\n",
            "amazon/images/mobile_phone/frame_0033.jpg\n",
            "amazon/images/mobile_phone/frame_0034.jpg\n",
            "amazon/images/mobile_phone/frame_0035.jpg\n",
            "amazon/images/mobile_phone/frame_0036.jpg\n",
            "amazon/images/mobile_phone/frame_0037.jpg\n",
            "amazon/images/mobile_phone/frame_0038.jpg\n",
            "amazon/images/mobile_phone/frame_0039.jpg\n",
            "amazon/images/mobile_phone/frame_0040.jpg\n",
            "amazon/images/mobile_phone/frame_0041.jpg\n",
            "amazon/images/mobile_phone/frame_0042.jpg\n",
            "amazon/images/mobile_phone/frame_0043.jpg\n",
            "amazon/images/mobile_phone/frame_0044.jpg\n",
            "amazon/images/mobile_phone/frame_0045.jpg\n",
            "amazon/images/mobile_phone/frame_0046.jpg\n",
            "amazon/images/mobile_phone/frame_0047.jpg\n",
            "amazon/images/mobile_phone/frame_0048.jpg\n",
            "amazon/images/mobile_phone/frame_0049.jpg\n",
            "amazon/images/mobile_phone/frame_0050.jpg\n",
            "amazon/images/mobile_phone/frame_0051.jpg\n",
            "amazon/images/mobile_phone/frame_0052.jpg\n",
            "amazon/images/mobile_phone/frame_0053.jpg\n",
            "amazon/images/mobile_phone/frame_0054.jpg\n",
            "amazon/images/mobile_phone/frame_0055.jpg\n",
            "amazon/images/mobile_phone/frame_0056.jpg\n",
            "amazon/images/mobile_phone/frame_0057.jpg\n",
            "amazon/images/mobile_phone/frame_0058.jpg\n",
            "amazon/images/mobile_phone/frame_0059.jpg\n",
            "amazon/images/mobile_phone/frame_0060.jpg\n",
            "amazon/images/mobile_phone/frame_0061.jpg\n",
            "amazon/images/mobile_phone/frame_0062.jpg\n",
            "amazon/images/mobile_phone/frame_0063.jpg\n",
            "amazon/images/mobile_phone/frame_0064.jpg\n",
            "amazon/images/mobile_phone/frame_0065.jpg\n",
            "amazon/images/mobile_phone/frame_0066.jpg\n",
            "amazon/images/mobile_phone/frame_0067.jpg\n",
            "amazon/images/mobile_phone/frame_0068.jpg\n",
            "amazon/images/mobile_phone/frame_0069.jpg\n",
            "amazon/images/mobile_phone/frame_0070.jpg\n",
            "amazon/images/mobile_phone/frame_0071.jpg\n",
            "amazon/images/mobile_phone/frame_0072.jpg\n",
            "amazon/images/mobile_phone/frame_0073.jpg\n",
            "amazon/images/mobile_phone/frame_0074.jpg\n",
            "amazon/images/mobile_phone/frame_0075.jpg\n",
            "amazon/images/mobile_phone/frame_0076.jpg\n",
            "amazon/images/mobile_phone/frame_0077.jpg\n",
            "amazon/images/mobile_phone/frame_0078.jpg\n",
            "amazon/images/mobile_phone/frame_0079.jpg\n",
            "amazon/images/mobile_phone/frame_0080.jpg\n",
            "amazon/images/mobile_phone/frame_0081.jpg\n",
            "amazon/images/mobile_phone/frame_0082.jpg\n",
            "amazon/images/mobile_phone/frame_0083.jpg\n",
            "amazon/images/mobile_phone/frame_0084.jpg\n",
            "amazon/images/mobile_phone/frame_0085.jpg\n",
            "amazon/images/mobile_phone/frame_0086.jpg\n",
            "amazon/images/mobile_phone/frame_0087.jpg\n",
            "amazon/images/mobile_phone/frame_0088.jpg\n",
            "amazon/images/mobile_phone/frame_0089.jpg\n",
            "amazon/images/mobile_phone/frame_0090.jpg\n",
            "amazon/images/mobile_phone/frame_0091.jpg\n",
            "amazon/images/mobile_phone/frame_0092.jpg\n",
            "amazon/images/mobile_phone/frame_0093.jpg\n",
            "amazon/images/mobile_phone/frame_0094.jpg\n",
            "amazon/images/mobile_phone/frame_0095.jpg\n",
            "amazon/images/mobile_phone/frame_0096.jpg\n",
            "amazon/images/mobile_phone/frame_0097.jpg\n",
            "amazon/images/mobile_phone/frame_0098.jpg\n",
            "amazon/images/mobile_phone/frame_0099.jpg\n",
            "amazon/images/mobile_phone/frame_0100.jpg\n",
            "amazon/images/monitor/frame_0001.jpg\n",
            "amazon/images/monitor/frame_0002.jpg\n",
            "amazon/images/monitor/frame_0003.jpg\n",
            "amazon/images/monitor/frame_0004.jpg\n",
            "amazon/images/monitor/frame_0005.jpg\n",
            "amazon/images/monitor/frame_0006.jpg\n",
            "amazon/images/monitor/frame_0007.jpg\n",
            "amazon/images/monitor/frame_0008.jpg\n",
            "amazon/images/monitor/frame_0009.jpg\n",
            "amazon/images/monitor/frame_0010.jpg\n",
            "amazon/images/monitor/frame_0011.jpg\n",
            "amazon/images/monitor/frame_0012.jpg\n",
            "amazon/images/monitor/frame_0013.jpg\n",
            "amazon/images/monitor/frame_0014.jpg\n",
            "amazon/images/monitor/frame_0015.jpg\n",
            "amazon/images/monitor/frame_0016.jpg\n",
            "amazon/images/monitor/frame_0017.jpg\n",
            "amazon/images/monitor/frame_0018.jpg\n",
            "amazon/images/monitor/frame_0019.jpg\n",
            "amazon/images/monitor/frame_0020.jpg\n",
            "amazon/images/monitor/frame_0021.jpg\n",
            "amazon/images/monitor/frame_0022.jpg\n",
            "amazon/images/monitor/frame_0023.jpg\n",
            "amazon/images/monitor/frame_0024.jpg\n",
            "amazon/images/monitor/frame_0025.jpg\n",
            "amazon/images/monitor/frame_0026.jpg\n",
            "amazon/images/monitor/frame_0027.jpg\n",
            "amazon/images/monitor/frame_0028.jpg\n",
            "amazon/images/monitor/frame_0029.jpg\n",
            "amazon/images/monitor/frame_0030.jpg\n",
            "amazon/images/monitor/frame_0031.jpg\n",
            "amazon/images/monitor/frame_0032.jpg\n",
            "amazon/images/monitor/frame_0033.jpg\n",
            "amazon/images/monitor/frame_0034.jpg\n",
            "amazon/images/monitor/frame_0035.jpg\n",
            "amazon/images/monitor/frame_0036.jpg\n",
            "amazon/images/monitor/frame_0037.jpg\n",
            "amazon/images/monitor/frame_0038.jpg\n",
            "amazon/images/monitor/frame_0039.jpg\n",
            "amazon/images/monitor/frame_0040.jpg\n",
            "amazon/images/monitor/frame_0041.jpg\n",
            "amazon/images/monitor/frame_0042.jpg\n",
            "amazon/images/monitor/frame_0043.jpg\n",
            "amazon/images/monitor/frame_0044.jpg\n",
            "amazon/images/monitor/frame_0045.jpg\n",
            "amazon/images/monitor/frame_0046.jpg\n",
            "amazon/images/monitor/frame_0047.jpg\n",
            "amazon/images/monitor/frame_0048.jpg\n",
            "amazon/images/monitor/frame_0049.jpg\n",
            "amazon/images/monitor/frame_0050.jpg\n",
            "amazon/images/monitor/frame_0051.jpg\n",
            "amazon/images/monitor/frame_0052.jpg\n",
            "amazon/images/monitor/frame_0053.jpg\n",
            "amazon/images/monitor/frame_0054.jpg\n",
            "amazon/images/monitor/frame_0055.jpg\n",
            "amazon/images/monitor/frame_0056.jpg\n",
            "amazon/images/monitor/frame_0057.jpg\n",
            "amazon/images/monitor/frame_0058.jpg\n",
            "amazon/images/monitor/frame_0059.jpg\n",
            "amazon/images/monitor/frame_0060.jpg\n",
            "amazon/images/monitor/frame_0061.jpg\n",
            "amazon/images/monitor/frame_0062.jpg\n",
            "amazon/images/monitor/frame_0063.jpg\n",
            "amazon/images/monitor/frame_0064.jpg\n",
            "amazon/images/monitor/frame_0065.jpg\n",
            "amazon/images/monitor/frame_0066.jpg\n",
            "amazon/images/monitor/frame_0067.jpg\n",
            "amazon/images/monitor/frame_0068.jpg\n",
            "amazon/images/monitor/frame_0069.jpg\n",
            "amazon/images/monitor/frame_0070.jpg\n",
            "amazon/images/monitor/frame_0071.jpg\n",
            "amazon/images/monitor/frame_0072.jpg\n",
            "amazon/images/monitor/frame_0073.jpg\n",
            "amazon/images/monitor/frame_0074.jpg\n",
            "amazon/images/monitor/frame_0075.jpg\n",
            "amazon/images/monitor/frame_0076.jpg\n",
            "amazon/images/monitor/frame_0077.jpg\n",
            "amazon/images/monitor/frame_0078.jpg\n",
            "amazon/images/monitor/frame_0079.jpg\n",
            "amazon/images/monitor/frame_0080.jpg\n",
            "amazon/images/monitor/frame_0081.jpg\n",
            "amazon/images/monitor/frame_0082.jpg\n",
            "amazon/images/monitor/frame_0083.jpg\n",
            "amazon/images/monitor/frame_0084.jpg\n",
            "amazon/images/monitor/frame_0085.jpg\n",
            "amazon/images/monitor/frame_0086.jpg\n",
            "amazon/images/monitor/frame_0087.jpg\n",
            "amazon/images/monitor/frame_0088.jpg\n",
            "amazon/images/monitor/frame_0089.jpg\n",
            "amazon/images/monitor/frame_0090.jpg\n",
            "amazon/images/monitor/frame_0091.jpg\n",
            "amazon/images/monitor/frame_0092.jpg\n",
            "amazon/images/monitor/frame_0093.jpg\n",
            "amazon/images/monitor/frame_0094.jpg\n",
            "amazon/images/monitor/frame_0095.jpg\n",
            "amazon/images/monitor/frame_0096.jpg\n",
            "amazon/images/monitor/frame_0097.jpg\n",
            "amazon/images/monitor/frame_0098.jpg\n",
            "amazon/images/monitor/frame_0099.jpg\n",
            "amazon/images/mouse/frame_0001.jpg\n",
            "amazon/images/mouse/frame_0002.jpg\n",
            "amazon/images/mouse/frame_0003.jpg\n",
            "amazon/images/mouse/frame_0004.jpg\n",
            "amazon/images/mouse/frame_0005.jpg\n",
            "amazon/images/mouse/frame_0006.jpg\n",
            "amazon/images/mouse/frame_0007.jpg\n",
            "amazon/images/mouse/frame_0008.jpg\n",
            "amazon/images/mouse/frame_0009.jpg\n",
            "amazon/images/mouse/frame_0010.jpg\n",
            "amazon/images/mouse/frame_0011.jpg\n",
            "amazon/images/mouse/frame_0012.jpg\n",
            "amazon/images/mouse/frame_0013.jpg\n",
            "amazon/images/mouse/frame_0014.jpg\n",
            "amazon/images/mouse/frame_0015.jpg\n",
            "amazon/images/mouse/frame_0016.jpg\n",
            "amazon/images/mouse/frame_0017.jpg\n",
            "amazon/images/mouse/frame_0018.jpg\n",
            "amazon/images/mouse/frame_0019.jpg\n",
            "amazon/images/mouse/frame_0020.jpg\n",
            "amazon/images/mouse/frame_0021.jpg\n",
            "amazon/images/mouse/frame_0022.jpg\n",
            "amazon/images/mouse/frame_0023.jpg\n",
            "amazon/images/mouse/frame_0024.jpg\n",
            "amazon/images/mouse/frame_0025.jpg\n",
            "amazon/images/mouse/frame_0026.jpg\n",
            "amazon/images/mouse/frame_0027.jpg\n",
            "amazon/images/mouse/frame_0028.jpg\n",
            "amazon/images/mouse/frame_0029.jpg\n",
            "amazon/images/mouse/frame_0030.jpg\n",
            "amazon/images/mouse/frame_0031.jpg\n",
            "amazon/images/mouse/frame_0032.jpg\n",
            "amazon/images/mouse/frame_0033.jpg\n",
            "amazon/images/mouse/frame_0034.jpg\n",
            "amazon/images/mouse/frame_0035.jpg\n",
            "amazon/images/mouse/frame_0036.jpg\n",
            "amazon/images/mouse/frame_0037.jpg\n",
            "amazon/images/mouse/frame_0038.jpg\n",
            "amazon/images/mouse/frame_0039.jpg\n",
            "amazon/images/mouse/frame_0040.jpg\n",
            "amazon/images/mouse/frame_0041.jpg\n",
            "amazon/images/mouse/frame_0042.jpg\n",
            "amazon/images/mouse/frame_0043.jpg\n",
            "amazon/images/mouse/frame_0044.jpg\n",
            "amazon/images/mouse/frame_0045.jpg\n",
            "amazon/images/mouse/frame_0046.jpg\n",
            "amazon/images/mouse/frame_0047.jpg\n",
            "amazon/images/mouse/frame_0048.jpg\n",
            "amazon/images/mouse/frame_0049.jpg\n",
            "amazon/images/mouse/frame_0050.jpg\n",
            "amazon/images/mouse/frame_0051.jpg\n",
            "amazon/images/mouse/frame_0052.jpg\n",
            "amazon/images/mouse/frame_0053.jpg\n",
            "amazon/images/mouse/frame_0054.jpg\n",
            "amazon/images/mouse/frame_0055.jpg\n",
            "amazon/images/mouse/frame_0056.jpg\n",
            "amazon/images/mouse/frame_0057.jpg\n",
            "amazon/images/mouse/frame_0058.jpg\n",
            "amazon/images/mouse/frame_0059.jpg\n",
            "amazon/images/mouse/frame_0060.jpg\n",
            "amazon/images/mouse/frame_0061.jpg\n",
            "amazon/images/mouse/frame_0062.jpg\n",
            "amazon/images/mouse/frame_0063.jpg\n",
            "amazon/images/mouse/frame_0064.jpg\n",
            "amazon/images/mouse/frame_0065.jpg\n",
            "amazon/images/mouse/frame_0066.jpg\n",
            "amazon/images/mouse/frame_0067.jpg\n",
            "amazon/images/mouse/frame_0068.jpg\n",
            "amazon/images/mouse/frame_0069.jpg\n",
            "amazon/images/mouse/frame_0070.jpg\n",
            "amazon/images/mouse/frame_0071.jpg\n",
            "amazon/images/mouse/frame_0072.jpg\n",
            "amazon/images/mouse/frame_0073.jpg\n",
            "amazon/images/mouse/frame_0074.jpg\n",
            "amazon/images/mouse/frame_0075.jpg\n",
            "amazon/images/mouse/frame_0076.jpg\n",
            "amazon/images/mouse/frame_0077.jpg\n",
            "amazon/images/mouse/frame_0078.jpg\n",
            "amazon/images/mouse/frame_0079.jpg\n",
            "amazon/images/mouse/frame_0080.jpg\n",
            "amazon/images/mouse/frame_0081.jpg\n",
            "amazon/images/mouse/frame_0082.jpg\n",
            "amazon/images/mouse/frame_0083.jpg\n",
            "amazon/images/mouse/frame_0084.jpg\n",
            "amazon/images/mouse/frame_0085.jpg\n",
            "amazon/images/mouse/frame_0086.jpg\n",
            "amazon/images/mouse/frame_0087.jpg\n",
            "amazon/images/mouse/frame_0088.jpg\n",
            "amazon/images/mouse/frame_0089.jpg\n",
            "amazon/images/mouse/frame_0090.jpg\n",
            "amazon/images/mouse/frame_0091.jpg\n",
            "amazon/images/mouse/frame_0092.jpg\n",
            "amazon/images/mouse/frame_0093.jpg\n",
            "amazon/images/mouse/frame_0094.jpg\n",
            "amazon/images/mouse/frame_0095.jpg\n",
            "amazon/images/mouse/frame_0096.jpg\n",
            "amazon/images/mouse/frame_0097.jpg\n",
            "amazon/images/mouse/frame_0098.jpg\n",
            "amazon/images/mouse/frame_0099.jpg\n",
            "amazon/images/mouse/frame_0100.jpg\n",
            "amazon/images/mug/frame_0001.jpg\n",
            "amazon/images/mug/frame_0002.jpg\n",
            "amazon/images/mug/frame_0003.jpg\n",
            "amazon/images/mug/frame_0004.jpg\n",
            "amazon/images/mug/frame_0005.jpg\n",
            "amazon/images/mug/frame_0006.jpg\n",
            "amazon/images/mug/frame_0007.jpg\n",
            "amazon/images/mug/frame_0008.jpg\n",
            "amazon/images/mug/frame_0009.jpg\n",
            "amazon/images/mug/frame_0010.jpg\n",
            "amazon/images/mug/frame_0011.jpg\n",
            "amazon/images/mug/frame_0012.jpg\n",
            "amazon/images/mug/frame_0013.jpg\n",
            "amazon/images/mug/frame_0014.jpg\n",
            "amazon/images/mug/frame_0015.jpg\n",
            "amazon/images/mug/frame_0016.jpg\n",
            "amazon/images/mug/frame_0017.jpg\n",
            "amazon/images/mug/frame_0018.jpg\n",
            "amazon/images/mug/frame_0019.jpg\n",
            "amazon/images/mug/frame_0020.jpg\n",
            "amazon/images/mug/frame_0021.jpg\n",
            "amazon/images/mug/frame_0022.jpg\n",
            "amazon/images/mug/frame_0023.jpg\n",
            "amazon/images/mug/frame_0024.jpg\n",
            "amazon/images/mug/frame_0025.jpg\n",
            "amazon/images/mug/frame_0026.jpg\n",
            "amazon/images/mug/frame_0027.jpg\n",
            "amazon/images/mug/frame_0028.jpg\n",
            "amazon/images/mug/frame_0029.jpg\n",
            "amazon/images/mug/frame_0030.jpg\n",
            "amazon/images/mug/frame_0031.jpg\n",
            "amazon/images/mug/frame_0032.jpg\n",
            "amazon/images/mug/frame_0033.jpg\n",
            "amazon/images/mug/frame_0034.jpg\n",
            "amazon/images/mug/frame_0035.jpg\n",
            "amazon/images/mug/frame_0036.jpg\n",
            "amazon/images/mug/frame_0037.jpg\n",
            "amazon/images/mug/frame_0038.jpg\n",
            "amazon/images/mug/frame_0039.jpg\n",
            "amazon/images/mug/frame_0040.jpg\n",
            "amazon/images/mug/frame_0041.jpg\n",
            "amazon/images/mug/frame_0042.jpg\n",
            "amazon/images/mug/frame_0043.jpg\n",
            "amazon/images/mug/frame_0044.jpg\n",
            "amazon/images/mug/frame_0045.jpg\n",
            "amazon/images/mug/frame_0046.jpg\n",
            "amazon/images/mug/frame_0047.jpg\n",
            "amazon/images/mug/frame_0048.jpg\n",
            "amazon/images/mug/frame_0049.jpg\n",
            "amazon/images/mug/frame_0050.jpg\n",
            "amazon/images/mug/frame_0051.jpg\n",
            "amazon/images/mug/frame_0052.jpg\n",
            "amazon/images/mug/frame_0053.jpg\n",
            "amazon/images/mug/frame_0054.jpg\n",
            "amazon/images/mug/frame_0055.jpg\n",
            "amazon/images/mug/frame_0056.jpg\n",
            "amazon/images/mug/frame_0057.jpg\n",
            "amazon/images/mug/frame_0058.jpg\n",
            "amazon/images/mug/frame_0059.jpg\n",
            "amazon/images/mug/frame_0060.jpg\n",
            "amazon/images/mug/frame_0061.jpg\n",
            "amazon/images/mug/frame_0062.jpg\n",
            "amazon/images/mug/frame_0063.jpg\n",
            "amazon/images/mug/frame_0064.jpg\n",
            "amazon/images/mug/frame_0065.jpg\n",
            "amazon/images/mug/frame_0066.jpg\n",
            "amazon/images/mug/frame_0067.jpg\n",
            "amazon/images/mug/frame_0068.jpg\n",
            "amazon/images/mug/frame_0069.jpg\n",
            "amazon/images/mug/frame_0070.jpg\n",
            "amazon/images/mug/frame_0071.jpg\n",
            "amazon/images/mug/frame_0072.jpg\n",
            "amazon/images/mug/frame_0073.jpg\n",
            "amazon/images/mug/frame_0074.jpg\n",
            "amazon/images/mug/frame_0075.jpg\n",
            "amazon/images/mug/frame_0076.jpg\n",
            "amazon/images/mug/frame_0077.jpg\n",
            "amazon/images/mug/frame_0078.jpg\n",
            "amazon/images/mug/frame_0079.jpg\n",
            "amazon/images/mug/frame_0080.jpg\n",
            "amazon/images/mug/frame_0081.jpg\n",
            "amazon/images/mug/frame_0082.jpg\n",
            "amazon/images/mug/frame_0083.jpg\n",
            "amazon/images/mug/frame_0084.jpg\n",
            "amazon/images/mug/frame_0085.jpg\n",
            "amazon/images/mug/frame_0086.jpg\n",
            "amazon/images/mug/frame_0087.jpg\n",
            "amazon/images/mug/frame_0088.jpg\n",
            "amazon/images/mug/frame_0089.jpg\n",
            "amazon/images/mug/frame_0090.jpg\n",
            "amazon/images/mug/frame_0091.jpg\n",
            "amazon/images/mug/frame_0092.jpg\n",
            "amazon/images/mug/frame_0093.jpg\n",
            "amazon/images/mug/frame_0094.jpg\n",
            "amazon/images/paper_notebook/frame_0001.jpg\n",
            "amazon/images/paper_notebook/frame_0002.jpg\n",
            "amazon/images/paper_notebook/frame_0003.jpg\n",
            "amazon/images/paper_notebook/frame_0004.jpg\n",
            "amazon/images/paper_notebook/frame_0005.jpg\n",
            "amazon/images/paper_notebook/frame_0006.jpg\n",
            "amazon/images/paper_notebook/frame_0007.jpg\n",
            "amazon/images/paper_notebook/frame_0008.jpg\n",
            "amazon/images/paper_notebook/frame_0009.jpg\n",
            "amazon/images/paper_notebook/frame_0010.jpg\n",
            "amazon/images/paper_notebook/frame_0011.jpg\n",
            "amazon/images/paper_notebook/frame_0012.jpg\n",
            "amazon/images/paper_notebook/frame_0013.jpg\n",
            "amazon/images/paper_notebook/frame_0014.jpg\n",
            "amazon/images/paper_notebook/frame_0015.jpg\n",
            "amazon/images/paper_notebook/frame_0016.jpg\n",
            "amazon/images/paper_notebook/frame_0017.jpg\n",
            "amazon/images/paper_notebook/frame_0018.jpg\n",
            "amazon/images/paper_notebook/frame_0019.jpg\n",
            "amazon/images/paper_notebook/frame_0020.jpg\n",
            "amazon/images/paper_notebook/frame_0021.jpg\n",
            "amazon/images/paper_notebook/frame_0022.jpg\n",
            "amazon/images/paper_notebook/frame_0023.jpg\n",
            "amazon/images/paper_notebook/frame_0024.jpg\n",
            "amazon/images/paper_notebook/frame_0025.jpg\n",
            "amazon/images/paper_notebook/frame_0026.jpg\n",
            "amazon/images/paper_notebook/frame_0027.jpg\n",
            "amazon/images/paper_notebook/frame_0028.jpg\n",
            "amazon/images/paper_notebook/frame_0029.jpg\n",
            "amazon/images/paper_notebook/frame_0030.jpg\n",
            "amazon/images/paper_notebook/frame_0031.jpg\n",
            "amazon/images/paper_notebook/frame_0032.jpg\n",
            "amazon/images/paper_notebook/frame_0033.jpg\n",
            "amazon/images/paper_notebook/frame_0034.jpg\n",
            "amazon/images/paper_notebook/frame_0035.jpg\n",
            "amazon/images/paper_notebook/frame_0036.jpg\n",
            "amazon/images/paper_notebook/frame_0037.jpg\n",
            "amazon/images/paper_notebook/frame_0038.jpg\n",
            "amazon/images/paper_notebook/frame_0039.jpg\n",
            "amazon/images/paper_notebook/frame_0040.jpg\n",
            "amazon/images/paper_notebook/frame_0041.jpg\n",
            "amazon/images/paper_notebook/frame_0042.jpg\n",
            "amazon/images/paper_notebook/frame_0043.jpg\n",
            "amazon/images/paper_notebook/frame_0044.jpg\n",
            "amazon/images/paper_notebook/frame_0045.jpg\n",
            "amazon/images/paper_notebook/frame_0046.jpg\n",
            "amazon/images/paper_notebook/frame_0047.jpg\n",
            "amazon/images/paper_notebook/frame_0048.jpg\n",
            "amazon/images/paper_notebook/frame_0049.jpg\n",
            "amazon/images/paper_notebook/frame_0050.jpg\n",
            "amazon/images/paper_notebook/frame_0051.jpg\n",
            "amazon/images/paper_notebook/frame_0052.jpg\n",
            "amazon/images/paper_notebook/frame_0053.jpg\n",
            "amazon/images/paper_notebook/frame_0054.jpg\n",
            "amazon/images/paper_notebook/frame_0055.jpg\n",
            "amazon/images/paper_notebook/frame_0056.jpg\n",
            "amazon/images/paper_notebook/frame_0057.jpg\n",
            "amazon/images/paper_notebook/frame_0058.jpg\n",
            "amazon/images/paper_notebook/frame_0059.jpg\n",
            "amazon/images/paper_notebook/frame_0060.jpg\n",
            "amazon/images/paper_notebook/frame_0061.jpg\n",
            "amazon/images/paper_notebook/frame_0062.jpg\n",
            "amazon/images/paper_notebook/frame_0063.jpg\n",
            "amazon/images/paper_notebook/frame_0064.jpg\n",
            "amazon/images/paper_notebook/frame_0065.jpg\n",
            "amazon/images/paper_notebook/frame_0066.jpg\n",
            "amazon/images/paper_notebook/frame_0067.jpg\n",
            "amazon/images/paper_notebook/frame_0068.jpg\n",
            "amazon/images/paper_notebook/frame_0069.jpg\n",
            "amazon/images/paper_notebook/frame_0070.jpg\n",
            "amazon/images/paper_notebook/frame_0071.jpg\n",
            "amazon/images/paper_notebook/frame_0072.jpg\n",
            "amazon/images/paper_notebook/frame_0073.jpg\n",
            "amazon/images/paper_notebook/frame_0074.jpg\n",
            "amazon/images/paper_notebook/frame_0075.jpg\n",
            "amazon/images/paper_notebook/frame_0076.jpg\n",
            "amazon/images/paper_notebook/frame_0077.jpg\n",
            "amazon/images/paper_notebook/frame_0078.jpg\n",
            "amazon/images/paper_notebook/frame_0079.jpg\n",
            "amazon/images/paper_notebook/frame_0080.jpg\n",
            "amazon/images/paper_notebook/frame_0081.jpg\n",
            "amazon/images/paper_notebook/frame_0082.jpg\n",
            "amazon/images/paper_notebook/frame_0083.jpg\n",
            "amazon/images/paper_notebook/frame_0084.jpg\n",
            "amazon/images/paper_notebook/frame_0085.jpg\n",
            "amazon/images/paper_notebook/frame_0086.jpg\n",
            "amazon/images/paper_notebook/frame_0087.jpg\n",
            "amazon/images/paper_notebook/frame_0088.jpg\n",
            "amazon/images/paper_notebook/frame_0089.jpg\n",
            "amazon/images/paper_notebook/frame_0090.jpg\n",
            "amazon/images/paper_notebook/frame_0091.jpg\n",
            "amazon/images/paper_notebook/frame_0092.jpg\n",
            "amazon/images/paper_notebook/frame_0093.jpg\n",
            "amazon/images/paper_notebook/frame_0094.jpg\n",
            "amazon/images/paper_notebook/frame_0095.jpg\n",
            "amazon/images/paper_notebook/frame_0096.jpg\n",
            "amazon/images/pen/frame_0001.jpg\n",
            "amazon/images/pen/frame_0002.jpg\n",
            "amazon/images/pen/frame_0003.jpg\n",
            "amazon/images/pen/frame_0004.jpg\n",
            "amazon/images/pen/frame_0005.jpg\n",
            "amazon/images/pen/frame_0006.jpg\n",
            "amazon/images/pen/frame_0007.jpg\n",
            "amazon/images/pen/frame_0008.jpg\n",
            "amazon/images/pen/frame_0009.jpg\n",
            "amazon/images/pen/frame_0010.jpg\n",
            "amazon/images/pen/frame_0011.jpg\n",
            "amazon/images/pen/frame_0012.jpg\n",
            "amazon/images/pen/frame_0013.jpg\n",
            "amazon/images/pen/frame_0014.jpg\n",
            "amazon/images/pen/frame_0015.jpg\n",
            "amazon/images/pen/frame_0016.jpg\n",
            "amazon/images/pen/frame_0017.jpg\n",
            "amazon/images/pen/frame_0018.jpg\n",
            "amazon/images/pen/frame_0019.jpg\n",
            "amazon/images/pen/frame_0020.jpg\n",
            "amazon/images/pen/frame_0021.jpg\n",
            "amazon/images/pen/frame_0022.jpg\n",
            "amazon/images/pen/frame_0023.jpg\n",
            "amazon/images/pen/frame_0024.jpg\n",
            "amazon/images/pen/frame_0025.jpg\n",
            "amazon/images/pen/frame_0026.jpg\n",
            "amazon/images/pen/frame_0027.jpg\n",
            "amazon/images/pen/frame_0028.jpg\n",
            "amazon/images/pen/frame_0029.jpg\n",
            "amazon/images/pen/frame_0030.jpg\n",
            "amazon/images/pen/frame_0031.jpg\n",
            "amazon/images/pen/frame_0032.jpg\n",
            "amazon/images/pen/frame_0033.jpg\n",
            "amazon/images/pen/frame_0034.jpg\n",
            "amazon/images/pen/frame_0035.jpg\n",
            "amazon/images/pen/frame_0036.jpg\n",
            "amazon/images/pen/frame_0037.jpg\n",
            "amazon/images/pen/frame_0038.jpg\n",
            "amazon/images/pen/frame_0039.jpg\n",
            "amazon/images/pen/frame_0040.jpg\n",
            "amazon/images/pen/frame_0041.jpg\n",
            "amazon/images/pen/frame_0042.jpg\n",
            "amazon/images/pen/frame_0043.jpg\n",
            "amazon/images/pen/frame_0044.jpg\n",
            "amazon/images/pen/frame_0045.jpg\n",
            "amazon/images/pen/frame_0046.jpg\n",
            "amazon/images/pen/frame_0047.jpg\n",
            "amazon/images/pen/frame_0048.jpg\n",
            "amazon/images/pen/frame_0049.jpg\n",
            "amazon/images/pen/frame_0050.jpg\n",
            "amazon/images/pen/frame_0051.jpg\n",
            "amazon/images/pen/frame_0052.jpg\n",
            "amazon/images/pen/frame_0053.jpg\n",
            "amazon/images/pen/frame_0054.jpg\n",
            "amazon/images/pen/frame_0055.jpg\n",
            "amazon/images/pen/frame_0056.jpg\n",
            "amazon/images/pen/frame_0057.jpg\n",
            "amazon/images/pen/frame_0058.jpg\n",
            "amazon/images/pen/frame_0059.jpg\n",
            "amazon/images/pen/frame_0060.jpg\n",
            "amazon/images/pen/frame_0061.jpg\n",
            "amazon/images/pen/frame_0062.jpg\n",
            "amazon/images/pen/frame_0063.jpg\n",
            "amazon/images/pen/frame_0064.jpg\n",
            "amazon/images/pen/frame_0065.jpg\n",
            "amazon/images/pen/frame_0066.jpg\n",
            "amazon/images/pen/frame_0067.jpg\n",
            "amazon/images/pen/frame_0068.jpg\n",
            "amazon/images/pen/frame_0069.jpg\n",
            "amazon/images/pen/frame_0070.jpg\n",
            "amazon/images/pen/frame_0071.jpg\n",
            "amazon/images/pen/frame_0072.jpg\n",
            "amazon/images/pen/frame_0073.jpg\n",
            "amazon/images/pen/frame_0074.jpg\n",
            "amazon/images/pen/frame_0075.jpg\n",
            "amazon/images/pen/frame_0076.jpg\n",
            "amazon/images/pen/frame_0077.jpg\n",
            "amazon/images/pen/frame_0078.jpg\n",
            "amazon/images/pen/frame_0079.jpg\n",
            "amazon/images/pen/frame_0080.jpg\n",
            "amazon/images/pen/frame_0081.jpg\n",
            "amazon/images/pen/frame_0082.jpg\n",
            "amazon/images/pen/frame_0083.jpg\n",
            "amazon/images/pen/frame_0084.jpg\n",
            "amazon/images/pen/frame_0085.jpg\n",
            "amazon/images/pen/frame_0086.jpg\n",
            "amazon/images/pen/frame_0087.jpg\n",
            "amazon/images/pen/frame_0088.jpg\n",
            "amazon/images/pen/frame_0089.jpg\n",
            "amazon/images/pen/frame_0090.jpg\n",
            "amazon/images/pen/frame_0091.jpg\n",
            "amazon/images/pen/frame_0092.jpg\n",
            "amazon/images/pen/frame_0093.jpg\n",
            "amazon/images/pen/frame_0094.jpg\n",
            "amazon/images/pen/frame_0095.jpg\n",
            "amazon/images/phone/frame_0001.jpg\n",
            "amazon/images/phone/frame_0002.jpg\n",
            "amazon/images/phone/frame_0003.jpg\n",
            "amazon/images/phone/frame_0004.jpg\n",
            "amazon/images/phone/frame_0005.jpg\n",
            "amazon/images/phone/frame_0006.jpg\n",
            "amazon/images/phone/frame_0007.jpg\n",
            "amazon/images/phone/frame_0008.jpg\n",
            "amazon/images/phone/frame_0009.jpg\n",
            "amazon/images/phone/frame_0010.jpg\n",
            "amazon/images/phone/frame_0011.jpg\n",
            "amazon/images/phone/frame_0012.jpg\n",
            "amazon/images/phone/frame_0013.jpg\n",
            "amazon/images/phone/frame_0014.jpg\n",
            "amazon/images/phone/frame_0015.jpg\n",
            "amazon/images/phone/frame_0016.jpg\n",
            "amazon/images/phone/frame_0017.jpg\n",
            "amazon/images/phone/frame_0018.jpg\n",
            "amazon/images/phone/frame_0019.jpg\n",
            "amazon/images/phone/frame_0020.jpg\n",
            "amazon/images/phone/frame_0021.jpg\n",
            "amazon/images/phone/frame_0022.jpg\n",
            "amazon/images/phone/frame_0023.jpg\n",
            "amazon/images/phone/frame_0024.jpg\n",
            "amazon/images/phone/frame_0025.jpg\n",
            "amazon/images/phone/frame_0026.jpg\n",
            "amazon/images/phone/frame_0027.jpg\n",
            "amazon/images/phone/frame_0028.jpg\n",
            "amazon/images/phone/frame_0029.jpg\n",
            "amazon/images/phone/frame_0030.jpg\n",
            "amazon/images/phone/frame_0031.jpg\n",
            "amazon/images/phone/frame_0032.jpg\n",
            "amazon/images/phone/frame_0033.jpg\n",
            "amazon/images/phone/frame_0034.jpg\n",
            "amazon/images/phone/frame_0035.jpg\n",
            "amazon/images/phone/frame_0036.jpg\n",
            "amazon/images/phone/frame_0037.jpg\n",
            "amazon/images/phone/frame_0038.jpg\n",
            "amazon/images/phone/frame_0039.jpg\n",
            "amazon/images/phone/frame_0040.jpg\n",
            "amazon/images/phone/frame_0041.jpg\n",
            "amazon/images/phone/frame_0042.jpg\n",
            "amazon/images/phone/frame_0043.jpg\n",
            "amazon/images/phone/frame_0044.jpg\n",
            "amazon/images/phone/frame_0045.jpg\n",
            "amazon/images/phone/frame_0046.jpg\n",
            "amazon/images/phone/frame_0047.jpg\n",
            "amazon/images/phone/frame_0048.jpg\n",
            "amazon/images/phone/frame_0049.jpg\n",
            "amazon/images/phone/frame_0050.jpg\n",
            "amazon/images/phone/frame_0051.jpg\n",
            "amazon/images/phone/frame_0052.jpg\n",
            "amazon/images/phone/frame_0053.jpg\n",
            "amazon/images/phone/frame_0054.jpg\n",
            "amazon/images/phone/frame_0055.jpg\n",
            "amazon/images/phone/frame_0056.jpg\n",
            "amazon/images/phone/frame_0057.jpg\n",
            "amazon/images/phone/frame_0058.jpg\n",
            "amazon/images/phone/frame_0059.jpg\n",
            "amazon/images/phone/frame_0060.jpg\n",
            "amazon/images/phone/frame_0061.jpg\n",
            "amazon/images/phone/frame_0062.jpg\n",
            "amazon/images/phone/frame_0063.jpg\n",
            "amazon/images/phone/frame_0064.jpg\n",
            "amazon/images/phone/frame_0065.jpg\n",
            "amazon/images/phone/frame_0066.jpg\n",
            "amazon/images/phone/frame_0067.jpg\n",
            "amazon/images/phone/frame_0068.jpg\n",
            "amazon/images/phone/frame_0069.jpg\n",
            "amazon/images/phone/frame_0070.jpg\n",
            "amazon/images/phone/frame_0071.jpg\n",
            "amazon/images/phone/frame_0072.jpg\n",
            "amazon/images/phone/frame_0073.jpg\n",
            "amazon/images/phone/frame_0074.jpg\n",
            "amazon/images/phone/frame_0075.jpg\n",
            "amazon/images/phone/frame_0076.jpg\n",
            "amazon/images/phone/frame_0077.jpg\n",
            "amazon/images/phone/frame_0078.jpg\n",
            "amazon/images/phone/frame_0079.jpg\n",
            "amazon/images/phone/frame_0080.jpg\n",
            "amazon/images/phone/frame_0081.jpg\n",
            "amazon/images/phone/frame_0082.jpg\n",
            "amazon/images/phone/frame_0083.jpg\n",
            "amazon/images/phone/frame_0084.jpg\n",
            "amazon/images/phone/frame_0085.jpg\n",
            "amazon/images/phone/frame_0086.jpg\n",
            "amazon/images/phone/frame_0087.jpg\n",
            "amazon/images/phone/frame_0088.jpg\n",
            "amazon/images/phone/frame_0089.jpg\n",
            "amazon/images/phone/frame_0090.jpg\n",
            "amazon/images/phone/frame_0091.jpg\n",
            "amazon/images/phone/frame_0092.jpg\n",
            "amazon/images/phone/frame_0093.jpg\n",
            "amazon/images/printer/frame_0001.jpg\n",
            "amazon/images/printer/frame_0002.jpg\n",
            "amazon/images/printer/frame_0003.jpg\n",
            "amazon/images/printer/frame_0004.jpg\n",
            "amazon/images/printer/frame_0005.jpg\n",
            "amazon/images/printer/frame_0006.jpg\n",
            "amazon/images/printer/frame_0007.jpg\n",
            "amazon/images/printer/frame_0008.jpg\n",
            "amazon/images/printer/frame_0009.jpg\n",
            "amazon/images/printer/frame_0010.jpg\n",
            "amazon/images/printer/frame_0011.jpg\n",
            "amazon/images/printer/frame_0012.jpg\n",
            "amazon/images/printer/frame_0013.jpg\n",
            "amazon/images/printer/frame_0014.jpg\n",
            "amazon/images/printer/frame_0015.jpg\n",
            "amazon/images/printer/frame_0016.jpg\n",
            "amazon/images/printer/frame_0017.jpg\n",
            "amazon/images/printer/frame_0018.jpg\n",
            "amazon/images/printer/frame_0019.jpg\n",
            "amazon/images/printer/frame_0020.jpg\n",
            "amazon/images/printer/frame_0021.jpg\n",
            "amazon/images/printer/frame_0022.jpg\n",
            "amazon/images/printer/frame_0023.jpg\n",
            "amazon/images/printer/frame_0024.jpg\n",
            "amazon/images/printer/frame_0025.jpg\n",
            "amazon/images/printer/frame_0026.jpg\n",
            "amazon/images/printer/frame_0027.jpg\n",
            "amazon/images/printer/frame_0028.jpg\n",
            "amazon/images/printer/frame_0029.jpg\n",
            "amazon/images/printer/frame_0030.jpg\n",
            "amazon/images/printer/frame_0031.jpg\n",
            "amazon/images/printer/frame_0032.jpg\n",
            "amazon/images/printer/frame_0033.jpg\n",
            "amazon/images/printer/frame_0034.jpg\n",
            "amazon/images/printer/frame_0035.jpg\n",
            "amazon/images/printer/frame_0036.jpg\n",
            "amazon/images/printer/frame_0037.jpg\n",
            "amazon/images/printer/frame_0038.jpg\n",
            "amazon/images/printer/frame_0039.jpg\n",
            "amazon/images/printer/frame_0040.jpg\n",
            "amazon/images/printer/frame_0041.jpg\n",
            "amazon/images/printer/frame_0042.jpg\n",
            "amazon/images/printer/frame_0043.jpg\n",
            "amazon/images/printer/frame_0044.jpg\n",
            "amazon/images/printer/frame_0045.jpg\n",
            "amazon/images/printer/frame_0046.jpg\n",
            "amazon/images/printer/frame_0047.jpg\n",
            "amazon/images/printer/frame_0048.jpg\n",
            "amazon/images/printer/frame_0049.jpg\n",
            "amazon/images/printer/frame_0050.jpg\n",
            "amazon/images/printer/frame_0051.jpg\n",
            "amazon/images/printer/frame_0052.jpg\n",
            "amazon/images/printer/frame_0053.jpg\n",
            "amazon/images/printer/frame_0054.jpg\n",
            "amazon/images/printer/frame_0055.jpg\n",
            "amazon/images/printer/frame_0056.jpg\n",
            "amazon/images/printer/frame_0057.jpg\n",
            "amazon/images/printer/frame_0058.jpg\n",
            "amazon/images/printer/frame_0059.jpg\n",
            "amazon/images/printer/frame_0060.jpg\n",
            "amazon/images/printer/frame_0061.jpg\n",
            "amazon/images/printer/frame_0062.jpg\n",
            "amazon/images/printer/frame_0063.jpg\n",
            "amazon/images/printer/frame_0064.jpg\n",
            "amazon/images/printer/frame_0065.jpg\n",
            "amazon/images/printer/frame_0066.jpg\n",
            "amazon/images/printer/frame_0067.jpg\n",
            "amazon/images/printer/frame_0068.jpg\n",
            "amazon/images/printer/frame_0069.jpg\n",
            "amazon/images/printer/frame_0070.jpg\n",
            "amazon/images/printer/frame_0071.jpg\n",
            "amazon/images/printer/frame_0072.jpg\n",
            "amazon/images/printer/frame_0073.jpg\n",
            "amazon/images/printer/frame_0074.jpg\n",
            "amazon/images/printer/frame_0075.jpg\n",
            "amazon/images/printer/frame_0076.jpg\n",
            "amazon/images/printer/frame_0077.jpg\n",
            "amazon/images/printer/frame_0078.jpg\n",
            "amazon/images/printer/frame_0079.jpg\n",
            "amazon/images/printer/frame_0080.jpg\n",
            "amazon/images/printer/frame_0081.jpg\n",
            "amazon/images/printer/frame_0082.jpg\n",
            "amazon/images/printer/frame_0083.jpg\n",
            "amazon/images/printer/frame_0084.jpg\n",
            "amazon/images/printer/frame_0085.jpg\n",
            "amazon/images/printer/frame_0086.jpg\n",
            "amazon/images/printer/frame_0087.jpg\n",
            "amazon/images/printer/frame_0088.jpg\n",
            "amazon/images/printer/frame_0089.jpg\n",
            "amazon/images/printer/frame_0090.jpg\n",
            "amazon/images/printer/frame_0091.jpg\n",
            "amazon/images/printer/frame_0092.jpg\n",
            "amazon/images/printer/frame_0093.jpg\n",
            "amazon/images/printer/frame_0094.jpg\n",
            "amazon/images/printer/frame_0095.jpg\n",
            "amazon/images/printer/frame_0096.jpg\n",
            "amazon/images/printer/frame_0097.jpg\n",
            "amazon/images/printer/frame_0098.jpg\n",
            "amazon/images/printer/frame_0099.jpg\n",
            "amazon/images/printer/frame_0100.jpg\n",
            "amazon/images/projector/frame_0001.jpg\n",
            "amazon/images/projector/frame_0002.jpg\n",
            "amazon/images/projector/frame_0003.jpg\n",
            "amazon/images/projector/frame_0004.jpg\n",
            "amazon/images/projector/frame_0005.jpg\n",
            "amazon/images/projector/frame_0006.jpg\n",
            "amazon/images/projector/frame_0007.jpg\n",
            "amazon/images/projector/frame_0008.jpg\n",
            "amazon/images/projector/frame_0009.jpg\n",
            "amazon/images/projector/frame_0010.jpg\n",
            "amazon/images/projector/frame_0011.jpg\n",
            "amazon/images/projector/frame_0012.jpg\n",
            "amazon/images/projector/frame_0013.jpg\n",
            "amazon/images/projector/frame_0014.jpg\n",
            "amazon/images/projector/frame_0015.jpg\n",
            "amazon/images/projector/frame_0016.jpg\n",
            "amazon/images/projector/frame_0017.jpg\n",
            "amazon/images/projector/frame_0018.jpg\n",
            "amazon/images/projector/frame_0019.jpg\n",
            "amazon/images/projector/frame_0020.jpg\n",
            "amazon/images/projector/frame_0021.jpg\n",
            "amazon/images/projector/frame_0022.jpg\n",
            "amazon/images/projector/frame_0023.jpg\n",
            "amazon/images/projector/frame_0024.jpg\n",
            "amazon/images/projector/frame_0025.jpg\n",
            "amazon/images/projector/frame_0026.jpg\n",
            "amazon/images/projector/frame_0027.jpg\n",
            "amazon/images/projector/frame_0028.jpg\n",
            "amazon/images/projector/frame_0029.jpg\n",
            "amazon/images/projector/frame_0030.jpg\n",
            "amazon/images/projector/frame_0031.jpg\n",
            "amazon/images/projector/frame_0032.jpg\n",
            "amazon/images/projector/frame_0033.jpg\n",
            "amazon/images/projector/frame_0034.jpg\n",
            "amazon/images/projector/frame_0035.jpg\n",
            "amazon/images/projector/frame_0036.jpg\n",
            "amazon/images/projector/frame_0037.jpg\n",
            "amazon/images/projector/frame_0038.jpg\n",
            "amazon/images/projector/frame_0039.jpg\n",
            "amazon/images/projector/frame_0040.jpg\n",
            "amazon/images/projector/frame_0041.jpg\n",
            "amazon/images/projector/frame_0042.jpg\n",
            "amazon/images/projector/frame_0043.jpg\n",
            "amazon/images/projector/frame_0044.jpg\n",
            "amazon/images/projector/frame_0045.jpg\n",
            "amazon/images/projector/frame_0046.jpg\n",
            "amazon/images/projector/frame_0047.jpg\n",
            "amazon/images/projector/frame_0048.jpg\n",
            "amazon/images/projector/frame_0049.jpg\n",
            "amazon/images/projector/frame_0050.jpg\n",
            "amazon/images/projector/frame_0051.jpg\n",
            "amazon/images/projector/frame_0052.jpg\n",
            "amazon/images/projector/frame_0053.jpg\n",
            "amazon/images/projector/frame_0054.jpg\n",
            "amazon/images/projector/frame_0055.jpg\n",
            "amazon/images/projector/frame_0056.jpg\n",
            "amazon/images/projector/frame_0057.jpg\n",
            "amazon/images/projector/frame_0058.jpg\n",
            "amazon/images/projector/frame_0059.jpg\n",
            "amazon/images/projector/frame_0060.jpg\n",
            "amazon/images/projector/frame_0061.jpg\n",
            "amazon/images/projector/frame_0062.jpg\n",
            "amazon/images/projector/frame_0063.jpg\n",
            "amazon/images/projector/frame_0064.jpg\n",
            "amazon/images/projector/frame_0065.jpg\n",
            "amazon/images/projector/frame_0066.jpg\n",
            "amazon/images/projector/frame_0067.jpg\n",
            "amazon/images/projector/frame_0068.jpg\n",
            "amazon/images/projector/frame_0069.jpg\n",
            "amazon/images/projector/frame_0070.jpg\n",
            "amazon/images/projector/frame_0071.jpg\n",
            "amazon/images/projector/frame_0072.jpg\n",
            "amazon/images/projector/frame_0073.jpg\n",
            "amazon/images/projector/frame_0074.jpg\n",
            "amazon/images/projector/frame_0075.jpg\n",
            "amazon/images/projector/frame_0076.jpg\n",
            "amazon/images/projector/frame_0077.jpg\n",
            "amazon/images/projector/frame_0078.jpg\n",
            "amazon/images/projector/frame_0079.jpg\n",
            "amazon/images/projector/frame_0080.jpg\n",
            "amazon/images/projector/frame_0081.jpg\n",
            "amazon/images/projector/frame_0082.jpg\n",
            "amazon/images/projector/frame_0083.jpg\n",
            "amazon/images/projector/frame_0084.jpg\n",
            "amazon/images/projector/frame_0085.jpg\n",
            "amazon/images/projector/frame_0086.jpg\n",
            "amazon/images/projector/frame_0087.jpg\n",
            "amazon/images/projector/frame_0088.jpg\n",
            "amazon/images/projector/frame_0089.jpg\n",
            "amazon/images/projector/frame_0090.jpg\n",
            "amazon/images/projector/frame_0091.jpg\n",
            "amazon/images/projector/frame_0092.jpg\n",
            "amazon/images/projector/frame_0093.jpg\n",
            "amazon/images/projector/frame_0094.jpg\n",
            "amazon/images/projector/frame_0095.jpg\n",
            "amazon/images/projector/frame_0096.jpg\n",
            "amazon/images/projector/frame_0097.jpg\n",
            "amazon/images/projector/frame_0098.jpg\n",
            "amazon/images/punchers/frame_0001.jpg\n",
            "amazon/images/punchers/frame_0002.jpg\n",
            "amazon/images/punchers/frame_0003.jpg\n",
            "amazon/images/punchers/frame_0004.jpg\n",
            "amazon/images/punchers/frame_0005.jpg\n",
            "amazon/images/punchers/frame_0006.jpg\n",
            "amazon/images/punchers/frame_0007.jpg\n",
            "amazon/images/punchers/frame_0008.jpg\n",
            "amazon/images/punchers/frame_0009.jpg\n",
            "amazon/images/punchers/frame_0010.jpg\n",
            "amazon/images/punchers/frame_0011.jpg\n",
            "amazon/images/punchers/frame_0012.jpg\n",
            "amazon/images/punchers/frame_0013.jpg\n",
            "amazon/images/punchers/frame_0014.jpg\n",
            "amazon/images/punchers/frame_0015.jpg\n",
            "amazon/images/punchers/frame_0016.jpg\n",
            "amazon/images/punchers/frame_0017.jpg\n",
            "amazon/images/punchers/frame_0018.jpg\n",
            "amazon/images/punchers/frame_0019.jpg\n",
            "amazon/images/punchers/frame_0020.jpg\n",
            "amazon/images/punchers/frame_0021.jpg\n",
            "amazon/images/punchers/frame_0022.jpg\n",
            "amazon/images/punchers/frame_0023.jpg\n",
            "amazon/images/punchers/frame_0024.jpg\n",
            "amazon/images/punchers/frame_0025.jpg\n",
            "amazon/images/punchers/frame_0026.jpg\n",
            "amazon/images/punchers/frame_0027.jpg\n",
            "amazon/images/punchers/frame_0028.jpg\n",
            "amazon/images/punchers/frame_0029.jpg\n",
            "amazon/images/punchers/frame_0030.jpg\n",
            "amazon/images/punchers/frame_0031.jpg\n",
            "amazon/images/punchers/frame_0032.jpg\n",
            "amazon/images/punchers/frame_0033.jpg\n",
            "amazon/images/punchers/frame_0034.jpg\n",
            "amazon/images/punchers/frame_0035.jpg\n",
            "amazon/images/punchers/frame_0036.jpg\n",
            "amazon/images/punchers/frame_0037.jpg\n",
            "amazon/images/punchers/frame_0038.jpg\n",
            "amazon/images/punchers/frame_0039.jpg\n",
            "amazon/images/punchers/frame_0040.jpg\n",
            "amazon/images/punchers/frame_0041.jpg\n",
            "amazon/images/punchers/frame_0042.jpg\n",
            "amazon/images/punchers/frame_0043.jpg\n",
            "amazon/images/punchers/frame_0044.jpg\n",
            "amazon/images/punchers/frame_0045.jpg\n",
            "amazon/images/punchers/frame_0046.jpg\n",
            "amazon/images/punchers/frame_0047.jpg\n",
            "amazon/images/punchers/frame_0048.jpg\n",
            "amazon/images/punchers/frame_0049.jpg\n",
            "amazon/images/punchers/frame_0050.jpg\n",
            "amazon/images/punchers/frame_0051.jpg\n",
            "amazon/images/punchers/frame_0052.jpg\n",
            "amazon/images/punchers/frame_0053.jpg\n",
            "amazon/images/punchers/frame_0054.jpg\n",
            "amazon/images/punchers/frame_0055.jpg\n",
            "amazon/images/punchers/frame_0056.jpg\n",
            "amazon/images/punchers/frame_0057.jpg\n",
            "amazon/images/punchers/frame_0058.jpg\n",
            "amazon/images/punchers/frame_0059.jpg\n",
            "amazon/images/punchers/frame_0060.jpg\n",
            "amazon/images/punchers/frame_0061.jpg\n",
            "amazon/images/punchers/frame_0062.jpg\n",
            "amazon/images/punchers/frame_0063.jpg\n",
            "amazon/images/punchers/frame_0064.jpg\n",
            "amazon/images/punchers/frame_0065.jpg\n",
            "amazon/images/punchers/frame_0066.jpg\n",
            "amazon/images/punchers/frame_0067.jpg\n",
            "amazon/images/punchers/frame_0068.jpg\n",
            "amazon/images/punchers/frame_0069.jpg\n",
            "amazon/images/punchers/frame_0070.jpg\n",
            "amazon/images/punchers/frame_0071.jpg\n",
            "amazon/images/punchers/frame_0072.jpg\n",
            "amazon/images/punchers/frame_0073.jpg\n",
            "amazon/images/punchers/frame_0074.jpg\n",
            "amazon/images/punchers/frame_0075.jpg\n",
            "amazon/images/punchers/frame_0076.jpg\n",
            "amazon/images/punchers/frame_0077.jpg\n",
            "amazon/images/punchers/frame_0078.jpg\n",
            "amazon/images/punchers/frame_0079.jpg\n",
            "amazon/images/punchers/frame_0080.jpg\n",
            "amazon/images/punchers/frame_0081.jpg\n",
            "amazon/images/punchers/frame_0082.jpg\n",
            "amazon/images/punchers/frame_0083.jpg\n",
            "amazon/images/punchers/frame_0084.jpg\n",
            "amazon/images/punchers/frame_0085.jpg\n",
            "amazon/images/punchers/frame_0086.jpg\n",
            "amazon/images/punchers/frame_0087.jpg\n",
            "amazon/images/punchers/frame_0088.jpg\n",
            "amazon/images/punchers/frame_0089.jpg\n",
            "amazon/images/punchers/frame_0090.jpg\n",
            "amazon/images/punchers/frame_0091.jpg\n",
            "amazon/images/punchers/frame_0092.jpg\n",
            "amazon/images/punchers/frame_0093.jpg\n",
            "amazon/images/punchers/frame_0094.jpg\n",
            "amazon/images/punchers/frame_0095.jpg\n",
            "amazon/images/punchers/frame_0096.jpg\n",
            "amazon/images/punchers/frame_0097.jpg\n",
            "amazon/images/punchers/frame_0098.jpg\n",
            "amazon/images/ring_binder/frame_0001.jpg\n",
            "amazon/images/ring_binder/frame_0002.jpg\n",
            "amazon/images/ring_binder/frame_0003.jpg\n",
            "amazon/images/ring_binder/frame_0004.jpg\n",
            "amazon/images/ring_binder/frame_0005.jpg\n",
            "amazon/images/ring_binder/frame_0006.jpg\n",
            "amazon/images/ring_binder/frame_0007.jpg\n",
            "amazon/images/ring_binder/frame_0008.jpg\n",
            "amazon/images/ring_binder/frame_0009.jpg\n",
            "amazon/images/ring_binder/frame_0010.jpg\n",
            "amazon/images/ring_binder/frame_0011.jpg\n",
            "amazon/images/ring_binder/frame_0012.jpg\n",
            "amazon/images/ring_binder/frame_0013.jpg\n",
            "amazon/images/ring_binder/frame_0014.jpg\n",
            "amazon/images/ring_binder/frame_0015.jpg\n",
            "amazon/images/ring_binder/frame_0016.jpg\n",
            "amazon/images/ring_binder/frame_0017.jpg\n",
            "amazon/images/ring_binder/frame_0018.jpg\n",
            "amazon/images/ring_binder/frame_0019.jpg\n",
            "amazon/images/ring_binder/frame_0020.jpg\n",
            "amazon/images/ring_binder/frame_0021.jpg\n",
            "amazon/images/ring_binder/frame_0022.jpg\n",
            "amazon/images/ring_binder/frame_0023.jpg\n",
            "amazon/images/ring_binder/frame_0024.jpg\n",
            "amazon/images/ring_binder/frame_0025.jpg\n",
            "amazon/images/ring_binder/frame_0026.jpg\n",
            "amazon/images/ring_binder/frame_0027.jpg\n",
            "amazon/images/ring_binder/frame_0028.jpg\n",
            "amazon/images/ring_binder/frame_0029.jpg\n",
            "amazon/images/ring_binder/frame_0030.jpg\n",
            "amazon/images/ring_binder/frame_0031.jpg\n",
            "amazon/images/ring_binder/frame_0032.jpg\n",
            "amazon/images/ring_binder/frame_0033.jpg\n",
            "amazon/images/ring_binder/frame_0034.jpg\n",
            "amazon/images/ring_binder/frame_0035.jpg\n",
            "amazon/images/ring_binder/frame_0036.jpg\n",
            "amazon/images/ring_binder/frame_0037.jpg\n",
            "amazon/images/ring_binder/frame_0038.jpg\n",
            "amazon/images/ring_binder/frame_0039.jpg\n",
            "amazon/images/ring_binder/frame_0040.jpg\n",
            "amazon/images/ring_binder/frame_0041.jpg\n",
            "amazon/images/ring_binder/frame_0042.jpg\n",
            "amazon/images/ring_binder/frame_0043.jpg\n",
            "amazon/images/ring_binder/frame_0044.jpg\n",
            "amazon/images/ring_binder/frame_0045.jpg\n",
            "amazon/images/ring_binder/frame_0046.jpg\n",
            "amazon/images/ring_binder/frame_0047.jpg\n",
            "amazon/images/ring_binder/frame_0048.jpg\n",
            "amazon/images/ring_binder/frame_0049.jpg\n",
            "amazon/images/ring_binder/frame_0050.jpg\n",
            "amazon/images/ring_binder/frame_0051.jpg\n",
            "amazon/images/ring_binder/frame_0052.jpg\n",
            "amazon/images/ring_binder/frame_0053.jpg\n",
            "amazon/images/ring_binder/frame_0054.jpg\n",
            "amazon/images/ring_binder/frame_0055.jpg\n",
            "amazon/images/ring_binder/frame_0056.jpg\n",
            "amazon/images/ring_binder/frame_0057.jpg\n",
            "amazon/images/ring_binder/frame_0058.jpg\n",
            "amazon/images/ring_binder/frame_0059.jpg\n",
            "amazon/images/ring_binder/frame_0060.jpg\n",
            "amazon/images/ring_binder/frame_0061.jpg\n",
            "amazon/images/ring_binder/frame_0062.jpg\n",
            "amazon/images/ring_binder/frame_0063.jpg\n",
            "amazon/images/ring_binder/frame_0064.jpg\n",
            "amazon/images/ring_binder/frame_0065.jpg\n",
            "amazon/images/ring_binder/frame_0066.jpg\n",
            "amazon/images/ring_binder/frame_0067.jpg\n",
            "amazon/images/ring_binder/frame_0068.jpg\n",
            "amazon/images/ring_binder/frame_0069.jpg\n",
            "amazon/images/ring_binder/frame_0070.jpg\n",
            "amazon/images/ring_binder/frame_0071.jpg\n",
            "amazon/images/ring_binder/frame_0072.jpg\n",
            "amazon/images/ring_binder/frame_0073.jpg\n",
            "amazon/images/ring_binder/frame_0074.jpg\n",
            "amazon/images/ring_binder/frame_0075.jpg\n",
            "amazon/images/ring_binder/frame_0076.jpg\n",
            "amazon/images/ring_binder/frame_0077.jpg\n",
            "amazon/images/ring_binder/frame_0078.jpg\n",
            "amazon/images/ring_binder/frame_0079.jpg\n",
            "amazon/images/ring_binder/frame_0080.jpg\n",
            "amazon/images/ring_binder/frame_0081.jpg\n",
            "amazon/images/ring_binder/frame_0082.jpg\n",
            "amazon/images/ring_binder/frame_0083.jpg\n",
            "amazon/images/ring_binder/frame_0084.jpg\n",
            "amazon/images/ring_binder/frame_0085.jpg\n",
            "amazon/images/ring_binder/frame_0086.jpg\n",
            "amazon/images/ring_binder/frame_0087.jpg\n",
            "amazon/images/ring_binder/frame_0088.jpg\n",
            "amazon/images/ring_binder/frame_0089.jpg\n",
            "amazon/images/ring_binder/frame_0090.jpg\n",
            "amazon/images/ruler/frame_0001.jpg\n",
            "amazon/images/ruler/frame_0002.jpg\n",
            "amazon/images/ruler/frame_0003.jpg\n",
            "amazon/images/ruler/frame_0004.jpg\n",
            "amazon/images/ruler/frame_0005.jpg\n",
            "amazon/images/ruler/frame_0006.jpg\n",
            "amazon/images/ruler/frame_0007.jpg\n",
            "amazon/images/ruler/frame_0008.jpg\n",
            "amazon/images/ruler/frame_0009.jpg\n",
            "amazon/images/ruler/frame_0010.jpg\n",
            "amazon/images/ruler/frame_0011.jpg\n",
            "amazon/images/ruler/frame_0012.jpg\n",
            "amazon/images/ruler/frame_0013.jpg\n",
            "amazon/images/ruler/frame_0014.jpg\n",
            "amazon/images/ruler/frame_0015.jpg\n",
            "amazon/images/ruler/frame_0016.jpg\n",
            "amazon/images/ruler/frame_0017.jpg\n",
            "amazon/images/ruler/frame_0018.jpg\n",
            "amazon/images/ruler/frame_0019.jpg\n",
            "amazon/images/ruler/frame_0020.jpg\n",
            "amazon/images/ruler/frame_0021.jpg\n",
            "amazon/images/ruler/frame_0022.jpg\n",
            "amazon/images/ruler/frame_0023.jpg\n",
            "amazon/images/ruler/frame_0024.jpg\n",
            "amazon/images/ruler/frame_0025.jpg\n",
            "amazon/images/ruler/frame_0026.jpg\n",
            "amazon/images/ruler/frame_0027.jpg\n",
            "amazon/images/ruler/frame_0028.jpg\n",
            "amazon/images/ruler/frame_0029.jpg\n",
            "amazon/images/ruler/frame_0030.jpg\n",
            "amazon/images/ruler/frame_0031.jpg\n",
            "amazon/images/ruler/frame_0032.jpg\n",
            "amazon/images/ruler/frame_0033.jpg\n",
            "amazon/images/ruler/frame_0034.jpg\n",
            "amazon/images/ruler/frame_0035.jpg\n",
            "amazon/images/ruler/frame_0036.jpg\n",
            "amazon/images/ruler/frame_0037.jpg\n",
            "amazon/images/ruler/frame_0038.jpg\n",
            "amazon/images/ruler/frame_0039.jpg\n",
            "amazon/images/ruler/frame_0040.jpg\n",
            "amazon/images/ruler/frame_0041.jpg\n",
            "amazon/images/ruler/frame_0042.jpg\n",
            "amazon/images/ruler/frame_0043.jpg\n",
            "amazon/images/ruler/frame_0044.jpg\n",
            "amazon/images/ruler/frame_0045.jpg\n",
            "amazon/images/ruler/frame_0046.jpg\n",
            "amazon/images/ruler/frame_0047.jpg\n",
            "amazon/images/ruler/frame_0048.jpg\n",
            "amazon/images/ruler/frame_0049.jpg\n",
            "amazon/images/ruler/frame_0050.jpg\n",
            "amazon/images/ruler/frame_0051.jpg\n",
            "amazon/images/ruler/frame_0052.jpg\n",
            "amazon/images/ruler/frame_0053.jpg\n",
            "amazon/images/ruler/frame_0054.jpg\n",
            "amazon/images/ruler/frame_0055.jpg\n",
            "amazon/images/ruler/frame_0056.jpg\n",
            "amazon/images/ruler/frame_0057.jpg\n",
            "amazon/images/ruler/frame_0058.jpg\n",
            "amazon/images/ruler/frame_0059.jpg\n",
            "amazon/images/ruler/frame_0060.jpg\n",
            "amazon/images/ruler/frame_0061.jpg\n",
            "amazon/images/ruler/frame_0062.jpg\n",
            "amazon/images/ruler/frame_0063.jpg\n",
            "amazon/images/ruler/frame_0064.jpg\n",
            "amazon/images/ruler/frame_0065.jpg\n",
            "amazon/images/ruler/frame_0066.jpg\n",
            "amazon/images/ruler/frame_0067.jpg\n",
            "amazon/images/ruler/frame_0068.jpg\n",
            "amazon/images/ruler/frame_0069.jpg\n",
            "amazon/images/ruler/frame_0070.jpg\n",
            "amazon/images/ruler/frame_0071.jpg\n",
            "amazon/images/ruler/frame_0072.jpg\n",
            "amazon/images/ruler/frame_0073.jpg\n",
            "amazon/images/ruler/frame_0074.jpg\n",
            "amazon/images/ruler/frame_0075.jpg\n",
            "amazon/images/scissors/frame_0001.jpg\n",
            "amazon/images/scissors/frame_0002.jpg\n",
            "amazon/images/scissors/frame_0003.jpg\n",
            "amazon/images/scissors/frame_0004.jpg\n",
            "amazon/images/scissors/frame_0005.jpg\n",
            "amazon/images/scissors/frame_0006.jpg\n",
            "amazon/images/scissors/frame_0007.jpg\n",
            "amazon/images/scissors/frame_0008.jpg\n",
            "amazon/images/scissors/frame_0009.jpg\n",
            "amazon/images/scissors/frame_0010.jpg\n",
            "amazon/images/scissors/frame_0011.jpg\n",
            "amazon/images/scissors/frame_0012.jpg\n",
            "amazon/images/scissors/frame_0013.jpg\n",
            "amazon/images/scissors/frame_0014.jpg\n",
            "amazon/images/scissors/frame_0015.jpg\n",
            "amazon/images/scissors/frame_0016.jpg\n",
            "amazon/images/scissors/frame_0017.jpg\n",
            "amazon/images/scissors/frame_0018.jpg\n",
            "amazon/images/scissors/frame_0019.jpg\n",
            "amazon/images/scissors/frame_0020.jpg\n",
            "amazon/images/scissors/frame_0021.jpg\n",
            "amazon/images/scissors/frame_0022.jpg\n",
            "amazon/images/scissors/frame_0023.jpg\n",
            "amazon/images/scissors/frame_0024.jpg\n",
            "amazon/images/scissors/frame_0025.jpg\n",
            "amazon/images/scissors/frame_0026.jpg\n",
            "amazon/images/scissors/frame_0027.jpg\n",
            "amazon/images/scissors/frame_0028.jpg\n",
            "amazon/images/scissors/frame_0029.jpg\n",
            "amazon/images/scissors/frame_0030.jpg\n",
            "amazon/images/scissors/frame_0031.jpg\n",
            "amazon/images/scissors/frame_0032.jpg\n",
            "amazon/images/scissors/frame_0033.jpg\n",
            "amazon/images/scissors/frame_0034.jpg\n",
            "amazon/images/scissors/frame_0035.jpg\n",
            "amazon/images/scissors/frame_0036.jpg\n",
            "amazon/images/scissors/frame_0037.jpg\n",
            "amazon/images/scissors/frame_0038.jpg\n",
            "amazon/images/scissors/frame_0039.jpg\n",
            "amazon/images/scissors/frame_0040.jpg\n",
            "amazon/images/scissors/frame_0041.jpg\n",
            "amazon/images/scissors/frame_0042.jpg\n",
            "amazon/images/scissors/frame_0043.jpg\n",
            "amazon/images/scissors/frame_0044.jpg\n",
            "amazon/images/scissors/frame_0045.jpg\n",
            "amazon/images/scissors/frame_0046.jpg\n",
            "amazon/images/scissors/frame_0047.jpg\n",
            "amazon/images/scissors/frame_0048.jpg\n",
            "amazon/images/scissors/frame_0049.jpg\n",
            "amazon/images/scissors/frame_0050.jpg\n",
            "amazon/images/scissors/frame_0051.jpg\n",
            "amazon/images/scissors/frame_0052.jpg\n",
            "amazon/images/scissors/frame_0053.jpg\n",
            "amazon/images/scissors/frame_0054.jpg\n",
            "amazon/images/scissors/frame_0055.jpg\n",
            "amazon/images/scissors/frame_0056.jpg\n",
            "amazon/images/scissors/frame_0057.jpg\n",
            "amazon/images/scissors/frame_0058.jpg\n",
            "amazon/images/scissors/frame_0059.jpg\n",
            "amazon/images/scissors/frame_0060.jpg\n",
            "amazon/images/scissors/frame_0061.jpg\n",
            "amazon/images/scissors/frame_0062.jpg\n",
            "amazon/images/scissors/frame_0063.jpg\n",
            "amazon/images/scissors/frame_0064.jpg\n",
            "amazon/images/scissors/frame_0065.jpg\n",
            "amazon/images/scissors/frame_0066.jpg\n",
            "amazon/images/scissors/frame_0067.jpg\n",
            "amazon/images/scissors/frame_0068.jpg\n",
            "amazon/images/scissors/frame_0069.jpg\n",
            "amazon/images/scissors/frame_0070.jpg\n",
            "amazon/images/scissors/frame_0071.jpg\n",
            "amazon/images/scissors/frame_0072.jpg\n",
            "amazon/images/scissors/frame_0073.jpg\n",
            "amazon/images/scissors/frame_0074.jpg\n",
            "amazon/images/scissors/frame_0075.jpg\n",
            "amazon/images/scissors/frame_0076.jpg\n",
            "amazon/images/scissors/frame_0077.jpg\n",
            "amazon/images/scissors/frame_0078.jpg\n",
            "amazon/images/scissors/frame_0079.jpg\n",
            "amazon/images/scissors/frame_0080.jpg\n",
            "amazon/images/scissors/frame_0081.jpg\n",
            "amazon/images/scissors/frame_0082.jpg\n",
            "amazon/images/scissors/frame_0083.jpg\n",
            "amazon/images/scissors/frame_0084.jpg\n",
            "amazon/images/scissors/frame_0085.jpg\n",
            "amazon/images/scissors/frame_0086.jpg\n",
            "amazon/images/scissors/frame_0087.jpg\n",
            "amazon/images/scissors/frame_0088.jpg\n",
            "amazon/images/scissors/frame_0089.jpg\n",
            "amazon/images/scissors/frame_0090.jpg\n",
            "amazon/images/scissors/frame_0091.jpg\n",
            "amazon/images/scissors/frame_0092.jpg\n",
            "amazon/images/scissors/frame_0093.jpg\n",
            "amazon/images/scissors/frame_0094.jpg\n",
            "amazon/images/scissors/frame_0095.jpg\n",
            "amazon/images/scissors/frame_0096.jpg\n",
            "amazon/images/scissors/frame_0097.jpg\n",
            "amazon/images/scissors/frame_0098.jpg\n",
            "amazon/images/scissors/frame_0099.jpg\n",
            "amazon/images/scissors/frame_0100.jpg\n",
            "amazon/images/speaker/frame_0001.jpg\n",
            "amazon/images/speaker/frame_0002.jpg\n",
            "amazon/images/speaker/frame_0003.jpg\n",
            "amazon/images/speaker/frame_0004.jpg\n",
            "amazon/images/speaker/frame_0005.jpg\n",
            "amazon/images/speaker/frame_0006.jpg\n",
            "amazon/images/speaker/frame_0007.jpg\n",
            "amazon/images/speaker/frame_0008.jpg\n",
            "amazon/images/speaker/frame_0009.jpg\n",
            "amazon/images/speaker/frame_0010.jpg\n",
            "amazon/images/speaker/frame_0011.jpg\n",
            "amazon/images/speaker/frame_0012.jpg\n",
            "amazon/images/speaker/frame_0013.jpg\n",
            "amazon/images/speaker/frame_0014.jpg\n",
            "amazon/images/speaker/frame_0015.jpg\n",
            "amazon/images/speaker/frame_0016.jpg\n",
            "amazon/images/speaker/frame_0017.jpg\n",
            "amazon/images/speaker/frame_0018.jpg\n",
            "amazon/images/speaker/frame_0019.jpg\n",
            "amazon/images/speaker/frame_0020.jpg\n",
            "amazon/images/speaker/frame_0021.jpg\n",
            "amazon/images/speaker/frame_0022.jpg\n",
            "amazon/images/speaker/frame_0023.jpg\n",
            "amazon/images/speaker/frame_0024.jpg\n",
            "amazon/images/speaker/frame_0025.jpg\n",
            "amazon/images/speaker/frame_0026.jpg\n",
            "amazon/images/speaker/frame_0027.jpg\n",
            "amazon/images/speaker/frame_0028.jpg\n",
            "amazon/images/speaker/frame_0029.jpg\n",
            "amazon/images/speaker/frame_0030.jpg\n",
            "amazon/images/speaker/frame_0031.jpg\n",
            "amazon/images/speaker/frame_0032.jpg\n",
            "amazon/images/speaker/frame_0033.jpg\n",
            "amazon/images/speaker/frame_0034.jpg\n",
            "amazon/images/speaker/frame_0035.jpg\n",
            "amazon/images/speaker/frame_0036.jpg\n",
            "amazon/images/speaker/frame_0037.jpg\n",
            "amazon/images/speaker/frame_0038.jpg\n",
            "amazon/images/speaker/frame_0039.jpg\n",
            "amazon/images/speaker/frame_0040.jpg\n",
            "amazon/images/speaker/frame_0041.jpg\n",
            "amazon/images/speaker/frame_0042.jpg\n",
            "amazon/images/speaker/frame_0043.jpg\n",
            "amazon/images/speaker/frame_0044.jpg\n",
            "amazon/images/speaker/frame_0045.jpg\n",
            "amazon/images/speaker/frame_0046.jpg\n",
            "amazon/images/speaker/frame_0047.jpg\n",
            "amazon/images/speaker/frame_0048.jpg\n",
            "amazon/images/speaker/frame_0049.jpg\n",
            "amazon/images/speaker/frame_0050.jpg\n",
            "amazon/images/speaker/frame_0051.jpg\n",
            "amazon/images/speaker/frame_0052.jpg\n",
            "amazon/images/speaker/frame_0053.jpg\n",
            "amazon/images/speaker/frame_0054.jpg\n",
            "amazon/images/speaker/frame_0055.jpg\n",
            "amazon/images/speaker/frame_0056.jpg\n",
            "amazon/images/speaker/frame_0057.jpg\n",
            "amazon/images/speaker/frame_0058.jpg\n",
            "amazon/images/speaker/frame_0059.jpg\n",
            "amazon/images/speaker/frame_0060.jpg\n",
            "amazon/images/speaker/frame_0061.jpg\n",
            "amazon/images/speaker/frame_0062.jpg\n",
            "amazon/images/speaker/frame_0063.jpg\n",
            "amazon/images/speaker/frame_0064.jpg\n",
            "amazon/images/speaker/frame_0065.jpg\n",
            "amazon/images/speaker/frame_0066.jpg\n",
            "amazon/images/speaker/frame_0067.jpg\n",
            "amazon/images/speaker/frame_0068.jpg\n",
            "amazon/images/speaker/frame_0069.jpg\n",
            "amazon/images/speaker/frame_0070.jpg\n",
            "amazon/images/speaker/frame_0071.jpg\n",
            "amazon/images/speaker/frame_0072.jpg\n",
            "amazon/images/speaker/frame_0073.jpg\n",
            "amazon/images/speaker/frame_0074.jpg\n",
            "amazon/images/speaker/frame_0075.jpg\n",
            "amazon/images/speaker/frame_0076.jpg\n",
            "amazon/images/speaker/frame_0077.jpg\n",
            "amazon/images/speaker/frame_0078.jpg\n",
            "amazon/images/speaker/frame_0079.jpg\n",
            "amazon/images/speaker/frame_0080.jpg\n",
            "amazon/images/speaker/frame_0081.jpg\n",
            "amazon/images/speaker/frame_0082.jpg\n",
            "amazon/images/speaker/frame_0083.jpg\n",
            "amazon/images/speaker/frame_0084.jpg\n",
            "amazon/images/speaker/frame_0085.jpg\n",
            "amazon/images/speaker/frame_0086.jpg\n",
            "amazon/images/speaker/frame_0087.jpg\n",
            "amazon/images/speaker/frame_0088.jpg\n",
            "amazon/images/speaker/frame_0089.jpg\n",
            "amazon/images/speaker/frame_0090.jpg\n",
            "amazon/images/speaker/frame_0091.jpg\n",
            "amazon/images/speaker/frame_0092.jpg\n",
            "amazon/images/speaker/frame_0093.jpg\n",
            "amazon/images/speaker/frame_0094.jpg\n",
            "amazon/images/speaker/frame_0095.jpg\n",
            "amazon/images/speaker/frame_0096.jpg\n",
            "amazon/images/speaker/frame_0097.jpg\n",
            "amazon/images/speaker/frame_0098.jpg\n",
            "amazon/images/speaker/frame_0099.jpg\n",
            "amazon/images/stapler/frame_0001.jpg\n",
            "amazon/images/stapler/frame_0002.jpg\n",
            "amazon/images/stapler/frame_0003.jpg\n",
            "amazon/images/stapler/frame_0004.jpg\n",
            "amazon/images/stapler/frame_0005.jpg\n",
            "amazon/images/stapler/frame_0006.jpg\n",
            "amazon/images/stapler/frame_0007.jpg\n",
            "amazon/images/stapler/frame_0008.jpg\n",
            "amazon/images/stapler/frame_0009.jpg\n",
            "amazon/images/stapler/frame_0010.jpg\n",
            "amazon/images/stapler/frame_0011.jpg\n",
            "amazon/images/stapler/frame_0012.jpg\n",
            "amazon/images/stapler/frame_0013.jpg\n",
            "amazon/images/stapler/frame_0014.jpg\n",
            "amazon/images/stapler/frame_0015.jpg\n",
            "amazon/images/stapler/frame_0016.jpg\n",
            "amazon/images/stapler/frame_0017.jpg\n",
            "amazon/images/stapler/frame_0018.jpg\n",
            "amazon/images/stapler/frame_0019.jpg\n",
            "amazon/images/stapler/frame_0020.jpg\n",
            "amazon/images/stapler/frame_0021.jpg\n",
            "amazon/images/stapler/frame_0022.jpg\n",
            "amazon/images/stapler/frame_0023.jpg\n",
            "amazon/images/stapler/frame_0024.jpg\n",
            "amazon/images/stapler/frame_0025.jpg\n",
            "amazon/images/stapler/frame_0026.jpg\n",
            "amazon/images/stapler/frame_0027.jpg\n",
            "amazon/images/stapler/frame_0028.jpg\n",
            "amazon/images/stapler/frame_0029.jpg\n",
            "amazon/images/stapler/frame_0030.jpg\n",
            "amazon/images/stapler/frame_0031.jpg\n",
            "amazon/images/stapler/frame_0032.jpg\n",
            "amazon/images/stapler/frame_0033.jpg\n",
            "amazon/images/stapler/frame_0034.jpg\n",
            "amazon/images/stapler/frame_0035.jpg\n",
            "amazon/images/stapler/frame_0036.jpg\n",
            "amazon/images/stapler/frame_0037.jpg\n",
            "amazon/images/stapler/frame_0038.jpg\n",
            "amazon/images/stapler/frame_0039.jpg\n",
            "amazon/images/stapler/frame_0040.jpg\n",
            "amazon/images/stapler/frame_0041.jpg\n",
            "amazon/images/stapler/frame_0042.jpg\n",
            "amazon/images/stapler/frame_0043.jpg\n",
            "amazon/images/stapler/frame_0044.jpg\n",
            "amazon/images/stapler/frame_0045.jpg\n",
            "amazon/images/stapler/frame_0046.jpg\n",
            "amazon/images/stapler/frame_0047.jpg\n",
            "amazon/images/stapler/frame_0048.jpg\n",
            "amazon/images/stapler/frame_0049.jpg\n",
            "amazon/images/stapler/frame_0050.jpg\n",
            "amazon/images/stapler/frame_0051.jpg\n",
            "amazon/images/stapler/frame_0052.jpg\n",
            "amazon/images/stapler/frame_0053.jpg\n",
            "amazon/images/stapler/frame_0054.jpg\n",
            "amazon/images/stapler/frame_0055.jpg\n",
            "amazon/images/stapler/frame_0056.jpg\n",
            "amazon/images/stapler/frame_0057.jpg\n",
            "amazon/images/stapler/frame_0058.jpg\n",
            "amazon/images/stapler/frame_0059.jpg\n",
            "amazon/images/stapler/frame_0060.jpg\n",
            "amazon/images/stapler/frame_0061.jpg\n",
            "amazon/images/stapler/frame_0062.jpg\n",
            "amazon/images/stapler/frame_0063.jpg\n",
            "amazon/images/stapler/frame_0064.jpg\n",
            "amazon/images/stapler/frame_0065.jpg\n",
            "amazon/images/stapler/frame_0066.jpg\n",
            "amazon/images/stapler/frame_0067.jpg\n",
            "amazon/images/stapler/frame_0068.jpg\n",
            "amazon/images/stapler/frame_0069.jpg\n",
            "amazon/images/stapler/frame_0070.jpg\n",
            "amazon/images/stapler/frame_0071.jpg\n",
            "amazon/images/stapler/frame_0072.jpg\n",
            "amazon/images/stapler/frame_0073.jpg\n",
            "amazon/images/stapler/frame_0074.jpg\n",
            "amazon/images/stapler/frame_0075.jpg\n",
            "amazon/images/stapler/frame_0076.jpg\n",
            "amazon/images/stapler/frame_0077.jpg\n",
            "amazon/images/stapler/frame_0078.jpg\n",
            "amazon/images/stapler/frame_0079.jpg\n",
            "amazon/images/stapler/frame_0080.jpg\n",
            "amazon/images/stapler/frame_0081.jpg\n",
            "amazon/images/stapler/frame_0082.jpg\n",
            "amazon/images/stapler/frame_0083.jpg\n",
            "amazon/images/stapler/frame_0084.jpg\n",
            "amazon/images/stapler/frame_0085.jpg\n",
            "amazon/images/stapler/frame_0086.jpg\n",
            "amazon/images/stapler/frame_0087.jpg\n",
            "amazon/images/stapler/frame_0088.jpg\n",
            "amazon/images/stapler/frame_0089.jpg\n",
            "amazon/images/stapler/frame_0090.jpg\n",
            "amazon/images/stapler/frame_0091.jpg\n",
            "amazon/images/stapler/frame_0092.jpg\n",
            "amazon/images/stapler/frame_0093.jpg\n",
            "amazon/images/stapler/frame_0094.jpg\n",
            "amazon/images/stapler/frame_0095.jpg\n",
            "amazon/images/stapler/frame_0096.jpg\n",
            "amazon/images/stapler/frame_0097.jpg\n",
            "amazon/images/stapler/frame_0098.jpg\n",
            "amazon/images/stapler/frame_0099.jpg\n",
            "amazon/images/tape_dispenser/frame_0001.jpg\n",
            "amazon/images/tape_dispenser/frame_0002.jpg\n",
            "amazon/images/tape_dispenser/frame_0003.jpg\n",
            "amazon/images/tape_dispenser/frame_0004.jpg\n",
            "amazon/images/tape_dispenser/frame_0005.jpg\n",
            "amazon/images/tape_dispenser/frame_0006.jpg\n",
            "amazon/images/tape_dispenser/frame_0007.jpg\n",
            "amazon/images/tape_dispenser/frame_0008.jpg\n",
            "amazon/images/tape_dispenser/frame_0009.jpg\n",
            "amazon/images/tape_dispenser/frame_0010.jpg\n",
            "amazon/images/tape_dispenser/frame_0011.jpg\n",
            "amazon/images/tape_dispenser/frame_0012.jpg\n",
            "amazon/images/tape_dispenser/frame_0013.jpg\n",
            "amazon/images/tape_dispenser/frame_0014.jpg\n",
            "amazon/images/tape_dispenser/frame_0015.jpg\n",
            "amazon/images/tape_dispenser/frame_0016.jpg\n",
            "amazon/images/tape_dispenser/frame_0017.jpg\n",
            "amazon/images/tape_dispenser/frame_0018.jpg\n",
            "amazon/images/tape_dispenser/frame_0019.jpg\n",
            "amazon/images/tape_dispenser/frame_0020.jpg\n",
            "amazon/images/tape_dispenser/frame_0021.jpg\n",
            "amazon/images/tape_dispenser/frame_0022.jpg\n",
            "amazon/images/tape_dispenser/frame_0023.jpg\n",
            "amazon/images/tape_dispenser/frame_0024.jpg\n",
            "amazon/images/tape_dispenser/frame_0025.jpg\n",
            "amazon/images/tape_dispenser/frame_0026.jpg\n",
            "amazon/images/tape_dispenser/frame_0027.jpg\n",
            "amazon/images/tape_dispenser/frame_0028.jpg\n",
            "amazon/images/tape_dispenser/frame_0029.jpg\n",
            "amazon/images/tape_dispenser/frame_0030.jpg\n",
            "amazon/images/tape_dispenser/frame_0031.jpg\n",
            "amazon/images/tape_dispenser/frame_0032.jpg\n",
            "amazon/images/tape_dispenser/frame_0033.jpg\n",
            "amazon/images/tape_dispenser/frame_0034.jpg\n",
            "amazon/images/tape_dispenser/frame_0035.jpg\n",
            "amazon/images/tape_dispenser/frame_0036.jpg\n",
            "amazon/images/tape_dispenser/frame_0037.jpg\n",
            "amazon/images/tape_dispenser/frame_0038.jpg\n",
            "amazon/images/tape_dispenser/frame_0039.jpg\n",
            "amazon/images/tape_dispenser/frame_0040.jpg\n",
            "amazon/images/tape_dispenser/frame_0041.jpg\n",
            "amazon/images/tape_dispenser/frame_0042.jpg\n",
            "amazon/images/tape_dispenser/frame_0043.jpg\n",
            "amazon/images/tape_dispenser/frame_0044.jpg\n",
            "amazon/images/tape_dispenser/frame_0045.jpg\n",
            "amazon/images/tape_dispenser/frame_0046.jpg\n",
            "amazon/images/tape_dispenser/frame_0047.jpg\n",
            "amazon/images/tape_dispenser/frame_0048.jpg\n",
            "amazon/images/tape_dispenser/frame_0049.jpg\n",
            "amazon/images/tape_dispenser/frame_0050.jpg\n",
            "amazon/images/tape_dispenser/frame_0051.jpg\n",
            "amazon/images/tape_dispenser/frame_0052.jpg\n",
            "amazon/images/tape_dispenser/frame_0053.jpg\n",
            "amazon/images/tape_dispenser/frame_0054.jpg\n",
            "amazon/images/tape_dispenser/frame_0055.jpg\n",
            "amazon/images/tape_dispenser/frame_0056.jpg\n",
            "amazon/images/tape_dispenser/frame_0057.jpg\n",
            "amazon/images/tape_dispenser/frame_0058.jpg\n",
            "amazon/images/tape_dispenser/frame_0059.jpg\n",
            "amazon/images/tape_dispenser/frame_0060.jpg\n",
            "amazon/images/tape_dispenser/frame_0061.jpg\n",
            "amazon/images/tape_dispenser/frame_0062.jpg\n",
            "amazon/images/tape_dispenser/frame_0063.jpg\n",
            "amazon/images/tape_dispenser/frame_0064.jpg\n",
            "amazon/images/tape_dispenser/frame_0065.jpg\n",
            "amazon/images/tape_dispenser/frame_0066.jpg\n",
            "amazon/images/tape_dispenser/frame_0067.jpg\n",
            "amazon/images/tape_dispenser/frame_0068.jpg\n",
            "amazon/images/tape_dispenser/frame_0069.jpg\n",
            "amazon/images/tape_dispenser/frame_0070.jpg\n",
            "amazon/images/tape_dispenser/frame_0071.jpg\n",
            "amazon/images/tape_dispenser/frame_0072.jpg\n",
            "amazon/images/tape_dispenser/frame_0073.jpg\n",
            "amazon/images/tape_dispenser/frame_0074.jpg\n",
            "amazon/images/tape_dispenser/frame_0075.jpg\n",
            "amazon/images/tape_dispenser/frame_0076.jpg\n",
            "amazon/images/tape_dispenser/frame_0077.jpg\n",
            "amazon/images/tape_dispenser/frame_0078.jpg\n",
            "amazon/images/tape_dispenser/frame_0079.jpg\n",
            "amazon/images/tape_dispenser/frame_0080.jpg\n",
            "amazon/images/tape_dispenser/frame_0081.jpg\n",
            "amazon/images/tape_dispenser/frame_0082.jpg\n",
            "amazon/images/tape_dispenser/frame_0083.jpg\n",
            "amazon/images/tape_dispenser/frame_0084.jpg\n",
            "amazon/images/tape_dispenser/frame_0085.jpg\n",
            "amazon/images/tape_dispenser/frame_0086.jpg\n",
            "amazon/images/tape_dispenser/frame_0087.jpg\n",
            "amazon/images/tape_dispenser/frame_0088.jpg\n",
            "amazon/images/tape_dispenser/frame_0089.jpg\n",
            "amazon/images/tape_dispenser/frame_0090.jpg\n",
            "amazon/images/tape_dispenser/frame_0091.jpg\n",
            "amazon/images/tape_dispenser/frame_0092.jpg\n",
            "amazon/images/tape_dispenser/frame_0093.jpg\n",
            "amazon/images/tape_dispenser/frame_0094.jpg\n",
            "amazon/images/tape_dispenser/frame_0095.jpg\n",
            "amazon/images/tape_dispenser/frame_0096.jpg\n",
            "amazon/images/trash_can/frame_0001.jpg\n",
            "amazon/images/trash_can/frame_0002.jpg\n",
            "amazon/images/trash_can/frame_0003.jpg\n",
            "amazon/images/trash_can/frame_0004.jpg\n",
            "amazon/images/trash_can/frame_0005.jpg\n",
            "amazon/images/trash_can/frame_0006.jpg\n",
            "amazon/images/trash_can/frame_0007.jpg\n",
            "amazon/images/trash_can/frame_0008.jpg\n",
            "amazon/images/trash_can/frame_0009.jpg\n",
            "amazon/images/trash_can/frame_0010.jpg\n",
            "amazon/images/trash_can/frame_0011.jpg\n",
            "amazon/images/trash_can/frame_0012.jpg\n",
            "amazon/images/trash_can/frame_0013.jpg\n",
            "amazon/images/trash_can/frame_0014.jpg\n",
            "amazon/images/trash_can/frame_0015.jpg\n",
            "amazon/images/trash_can/frame_0016.jpg\n",
            "amazon/images/trash_can/frame_0017.jpg\n",
            "amazon/images/trash_can/frame_0018.jpg\n",
            "amazon/images/trash_can/frame_0019.jpg\n",
            "amazon/images/trash_can/frame_0020.jpg\n",
            "amazon/images/trash_can/frame_0021.jpg\n",
            "amazon/images/trash_can/frame_0022.jpg\n",
            "amazon/images/trash_can/frame_0023.jpg\n",
            "amazon/images/trash_can/frame_0024.jpg\n",
            "amazon/images/trash_can/frame_0025.jpg\n",
            "amazon/images/trash_can/frame_0026.jpg\n",
            "amazon/images/trash_can/frame_0027.jpg\n",
            "amazon/images/trash_can/frame_0028.jpg\n",
            "amazon/images/trash_can/frame_0029.jpg\n",
            "amazon/images/trash_can/frame_0030.jpg\n",
            "amazon/images/trash_can/frame_0031.jpg\n",
            "amazon/images/trash_can/frame_0032.jpg\n",
            "amazon/images/trash_can/frame_0033.jpg\n",
            "amazon/images/trash_can/frame_0034.jpg\n",
            "amazon/images/trash_can/frame_0035.jpg\n",
            "amazon/images/trash_can/frame_0036.jpg\n",
            "amazon/images/trash_can/frame_0037.jpg\n",
            "amazon/images/trash_can/frame_0038.jpg\n",
            "amazon/images/trash_can/frame_0039.jpg\n",
            "amazon/images/trash_can/frame_0040.jpg\n",
            "amazon/images/trash_can/frame_0041.jpg\n",
            "amazon/images/trash_can/frame_0042.jpg\n",
            "amazon/images/trash_can/frame_0043.jpg\n",
            "amazon/images/trash_can/frame_0044.jpg\n",
            "amazon/images/trash_can/frame_0045.jpg\n",
            "amazon/images/trash_can/frame_0046.jpg\n",
            "amazon/images/trash_can/frame_0047.jpg\n",
            "amazon/images/trash_can/frame_0048.jpg\n",
            "amazon/images/trash_can/frame_0049.jpg\n",
            "amazon/images/trash_can/frame_0050.jpg\n",
            "amazon/images/trash_can/frame_0051.jpg\n",
            "amazon/images/trash_can/frame_0052.jpg\n",
            "amazon/images/trash_can/frame_0053.jpg\n",
            "amazon/images/trash_can/frame_0054.jpg\n",
            "amazon/images/trash_can/frame_0055.jpg\n",
            "amazon/images/trash_can/frame_0056.jpg\n",
            "amazon/images/trash_can/frame_0057.jpg\n",
            "amazon/images/trash_can/frame_0058.jpg\n",
            "amazon/images/trash_can/frame_0059.jpg\n",
            "amazon/images/trash_can/frame_0060.jpg\n",
            "amazon/images/trash_can/frame_0061.jpg\n",
            "amazon/images/trash_can/frame_0062.jpg\n",
            "amazon/images/trash_can/frame_0063.jpg\n",
            "amazon/images/trash_can/frame_0064.jpg\n",
            "dslr/images/back_pack/frame_0001.jpg\n",
            "dslr/images/back_pack/frame_0002.jpg\n",
            "dslr/images/back_pack/frame_0003.jpg\n",
            "dslr/images/back_pack/frame_0004.jpg\n",
            "dslr/images/back_pack/frame_0005.jpg\n",
            "dslr/images/back_pack/frame_0006.jpg\n",
            "dslr/images/back_pack/frame_0007.jpg\n",
            "dslr/images/back_pack/frame_0008.jpg\n",
            "dslr/images/back_pack/frame_0009.jpg\n",
            "dslr/images/back_pack/frame_0010.jpg\n",
            "dslr/images/back_pack/frame_0011.jpg\n",
            "dslr/images/back_pack/frame_0012.jpg\n",
            "dslr/images/bike/frame_0001.jpg\n",
            "dslr/images/bike/frame_0002.jpg\n",
            "dslr/images/bike/frame_0003.jpg\n",
            "dslr/images/bike/frame_0004.jpg\n",
            "dslr/images/bike/frame_0005.jpg\n",
            "dslr/images/bike/frame_0006.jpg\n",
            "dslr/images/bike/frame_0007.jpg\n",
            "dslr/images/bike/frame_0008.jpg\n",
            "dslr/images/bike/frame_0009.jpg\n",
            "dslr/images/bike/frame_0010.jpg\n",
            "dslr/images/bike/frame_0011.jpg\n",
            "dslr/images/bike/frame_0012.jpg\n",
            "dslr/images/bike/frame_0013.jpg\n",
            "dslr/images/bike/frame_0014.jpg\n",
            "dslr/images/bike/frame_0015.jpg\n",
            "dslr/images/bike/frame_0016.jpg\n",
            "dslr/images/bike/frame_0017.jpg\n",
            "dslr/images/bike/frame_0018.jpg\n",
            "dslr/images/bike/frame_0019.jpg\n",
            "dslr/images/bike/frame_0020.jpg\n",
            "dslr/images/bike/frame_0021.jpg\n",
            "dslr/images/bike_helmet/frame_0001.jpg\n",
            "dslr/images/bike_helmet/frame_0002.jpg\n",
            "dslr/images/bike_helmet/frame_0003.jpg\n",
            "dslr/images/bike_helmet/frame_0004.jpg\n",
            "dslr/images/bike_helmet/frame_0005.jpg\n",
            "dslr/images/bike_helmet/frame_0006.jpg\n",
            "dslr/images/bike_helmet/frame_0007.jpg\n",
            "dslr/images/bike_helmet/frame_0008.jpg\n",
            "dslr/images/bike_helmet/frame_0009.jpg\n",
            "dslr/images/bike_helmet/frame_0010.jpg\n",
            "dslr/images/bike_helmet/frame_0011.jpg\n",
            "dslr/images/bike_helmet/frame_0012.jpg\n",
            "dslr/images/bike_helmet/frame_0013.jpg\n",
            "dslr/images/bike_helmet/frame_0014.jpg\n",
            "dslr/images/bike_helmet/frame_0015.jpg\n",
            "dslr/images/bike_helmet/frame_0016.jpg\n",
            "dslr/images/bike_helmet/frame_0017.jpg\n",
            "dslr/images/bike_helmet/frame_0018.jpg\n",
            "dslr/images/bike_helmet/frame_0019.jpg\n",
            "dslr/images/bike_helmet/frame_0020.jpg\n",
            "dslr/images/bike_helmet/frame_0021.jpg\n",
            "dslr/images/bike_helmet/frame_0022.jpg\n",
            "dslr/images/bike_helmet/frame_0023.jpg\n",
            "dslr/images/bike_helmet/frame_0024.jpg\n",
            "dslr/images/bookcase/frame_0001.jpg\n",
            "dslr/images/bookcase/frame_0002.jpg\n",
            "dslr/images/bookcase/frame_0003.jpg\n",
            "dslr/images/bookcase/frame_0004.jpg\n",
            "dslr/images/bookcase/frame_0005.jpg\n",
            "dslr/images/bookcase/frame_0006.jpg\n",
            "dslr/images/bookcase/frame_0007.jpg\n",
            "dslr/images/bookcase/frame_0008.jpg\n",
            "dslr/images/bookcase/frame_0009.jpg\n",
            "dslr/images/bookcase/frame_0010.jpg\n",
            "dslr/images/bookcase/frame_0011.jpg\n",
            "dslr/images/bookcase/frame_0012.jpg\n",
            "dslr/images/bottle/frame_0001.jpg\n",
            "dslr/images/bottle/frame_0002.jpg\n",
            "dslr/images/bottle/frame_0003.jpg\n",
            "dslr/images/bottle/frame_0004.jpg\n",
            "dslr/images/bottle/frame_0005.jpg\n",
            "dslr/images/bottle/frame_0006.jpg\n",
            "dslr/images/bottle/frame_0007.jpg\n",
            "dslr/images/bottle/frame_0008.jpg\n",
            "dslr/images/bottle/frame_0009.jpg\n",
            "dslr/images/bottle/frame_0010.jpg\n",
            "dslr/images/bottle/frame_0011.jpg\n",
            "dslr/images/bottle/frame_0012.jpg\n",
            "dslr/images/bottle/frame_0013.jpg\n",
            "dslr/images/bottle/frame_0014.jpg\n",
            "dslr/images/bottle/frame_0015.jpg\n",
            "dslr/images/bottle/frame_0016.jpg\n",
            "dslr/images/calculator/frame_0001.jpg\n",
            "dslr/images/calculator/frame_0002.jpg\n",
            "dslr/images/calculator/frame_0003.jpg\n",
            "dslr/images/calculator/frame_0004.jpg\n",
            "dslr/images/calculator/frame_0005.jpg\n",
            "dslr/images/calculator/frame_0006.jpg\n",
            "dslr/images/calculator/frame_0007.jpg\n",
            "dslr/images/calculator/frame_0008.jpg\n",
            "dslr/images/calculator/frame_0009.jpg\n",
            "dslr/images/calculator/frame_0010.jpg\n",
            "dslr/images/calculator/frame_0011.jpg\n",
            "dslr/images/calculator/frame_0012.jpg\n",
            "dslr/images/desk_chair/frame_0001.jpg\n",
            "dslr/images/desk_chair/frame_0002.jpg\n",
            "dslr/images/desk_chair/frame_0003.jpg\n",
            "dslr/images/desk_chair/frame_0004.jpg\n",
            "dslr/images/desk_chair/frame_0005.jpg\n",
            "dslr/images/desk_chair/frame_0006.jpg\n",
            "dslr/images/desk_chair/frame_0007.jpg\n",
            "dslr/images/desk_chair/frame_0008.jpg\n",
            "dslr/images/desk_chair/frame_0009.jpg\n",
            "dslr/images/desk_chair/frame_0010.jpg\n",
            "dslr/images/desk_chair/frame_0011.jpg\n",
            "dslr/images/desk_chair/frame_0012.jpg\n",
            "dslr/images/desk_chair/frame_0013.jpg\n",
            "dslr/images/desk_lamp/frame_0001.jpg\n",
            "dslr/images/desk_lamp/frame_0002.jpg\n",
            "dslr/images/desk_lamp/frame_0003.jpg\n",
            "dslr/images/desk_lamp/frame_0004.jpg\n",
            "dslr/images/desk_lamp/frame_0005.jpg\n",
            "dslr/images/desk_lamp/frame_0006.jpg\n",
            "dslr/images/desk_lamp/frame_0007.jpg\n",
            "dslr/images/desk_lamp/frame_0008.jpg\n",
            "dslr/images/desk_lamp/frame_0009.jpg\n",
            "dslr/images/desk_lamp/frame_0010.jpg\n",
            "dslr/images/desk_lamp/frame_0011.jpg\n",
            "dslr/images/desk_lamp/frame_0012.jpg\n",
            "dslr/images/desk_lamp/frame_0013.jpg\n",
            "dslr/images/desk_lamp/frame_0014.jpg\n",
            "dslr/images/desktop_computer/frame_0001.jpg\n",
            "dslr/images/desktop_computer/frame_0002.jpg\n",
            "dslr/images/desktop_computer/frame_0003.jpg\n",
            "dslr/images/desktop_computer/frame_0004.jpg\n",
            "dslr/images/desktop_computer/frame_0005.jpg\n",
            "dslr/images/desktop_computer/frame_0006.jpg\n",
            "dslr/images/desktop_computer/frame_0007.jpg\n",
            "dslr/images/desktop_computer/frame_0008.jpg\n",
            "dslr/images/desktop_computer/frame_0009.jpg\n",
            "dslr/images/desktop_computer/frame_0010.jpg\n",
            "dslr/images/desktop_computer/frame_0011.jpg\n",
            "dslr/images/desktop_computer/frame_0012.jpg\n",
            "dslr/images/desktop_computer/frame_0013.jpg\n",
            "dslr/images/desktop_computer/frame_0014.jpg\n",
            "dslr/images/desktop_computer/frame_0015.jpg\n",
            "dslr/images/file_cabinet/frame_0001.jpg\n",
            "dslr/images/file_cabinet/frame_0002.jpg\n",
            "dslr/images/file_cabinet/frame_0003.jpg\n",
            "dslr/images/file_cabinet/frame_0004.jpg\n",
            "dslr/images/file_cabinet/frame_0005.jpg\n",
            "dslr/images/file_cabinet/frame_0006.jpg\n",
            "dslr/images/file_cabinet/frame_0007.jpg\n",
            "dslr/images/file_cabinet/frame_0008.jpg\n",
            "dslr/images/file_cabinet/frame_0009.jpg\n",
            "dslr/images/file_cabinet/frame_0010.jpg\n",
            "dslr/images/file_cabinet/frame_0011.jpg\n",
            "dslr/images/file_cabinet/frame_0012.jpg\n",
            "dslr/images/file_cabinet/frame_0013.jpg\n",
            "dslr/images/file_cabinet/frame_0014.jpg\n",
            "dslr/images/file_cabinet/frame_0015.jpg\n",
            "dslr/images/headphones/frame_0001.jpg\n",
            "dslr/images/headphones/frame_0002.jpg\n",
            "dslr/images/headphones/frame_0003.jpg\n",
            "dslr/images/headphones/frame_0004.jpg\n",
            "dslr/images/headphones/frame_0005.jpg\n",
            "dslr/images/headphones/frame_0006.jpg\n",
            "dslr/images/headphones/frame_0007.jpg\n",
            "dslr/images/headphones/frame_0008.jpg\n",
            "dslr/images/headphones/frame_0009.jpg\n",
            "dslr/images/headphones/frame_0010.jpg\n",
            "dslr/images/headphones/frame_0011.jpg\n",
            "dslr/images/headphones/frame_0012.jpg\n",
            "dslr/images/headphones/frame_0013.jpg\n",
            "dslr/images/keyboard/frame_0001.jpg\n",
            "dslr/images/keyboard/frame_0002.jpg\n",
            "dslr/images/keyboard/frame_0003.jpg\n",
            "dslr/images/keyboard/frame_0004.jpg\n",
            "dslr/images/keyboard/frame_0005.jpg\n",
            "dslr/images/keyboard/frame_0006.jpg\n",
            "dslr/images/keyboard/frame_0007.jpg\n",
            "dslr/images/keyboard/frame_0008.jpg\n",
            "dslr/images/keyboard/frame_0009.jpg\n",
            "dslr/images/keyboard/frame_0010.jpg\n",
            "dslr/images/laptop_computer/frame_0001.jpg\n",
            "dslr/images/laptop_computer/frame_0002.jpg\n",
            "dslr/images/laptop_computer/frame_0003.jpg\n",
            "dslr/images/laptop_computer/frame_0004.jpg\n",
            "dslr/images/laptop_computer/frame_0005.jpg\n",
            "dslr/images/laptop_computer/frame_0006.jpg\n",
            "dslr/images/laptop_computer/frame_0007.jpg\n",
            "dslr/images/laptop_computer/frame_0008.jpg\n",
            "dslr/images/laptop_computer/frame_0009.jpg\n",
            "dslr/images/laptop_computer/frame_0010.jpg\n",
            "dslr/images/laptop_computer/frame_0011.jpg\n",
            "dslr/images/laptop_computer/frame_0012.jpg\n",
            "dslr/images/laptop_computer/frame_0013.jpg\n",
            "dslr/images/laptop_computer/frame_0014.jpg\n",
            "dslr/images/laptop_computer/frame_0015.jpg\n",
            "dslr/images/laptop_computer/frame_0016.jpg\n",
            "dslr/images/laptop_computer/frame_0017.jpg\n",
            "dslr/images/laptop_computer/frame_0018.jpg\n",
            "dslr/images/laptop_computer/frame_0019.jpg\n",
            "dslr/images/laptop_computer/frame_0020.jpg\n",
            "dslr/images/laptop_computer/frame_0021.jpg\n",
            "dslr/images/laptop_computer/frame_0022.jpg\n",
            "dslr/images/laptop_computer/frame_0023.jpg\n",
            "dslr/images/laptop_computer/frame_0024.jpg\n",
            "dslr/images/letter_tray/frame_0001.jpg\n",
            "dslr/images/letter_tray/frame_0002.jpg\n",
            "dslr/images/letter_tray/frame_0003.jpg\n",
            "dslr/images/letter_tray/frame_0004.jpg\n",
            "dslr/images/letter_tray/frame_0005.jpg\n",
            "dslr/images/letter_tray/frame_0006.jpg\n",
            "dslr/images/letter_tray/frame_0007.jpg\n",
            "dslr/images/letter_tray/frame_0008.jpg\n",
            "dslr/images/letter_tray/frame_0009.jpg\n",
            "dslr/images/letter_tray/frame_0010.jpg\n",
            "dslr/images/letter_tray/frame_0011.jpg\n",
            "dslr/images/letter_tray/frame_0012.jpg\n",
            "dslr/images/letter_tray/frame_0013.jpg\n",
            "dslr/images/letter_tray/frame_0014.jpg\n",
            "dslr/images/letter_tray/frame_0015.jpg\n",
            "dslr/images/letter_tray/frame_0016.jpg\n",
            "dslr/images/mobile_phone/frame_0001.jpg\n",
            "dslr/images/mobile_phone/frame_0002.jpg\n",
            "dslr/images/mobile_phone/frame_0003.jpg\n",
            "dslr/images/mobile_phone/frame_0004.jpg\n",
            "dslr/images/mobile_phone/frame_0005.jpg\n",
            "dslr/images/mobile_phone/frame_0006.jpg\n",
            "dslr/images/mobile_phone/frame_0007.jpg\n",
            "dslr/images/mobile_phone/frame_0008.jpg\n",
            "dslr/images/mobile_phone/frame_0009.jpg\n",
            "dslr/images/mobile_phone/frame_0010.jpg\n",
            "dslr/images/mobile_phone/frame_0011.jpg\n",
            "dslr/images/mobile_phone/frame_0012.jpg\n",
            "dslr/images/mobile_phone/frame_0013.jpg\n",
            "dslr/images/mobile_phone/frame_0014.jpg\n",
            "dslr/images/mobile_phone/frame_0015.jpg\n",
            "dslr/images/mobile_phone/frame_0016.jpg\n",
            "dslr/images/mobile_phone/frame_0017.jpg\n",
            "dslr/images/mobile_phone/frame_0018.jpg\n",
            "dslr/images/mobile_phone/frame_0019.jpg\n",
            "dslr/images/mobile_phone/frame_0020.jpg\n",
            "dslr/images/mobile_phone/frame_0021.jpg\n",
            "dslr/images/mobile_phone/frame_0022.jpg\n",
            "dslr/images/mobile_phone/frame_0023.jpg\n",
            "dslr/images/mobile_phone/frame_0024.jpg\n",
            "dslr/images/mobile_phone/frame_0025.jpg\n",
            "dslr/images/mobile_phone/frame_0026.jpg\n",
            "dslr/images/mobile_phone/frame_0027.jpg\n",
            "dslr/images/mobile_phone/frame_0028.jpg\n",
            "dslr/images/mobile_phone/frame_0029.jpg\n",
            "dslr/images/mobile_phone/frame_0030.jpg\n",
            "dslr/images/mobile_phone/frame_0031.jpg\n",
            "dslr/images/monitor/frame_0001.jpg\n",
            "dslr/images/monitor/frame_0002.jpg\n",
            "dslr/images/monitor/frame_0003.jpg\n",
            "dslr/images/monitor/frame_0004.jpg\n",
            "dslr/images/monitor/frame_0005.jpg\n",
            "dslr/images/monitor/frame_0006.jpg\n",
            "dslr/images/monitor/frame_0007.jpg\n",
            "dslr/images/monitor/frame_0008.jpg\n",
            "dslr/images/monitor/frame_0009.jpg\n",
            "dslr/images/monitor/frame_0010.jpg\n",
            "dslr/images/monitor/frame_0011.jpg\n",
            "dslr/images/monitor/frame_0012.jpg\n",
            "dslr/images/monitor/frame_0013.jpg\n",
            "dslr/images/monitor/frame_0014.jpg\n",
            "dslr/images/monitor/frame_0015.jpg\n",
            "dslr/images/monitor/frame_0016.jpg\n",
            "dslr/images/monitor/frame_0017.jpg\n",
            "dslr/images/monitor/frame_0018.jpg\n",
            "dslr/images/monitor/frame_0019.jpg\n",
            "dslr/images/monitor/frame_0020.jpg\n",
            "dslr/images/monitor/frame_0021.jpg\n",
            "dslr/images/monitor/frame_0022.jpg\n",
            "dslr/images/mouse/frame_0001.jpg\n",
            "dslr/images/mouse/frame_0002.jpg\n",
            "dslr/images/mouse/frame_0003.jpg\n",
            "dslr/images/mouse/frame_0004.jpg\n",
            "dslr/images/mouse/frame_0005.jpg\n",
            "dslr/images/mouse/frame_0006.jpg\n",
            "dslr/images/mouse/frame_0007.jpg\n",
            "dslr/images/mouse/frame_0008.jpg\n",
            "dslr/images/mouse/frame_0009.jpg\n",
            "dslr/images/mouse/frame_0010.jpg\n",
            "dslr/images/mouse/frame_0011.jpg\n",
            "dslr/images/mouse/frame_0012.jpg\n",
            "dslr/images/mug/frame_0001.jpg\n",
            "dslr/images/mug/frame_0002.jpg\n",
            "dslr/images/mug/frame_0003.jpg\n",
            "dslr/images/mug/frame_0004.jpg\n",
            "dslr/images/mug/frame_0005.jpg\n",
            "dslr/images/mug/frame_0006.jpg\n",
            "dslr/images/mug/frame_0007.jpg\n",
            "dslr/images/mug/frame_0008.jpg\n",
            "dslr/images/paper_notebook/frame_0001.jpg\n",
            "dslr/images/paper_notebook/frame_0002.jpg\n",
            "dslr/images/paper_notebook/frame_0003.jpg\n",
            "dslr/images/paper_notebook/frame_0004.jpg\n",
            "dslr/images/paper_notebook/frame_0005.jpg\n",
            "dslr/images/paper_notebook/frame_0006.jpg\n",
            "dslr/images/paper_notebook/frame_0007.jpg\n",
            "dslr/images/paper_notebook/frame_0008.jpg\n",
            "dslr/images/paper_notebook/frame_0009.jpg\n",
            "dslr/images/paper_notebook/frame_0010.jpg\n",
            "dslr/images/pen/frame_0001.jpg\n",
            "dslr/images/pen/frame_0002.jpg\n",
            "dslr/images/pen/frame_0003.jpg\n",
            "dslr/images/pen/frame_0004.jpg\n",
            "dslr/images/pen/frame_0005.jpg\n",
            "dslr/images/pen/frame_0006.jpg\n",
            "dslr/images/pen/frame_0007.jpg\n",
            "dslr/images/pen/frame_0008.jpg\n",
            "dslr/images/pen/frame_0009.jpg\n",
            "dslr/images/pen/frame_0010.jpg\n",
            "dslr/images/phone/frame_0001.jpg\n",
            "dslr/images/phone/frame_0002.jpg\n",
            "dslr/images/phone/frame_0003.jpg\n",
            "dslr/images/phone/frame_0004.jpg\n",
            "dslr/images/phone/frame_0005.jpg\n",
            "dslr/images/phone/frame_0006.jpg\n",
            "dslr/images/phone/frame_0007.jpg\n",
            "dslr/images/phone/frame_0008.jpg\n",
            "dslr/images/phone/frame_0009.jpg\n",
            "dslr/images/phone/frame_0010.jpg\n",
            "dslr/images/phone/frame_0011.jpg\n",
            "dslr/images/phone/frame_0012.jpg\n",
            "dslr/images/phone/frame_0013.jpg\n",
            "dslr/images/printer/frame_0001.jpg\n",
            "dslr/images/printer/frame_0002.jpg\n",
            "dslr/images/printer/frame_0003.jpg\n",
            "dslr/images/printer/frame_0004.jpg\n",
            "dslr/images/printer/frame_0005.jpg\n",
            "dslr/images/printer/frame_0006.jpg\n",
            "dslr/images/printer/frame_0007.jpg\n",
            "dslr/images/printer/frame_0008.jpg\n",
            "dslr/images/printer/frame_0009.jpg\n",
            "dslr/images/printer/frame_0010.jpg\n",
            "dslr/images/printer/frame_0011.jpg\n",
            "dslr/images/printer/frame_0012.jpg\n",
            "dslr/images/printer/frame_0013.jpg\n",
            "dslr/images/printer/frame_0014.jpg\n",
            "dslr/images/printer/frame_0015.jpg\n",
            "dslr/images/projector/frame_0001.jpg\n",
            "dslr/images/projector/frame_0002.jpg\n",
            "dslr/images/projector/frame_0003.jpg\n",
            "dslr/images/projector/frame_0004.jpg\n",
            "dslr/images/projector/frame_0005.jpg\n",
            "dslr/images/projector/frame_0006.jpg\n",
            "dslr/images/projector/frame_0007.jpg\n",
            "dslr/images/projector/frame_0008.jpg\n",
            "dslr/images/projector/frame_0009.jpg\n",
            "dslr/images/projector/frame_0010.jpg\n",
            "dslr/images/projector/frame_0011.jpg\n",
            "dslr/images/projector/frame_0012.jpg\n",
            "dslr/images/projector/frame_0013.jpg\n",
            "dslr/images/projector/frame_0014.jpg\n",
            "dslr/images/projector/frame_0015.jpg\n",
            "dslr/images/projector/frame_0016.jpg\n",
            "dslr/images/projector/frame_0017.jpg\n",
            "dslr/images/projector/frame_0018.jpg\n",
            "dslr/images/projector/frame_0019.jpg\n",
            "dslr/images/projector/frame_0020.jpg\n",
            "dslr/images/projector/frame_0021.jpg\n",
            "dslr/images/projector/frame_0022.jpg\n",
            "dslr/images/projector/frame_0023.jpg\n",
            "dslr/images/punchers/frame_0001.jpg\n",
            "dslr/images/punchers/frame_0002.jpg\n",
            "dslr/images/punchers/frame_0003.jpg\n",
            "dslr/images/punchers/frame_0004.jpg\n",
            "dslr/images/punchers/frame_0005.jpg\n",
            "dslr/images/punchers/frame_0006.jpg\n",
            "dslr/images/punchers/frame_0007.jpg\n",
            "dslr/images/punchers/frame_0008.jpg\n",
            "dslr/images/punchers/frame_0009.jpg\n",
            "dslr/images/punchers/frame_0010.jpg\n",
            "dslr/images/punchers/frame_0011.jpg\n",
            "dslr/images/punchers/frame_0012.jpg\n",
            "dslr/images/punchers/frame_0013.jpg\n",
            "dslr/images/punchers/frame_0014.jpg\n",
            "dslr/images/punchers/frame_0015.jpg\n",
            "dslr/images/punchers/frame_0016.jpg\n",
            "dslr/images/punchers/frame_0017.jpg\n",
            "dslr/images/punchers/frame_0018.jpg\n",
            "dslr/images/ring_binder/frame_0001.jpg\n",
            "dslr/images/ring_binder/frame_0002.jpg\n",
            "dslr/images/ring_binder/frame_0003.jpg\n",
            "dslr/images/ring_binder/frame_0004.jpg\n",
            "dslr/images/ring_binder/frame_0005.jpg\n",
            "dslr/images/ring_binder/frame_0006.jpg\n",
            "dslr/images/ring_binder/frame_0007.jpg\n",
            "dslr/images/ring_binder/frame_0008.jpg\n",
            "dslr/images/ring_binder/frame_0009.jpg\n",
            "dslr/images/ring_binder/frame_0010.jpg\n",
            "dslr/images/ruler/frame_0001.jpg\n",
            "dslr/images/ruler/frame_0002.jpg\n",
            "dslr/images/ruler/frame_0003.jpg\n",
            "dslr/images/ruler/frame_0004.jpg\n",
            "dslr/images/ruler/frame_0005.jpg\n",
            "dslr/images/ruler/frame_0006.jpg\n",
            "dslr/images/ruler/frame_0007.jpg\n",
            "dslr/images/scissors/frame_0001.jpg\n",
            "dslr/images/scissors/frame_0002.jpg\n",
            "dslr/images/scissors/frame_0003.jpg\n",
            "dslr/images/scissors/frame_0004.jpg\n",
            "dslr/images/scissors/frame_0005.jpg\n",
            "dslr/images/scissors/frame_0006.jpg\n",
            "dslr/images/scissors/frame_0007.jpg\n",
            "dslr/images/scissors/frame_0008.jpg\n",
            "dslr/images/scissors/frame_0009.jpg\n",
            "dslr/images/scissors/frame_0010.jpg\n",
            "dslr/images/scissors/frame_0011.jpg\n",
            "dslr/images/scissors/frame_0012.jpg\n",
            "dslr/images/scissors/frame_0013.jpg\n",
            "dslr/images/scissors/frame_0014.jpg\n",
            "dslr/images/scissors/frame_0015.jpg\n",
            "dslr/images/scissors/frame_0016.jpg\n",
            "dslr/images/scissors/frame_0017.jpg\n",
            "dslr/images/scissors/frame_0018.jpg\n",
            "dslr/images/speaker/frame_0001.jpg\n",
            "dslr/images/speaker/frame_0002.jpg\n",
            "dslr/images/speaker/frame_0003.jpg\n",
            "dslr/images/speaker/frame_0004.jpg\n",
            "dslr/images/speaker/frame_0005.jpg\n",
            "dslr/images/speaker/frame_0006.jpg\n",
            "dslr/images/speaker/frame_0007.jpg\n",
            "dslr/images/speaker/frame_0008.jpg\n",
            "dslr/images/speaker/frame_0009.jpg\n",
            "dslr/images/speaker/frame_0010.jpg\n",
            "dslr/images/speaker/frame_0011.jpg\n",
            "dslr/images/speaker/frame_0012.jpg\n",
            "dslr/images/speaker/frame_0013.jpg\n",
            "dslr/images/speaker/frame_0014.jpg\n",
            "dslr/images/speaker/frame_0015.jpg\n",
            "dslr/images/speaker/frame_0016.jpg\n",
            "dslr/images/speaker/frame_0017.jpg\n",
            "dslr/images/speaker/frame_0018.jpg\n",
            "dslr/images/speaker/frame_0019.jpg\n",
            "dslr/images/speaker/frame_0020.jpg\n",
            "dslr/images/speaker/frame_0021.jpg\n",
            "dslr/images/speaker/frame_0022.jpg\n",
            "dslr/images/speaker/frame_0023.jpg\n",
            "dslr/images/speaker/frame_0024.jpg\n",
            "dslr/images/speaker/frame_0025.jpg\n",
            "dslr/images/speaker/frame_0026.jpg\n",
            "dslr/images/stapler/frame_0001.jpg\n",
            "dslr/images/stapler/frame_0002.jpg\n",
            "dslr/images/stapler/frame_0003.jpg\n",
            "dslr/images/stapler/frame_0004.jpg\n",
            "dslr/images/stapler/frame_0005.jpg\n",
            "dslr/images/stapler/frame_0006.jpg\n",
            "dslr/images/stapler/frame_0007.jpg\n",
            "dslr/images/stapler/frame_0008.jpg\n",
            "dslr/images/stapler/frame_0009.jpg\n",
            "dslr/images/stapler/frame_0010.jpg\n",
            "dslr/images/stapler/frame_0011.jpg\n",
            "dslr/images/stapler/frame_0012.jpg\n",
            "dslr/images/stapler/frame_0013.jpg\n",
            "dslr/images/stapler/frame_0014.jpg\n",
            "dslr/images/stapler/frame_0015.jpg\n",
            "dslr/images/stapler/frame_0016.jpg\n",
            "dslr/images/stapler/frame_0017.jpg\n",
            "dslr/images/stapler/frame_0018.jpg\n",
            "dslr/images/stapler/frame_0019.jpg\n",
            "dslr/images/stapler/frame_0020.jpg\n",
            "dslr/images/stapler/frame_0021.jpg\n",
            "dslr/images/tape_dispenser/frame_0001.jpg\n",
            "dslr/images/tape_dispenser/frame_0002.jpg\n",
            "dslr/images/tape_dispenser/frame_0003.jpg\n",
            "dslr/images/tape_dispenser/frame_0004.jpg\n",
            "dslr/images/tape_dispenser/frame_0005.jpg\n",
            "dslr/images/tape_dispenser/frame_0006.jpg\n",
            "dslr/images/tape_dispenser/frame_0007.jpg\n",
            "dslr/images/tape_dispenser/frame_0008.jpg\n",
            "dslr/images/tape_dispenser/frame_0009.jpg\n",
            "dslr/images/tape_dispenser/frame_0010.jpg\n",
            "dslr/images/tape_dispenser/frame_0011.jpg\n",
            "dslr/images/tape_dispenser/frame_0012.jpg\n",
            "dslr/images/tape_dispenser/frame_0013.jpg\n",
            "dslr/images/tape_dispenser/frame_0014.jpg\n",
            "dslr/images/tape_dispenser/frame_0015.jpg\n",
            "dslr/images/tape_dispenser/frame_0016.jpg\n",
            "dslr/images/tape_dispenser/frame_0017.jpg\n",
            "dslr/images/tape_dispenser/frame_0018.jpg\n",
            "dslr/images/tape_dispenser/frame_0019.jpg\n",
            "dslr/images/tape_dispenser/frame_0020.jpg\n",
            "dslr/images/tape_dispenser/frame_0021.jpg\n",
            "dslr/images/tape_dispenser/frame_0022.jpg\n",
            "dslr/images/trash_can/frame_0001.jpg\n",
            "dslr/images/trash_can/frame_0002.jpg\n",
            "dslr/images/trash_can/frame_0003.jpg\n",
            "dslr/images/trash_can/frame_0004.jpg\n",
            "dslr/images/trash_can/frame_0005.jpg\n",
            "dslr/images/trash_can/frame_0006.jpg\n",
            "dslr/images/trash_can/frame_0007.jpg\n",
            "dslr/images/trash_can/frame_0008.jpg\n",
            "dslr/images/trash_can/frame_0009.jpg\n",
            "dslr/images/trash_can/frame_0010.jpg\n",
            "dslr/images/trash_can/frame_0011.jpg\n",
            "dslr/images/trash_can/frame_0012.jpg\n",
            "dslr/images/trash_can/frame_0013.jpg\n",
            "dslr/images/trash_can/frame_0014.jpg\n",
            "dslr/images/trash_can/frame_0015.jpg\n",
            "webcam/images/back_pack/frame_0001.jpg\n",
            "webcam/images/back_pack/frame_0002.jpg\n",
            "webcam/images/back_pack/frame_0003.jpg\n",
            "webcam/images/back_pack/frame_0004.jpg\n",
            "webcam/images/back_pack/frame_0005.jpg\n",
            "webcam/images/back_pack/frame_0006.jpg\n",
            "webcam/images/back_pack/frame_0007.jpg\n",
            "webcam/images/back_pack/frame_0008.jpg\n",
            "webcam/images/back_pack/frame_0009.jpg\n",
            "webcam/images/back_pack/frame_0010.jpg\n",
            "webcam/images/back_pack/frame_0011.jpg\n",
            "webcam/images/back_pack/frame_0012.jpg\n",
            "webcam/images/back_pack/frame_0013.jpg\n",
            "webcam/images/back_pack/frame_0014.jpg\n",
            "webcam/images/back_pack/frame_0015.jpg\n",
            "webcam/images/back_pack/frame_0016.jpg\n",
            "webcam/images/back_pack/frame_0017.jpg\n",
            "webcam/images/back_pack/frame_0018.jpg\n",
            "webcam/images/back_pack/frame_0019.jpg\n",
            "webcam/images/back_pack/frame_0020.jpg\n",
            "webcam/images/back_pack/frame_0021.jpg\n",
            "webcam/images/back_pack/frame_0022.jpg\n",
            "webcam/images/back_pack/frame_0023.jpg\n",
            "webcam/images/back_pack/frame_0024.jpg\n",
            "webcam/images/back_pack/frame_0025.jpg\n",
            "webcam/images/back_pack/frame_0026.jpg\n",
            "webcam/images/back_pack/frame_0027.jpg\n",
            "webcam/images/back_pack/frame_0028.jpg\n",
            "webcam/images/back_pack/frame_0029.jpg\n",
            "webcam/images/bike/frame_0001.jpg\n",
            "webcam/images/bike/frame_0002.jpg\n",
            "webcam/images/bike/frame_0003.jpg\n",
            "webcam/images/bike/frame_0004.jpg\n",
            "webcam/images/bike/frame_0005.jpg\n",
            "webcam/images/bike/frame_0006.jpg\n",
            "webcam/images/bike/frame_0007.jpg\n",
            "webcam/images/bike/frame_0008.jpg\n",
            "webcam/images/bike/frame_0009.jpg\n",
            "webcam/images/bike/frame_0010.jpg\n",
            "webcam/images/bike/frame_0011.jpg\n",
            "webcam/images/bike/frame_0012.jpg\n",
            "webcam/images/bike/frame_0013.jpg\n",
            "webcam/images/bike/frame_0014.jpg\n",
            "webcam/images/bike/frame_0015.jpg\n",
            "webcam/images/bike/frame_0016.jpg\n",
            "webcam/images/bike/frame_0017.jpg\n",
            "webcam/images/bike/frame_0018.jpg\n",
            "webcam/images/bike/frame_0019.jpg\n",
            "webcam/images/bike/frame_0020.jpg\n",
            "webcam/images/bike/frame_0021.jpg\n",
            "webcam/images/bike_helmet/frame_0001.jpg\n",
            "webcam/images/bike_helmet/frame_0002.jpg\n",
            "webcam/images/bike_helmet/frame_0003.jpg\n",
            "webcam/images/bike_helmet/frame_0004.jpg\n",
            "webcam/images/bike_helmet/frame_0005.jpg\n",
            "webcam/images/bike_helmet/frame_0006.jpg\n",
            "webcam/images/bike_helmet/frame_0007.jpg\n",
            "webcam/images/bike_helmet/frame_0008.jpg\n",
            "webcam/images/bike_helmet/frame_0009.jpg\n",
            "webcam/images/bike_helmet/frame_0010.jpg\n",
            "webcam/images/bike_helmet/frame_0011.jpg\n",
            "webcam/images/bike_helmet/frame_0012.jpg\n",
            "webcam/images/bike_helmet/frame_0013.jpg\n",
            "webcam/images/bike_helmet/frame_0014.jpg\n",
            "webcam/images/bike_helmet/frame_0015.jpg\n",
            "webcam/images/bike_helmet/frame_0016.jpg\n",
            "webcam/images/bike_helmet/frame_0017.jpg\n",
            "webcam/images/bike_helmet/frame_0018.jpg\n",
            "webcam/images/bike_helmet/frame_0019.jpg\n",
            "webcam/images/bike_helmet/frame_0020.jpg\n",
            "webcam/images/bike_helmet/frame_0021.jpg\n",
            "webcam/images/bike_helmet/frame_0022.jpg\n",
            "webcam/images/bike_helmet/frame_0023.jpg\n",
            "webcam/images/bike_helmet/frame_0024.jpg\n",
            "webcam/images/bike_helmet/frame_0025.jpg\n",
            "webcam/images/bike_helmet/frame_0026.jpg\n",
            "webcam/images/bike_helmet/frame_0027.jpg\n",
            "webcam/images/bike_helmet/frame_0028.jpg\n",
            "webcam/images/bookcase/frame_0001.jpg\n",
            "webcam/images/bookcase/frame_0002.jpg\n",
            "webcam/images/bookcase/frame_0003.jpg\n",
            "webcam/images/bookcase/frame_0004.jpg\n",
            "webcam/images/bookcase/frame_0005.jpg\n",
            "webcam/images/bookcase/frame_0006.jpg\n",
            "webcam/images/bookcase/frame_0007.jpg\n",
            "webcam/images/bookcase/frame_0008.jpg\n",
            "webcam/images/bookcase/frame_0009.jpg\n",
            "webcam/images/bookcase/frame_0010.jpg\n",
            "webcam/images/bookcase/frame_0011.jpg\n",
            "webcam/images/bookcase/frame_0012.jpg\n",
            "webcam/images/bottle/frame_0001.jpg\n",
            "webcam/images/bottle/frame_0002.jpg\n",
            "webcam/images/bottle/frame_0003.jpg\n",
            "webcam/images/bottle/frame_0004.jpg\n",
            "webcam/images/bottle/frame_0005.jpg\n",
            "webcam/images/bottle/frame_0006.jpg\n",
            "webcam/images/bottle/frame_0007.jpg\n",
            "webcam/images/bottle/frame_0008.jpg\n",
            "webcam/images/bottle/frame_0009.jpg\n",
            "webcam/images/bottle/frame_0010.jpg\n",
            "webcam/images/bottle/frame_0011.jpg\n",
            "webcam/images/bottle/frame_0012.jpg\n",
            "webcam/images/bottle/frame_0013.jpg\n",
            "webcam/images/bottle/frame_0014.jpg\n",
            "webcam/images/bottle/frame_0015.jpg\n",
            "webcam/images/bottle/frame_0016.jpg\n",
            "webcam/images/calculator/frame_0001.jpg\n",
            "webcam/images/calculator/frame_0002.jpg\n",
            "webcam/images/calculator/frame_0003.jpg\n",
            "webcam/images/calculator/frame_0004.jpg\n",
            "webcam/images/calculator/frame_0005.jpg\n",
            "webcam/images/calculator/frame_0006.jpg\n",
            "webcam/images/calculator/frame_0007.jpg\n",
            "webcam/images/calculator/frame_0008.jpg\n",
            "webcam/images/calculator/frame_0009.jpg\n",
            "webcam/images/calculator/frame_0010.jpg\n",
            "webcam/images/calculator/frame_0011.jpg\n",
            "webcam/images/calculator/frame_0012.jpg\n",
            "webcam/images/calculator/frame_0013.jpg\n",
            "webcam/images/calculator/frame_0014.jpg\n",
            "webcam/images/calculator/frame_0015.jpg\n",
            "webcam/images/calculator/frame_0016.jpg\n",
            "webcam/images/calculator/frame_0017.jpg\n",
            "webcam/images/calculator/frame_0018.jpg\n",
            "webcam/images/calculator/frame_0019.jpg\n",
            "webcam/images/calculator/frame_0020.jpg\n",
            "webcam/images/calculator/frame_0021.jpg\n",
            "webcam/images/calculator/frame_0022.jpg\n",
            "webcam/images/calculator/frame_0023.jpg\n",
            "webcam/images/calculator/frame_0024.jpg\n",
            "webcam/images/calculator/frame_0025.jpg\n",
            "webcam/images/calculator/frame_0026.jpg\n",
            "webcam/images/calculator/frame_0027.jpg\n",
            "webcam/images/calculator/frame_0028.jpg\n",
            "webcam/images/calculator/frame_0029.jpg\n",
            "webcam/images/calculator/frame_0030.jpg\n",
            "webcam/images/calculator/frame_0031.jpg\n",
            "webcam/images/desk_chair/frame_0001.jpg\n",
            "webcam/images/desk_chair/frame_0002.jpg\n",
            "webcam/images/desk_chair/frame_0003.jpg\n",
            "webcam/images/desk_chair/frame_0004.jpg\n",
            "webcam/images/desk_chair/frame_0005.jpg\n",
            "webcam/images/desk_chair/frame_0006.jpg\n",
            "webcam/images/desk_chair/frame_0007.jpg\n",
            "webcam/images/desk_chair/frame_0008.jpg\n",
            "webcam/images/desk_chair/frame_0009.jpg\n",
            "webcam/images/desk_chair/frame_0010.jpg\n",
            "webcam/images/desk_chair/frame_0011.jpg\n",
            "webcam/images/desk_chair/frame_0012.jpg\n",
            "webcam/images/desk_chair/frame_0013.jpg\n",
            "webcam/images/desk_chair/frame_0014.jpg\n",
            "webcam/images/desk_chair/frame_0015.jpg\n",
            "webcam/images/desk_chair/frame_0016.jpg\n",
            "webcam/images/desk_chair/frame_0017.jpg\n",
            "webcam/images/desk_chair/frame_0018.jpg\n",
            "webcam/images/desk_chair/frame_0019.jpg\n",
            "webcam/images/desk_chair/frame_0020.jpg\n",
            "webcam/images/desk_chair/frame_0021.jpg\n",
            "webcam/images/desk_chair/frame_0022.jpg\n",
            "webcam/images/desk_chair/frame_0023.jpg\n",
            "webcam/images/desk_chair/frame_0024.jpg\n",
            "webcam/images/desk_chair/frame_0025.jpg\n",
            "webcam/images/desk_chair/frame_0026.jpg\n",
            "webcam/images/desk_chair/frame_0027.jpg\n",
            "webcam/images/desk_chair/frame_0028.jpg\n",
            "webcam/images/desk_chair/frame_0029.jpg\n",
            "webcam/images/desk_chair/frame_0030.jpg\n",
            "webcam/images/desk_chair/frame_0031.jpg\n",
            "webcam/images/desk_chair/frame_0032.jpg\n",
            "webcam/images/desk_chair/frame_0033.jpg\n",
            "webcam/images/desk_chair/frame_0034.jpg\n",
            "webcam/images/desk_chair/frame_0035.jpg\n",
            "webcam/images/desk_chair/frame_0036.jpg\n",
            "webcam/images/desk_chair/frame_0037.jpg\n",
            "webcam/images/desk_chair/frame_0038.jpg\n",
            "webcam/images/desk_chair/frame_0039.jpg\n",
            "webcam/images/desk_chair/frame_0040.jpg\n",
            "webcam/images/desk_lamp/frame_0001.jpg\n",
            "webcam/images/desk_lamp/frame_0002.jpg\n",
            "webcam/images/desk_lamp/frame_0003.jpg\n",
            "webcam/images/desk_lamp/frame_0004.jpg\n",
            "webcam/images/desk_lamp/frame_0005.jpg\n",
            "webcam/images/desk_lamp/frame_0006.jpg\n",
            "webcam/images/desk_lamp/frame_0007.jpg\n",
            "webcam/images/desk_lamp/frame_0008.jpg\n",
            "webcam/images/desk_lamp/frame_0009.jpg\n",
            "webcam/images/desk_lamp/frame_0010.jpg\n",
            "webcam/images/desk_lamp/frame_0011.jpg\n",
            "webcam/images/desk_lamp/frame_0012.jpg\n",
            "webcam/images/desk_lamp/frame_0013.jpg\n",
            "webcam/images/desk_lamp/frame_0014.jpg\n",
            "webcam/images/desk_lamp/frame_0015.jpg\n",
            "webcam/images/desk_lamp/frame_0016.jpg\n",
            "webcam/images/desk_lamp/frame_0017.jpg\n",
            "webcam/images/desk_lamp/frame_0018.jpg\n",
            "webcam/images/desktop_computer/frame_0001.jpg\n",
            "webcam/images/desktop_computer/frame_0002.jpg\n",
            "webcam/images/desktop_computer/frame_0003.jpg\n",
            "webcam/images/desktop_computer/frame_0004.jpg\n",
            "webcam/images/desktop_computer/frame_0005.jpg\n",
            "webcam/images/desktop_computer/frame_0006.jpg\n",
            "webcam/images/desktop_computer/frame_0007.jpg\n",
            "webcam/images/desktop_computer/frame_0008.jpg\n",
            "webcam/images/desktop_computer/frame_0009.jpg\n",
            "webcam/images/desktop_computer/frame_0010.jpg\n",
            "webcam/images/desktop_computer/frame_0011.jpg\n",
            "webcam/images/desktop_computer/frame_0012.jpg\n",
            "webcam/images/desktop_computer/frame_0013.jpg\n",
            "webcam/images/desktop_computer/frame_0014.jpg\n",
            "webcam/images/desktop_computer/frame_0015.jpg\n",
            "webcam/images/desktop_computer/frame_0016.jpg\n",
            "webcam/images/desktop_computer/frame_0017.jpg\n",
            "webcam/images/desktop_computer/frame_0018.jpg\n",
            "webcam/images/desktop_computer/frame_0019.jpg\n",
            "webcam/images/desktop_computer/frame_0020.jpg\n",
            "webcam/images/desktop_computer/frame_0021.jpg\n",
            "webcam/images/file_cabinet/frame_0001.jpg\n",
            "webcam/images/file_cabinet/frame_0002.jpg\n",
            "webcam/images/file_cabinet/frame_0003.jpg\n",
            "webcam/images/file_cabinet/frame_0004.jpg\n",
            "webcam/images/file_cabinet/frame_0005.jpg\n",
            "webcam/images/file_cabinet/frame_0006.jpg\n",
            "webcam/images/file_cabinet/frame_0007.jpg\n",
            "webcam/images/file_cabinet/frame_0008.jpg\n",
            "webcam/images/file_cabinet/frame_0009.jpg\n",
            "webcam/images/file_cabinet/frame_0010.jpg\n",
            "webcam/images/file_cabinet/frame_0011.jpg\n",
            "webcam/images/file_cabinet/frame_0012.jpg\n",
            "webcam/images/file_cabinet/frame_0013.jpg\n",
            "webcam/images/file_cabinet/frame_0014.jpg\n",
            "webcam/images/file_cabinet/frame_0015.jpg\n",
            "webcam/images/file_cabinet/frame_0016.jpg\n",
            "webcam/images/file_cabinet/frame_0017.jpg\n",
            "webcam/images/file_cabinet/frame_0018.jpg\n",
            "webcam/images/file_cabinet/frame_0019.jpg\n",
            "webcam/images/headphones/frame_0001.jpg\n",
            "webcam/images/headphones/frame_0002.jpg\n",
            "webcam/images/headphones/frame_0003.jpg\n",
            "webcam/images/headphones/frame_0004.jpg\n",
            "webcam/images/headphones/frame_0005.jpg\n",
            "webcam/images/headphones/frame_0006.jpg\n",
            "webcam/images/headphones/frame_0007.jpg\n",
            "webcam/images/headphones/frame_0008.jpg\n",
            "webcam/images/headphones/frame_0009.jpg\n",
            "webcam/images/headphones/frame_0010.jpg\n",
            "webcam/images/headphones/frame_0011.jpg\n",
            "webcam/images/headphones/frame_0012.jpg\n",
            "webcam/images/headphones/frame_0013.jpg\n",
            "webcam/images/headphones/frame_0014.jpg\n",
            "webcam/images/headphones/frame_0015.jpg\n",
            "webcam/images/headphones/frame_0016.jpg\n",
            "webcam/images/headphones/frame_0017.jpg\n",
            "webcam/images/headphones/frame_0018.jpg\n",
            "webcam/images/headphones/frame_0019.jpg\n",
            "webcam/images/headphones/frame_0020.jpg\n",
            "webcam/images/headphones/frame_0021.jpg\n",
            "webcam/images/headphones/frame_0022.jpg\n",
            "webcam/images/headphones/frame_0023.jpg\n",
            "webcam/images/headphones/frame_0024.jpg\n",
            "webcam/images/headphones/frame_0025.jpg\n",
            "webcam/images/headphones/frame_0026.jpg\n",
            "webcam/images/headphones/frame_0027.jpg\n",
            "webcam/images/keyboard/frame_0001.jpg\n",
            "webcam/images/keyboard/frame_0002.jpg\n",
            "webcam/images/keyboard/frame_0003.jpg\n",
            "webcam/images/keyboard/frame_0004.jpg\n",
            "webcam/images/keyboard/frame_0005.jpg\n",
            "webcam/images/keyboard/frame_0006.jpg\n",
            "webcam/images/keyboard/frame_0007.jpg\n",
            "webcam/images/keyboard/frame_0008.jpg\n",
            "webcam/images/keyboard/frame_0009.jpg\n",
            "webcam/images/keyboard/frame_0010.jpg\n",
            "webcam/images/keyboard/frame_0011.jpg\n",
            "webcam/images/keyboard/frame_0012.jpg\n",
            "webcam/images/keyboard/frame_0013.jpg\n",
            "webcam/images/keyboard/frame_0014.jpg\n",
            "webcam/images/keyboard/frame_0015.jpg\n",
            "webcam/images/keyboard/frame_0016.jpg\n",
            "webcam/images/keyboard/frame_0017.jpg\n",
            "webcam/images/keyboard/frame_0018.jpg\n",
            "webcam/images/keyboard/frame_0019.jpg\n",
            "webcam/images/keyboard/frame_0020.jpg\n",
            "webcam/images/keyboard/frame_0021.jpg\n",
            "webcam/images/keyboard/frame_0022.jpg\n",
            "webcam/images/keyboard/frame_0023.jpg\n",
            "webcam/images/keyboard/frame_0024.jpg\n",
            "webcam/images/keyboard/frame_0025.jpg\n",
            "webcam/images/keyboard/frame_0026.jpg\n",
            "webcam/images/keyboard/frame_0027.jpg\n",
            "webcam/images/laptop_computer/frame_0001.jpg\n",
            "webcam/images/laptop_computer/frame_0002.jpg\n",
            "webcam/images/laptop_computer/frame_0003.jpg\n",
            "webcam/images/laptop_computer/frame_0004.jpg\n",
            "webcam/images/laptop_computer/frame_0005.jpg\n",
            "webcam/images/laptop_computer/frame_0006.jpg\n",
            "webcam/images/laptop_computer/frame_0007.jpg\n",
            "webcam/images/laptop_computer/frame_0008.jpg\n",
            "webcam/images/laptop_computer/frame_0009.jpg\n",
            "webcam/images/laptop_computer/frame_0010.jpg\n",
            "webcam/images/laptop_computer/frame_0011.jpg\n",
            "webcam/images/laptop_computer/frame_0012.jpg\n",
            "webcam/images/laptop_computer/frame_0013.jpg\n",
            "webcam/images/laptop_computer/frame_0014.jpg\n",
            "webcam/images/laptop_computer/frame_0015.jpg\n",
            "webcam/images/laptop_computer/frame_0016.jpg\n",
            "webcam/images/laptop_computer/frame_0017.jpg\n",
            "webcam/images/laptop_computer/frame_0018.jpg\n",
            "webcam/images/laptop_computer/frame_0019.jpg\n",
            "webcam/images/laptop_computer/frame_0020.jpg\n",
            "webcam/images/laptop_computer/frame_0021.jpg\n",
            "webcam/images/laptop_computer/frame_0022.jpg\n",
            "webcam/images/laptop_computer/frame_0023.jpg\n",
            "webcam/images/laptop_computer/frame_0024.jpg\n",
            "webcam/images/laptop_computer/frame_0025.jpg\n",
            "webcam/images/laptop_computer/frame_0026.jpg\n",
            "webcam/images/laptop_computer/frame_0027.jpg\n",
            "webcam/images/laptop_computer/frame_0028.jpg\n",
            "webcam/images/laptop_computer/frame_0029.jpg\n",
            "webcam/images/laptop_computer/frame_0030.jpg\n",
            "webcam/images/letter_tray/frame_0001.jpg\n",
            "webcam/images/letter_tray/frame_0002.jpg\n",
            "webcam/images/letter_tray/frame_0003.jpg\n",
            "webcam/images/letter_tray/frame_0004.jpg\n",
            "webcam/images/letter_tray/frame_0005.jpg\n",
            "webcam/images/letter_tray/frame_0006.jpg\n",
            "webcam/images/letter_tray/frame_0007.jpg\n",
            "webcam/images/letter_tray/frame_0008.jpg\n",
            "webcam/images/letter_tray/frame_0009.jpg\n",
            "webcam/images/letter_tray/frame_0010.jpg\n",
            "webcam/images/letter_tray/frame_0011.jpg\n",
            "webcam/images/letter_tray/frame_0012.jpg\n",
            "webcam/images/letter_tray/frame_0013.jpg\n",
            "webcam/images/letter_tray/frame_0014.jpg\n",
            "webcam/images/letter_tray/frame_0015.jpg\n",
            "webcam/images/letter_tray/frame_0016.jpg\n",
            "webcam/images/letter_tray/frame_0017.jpg\n",
            "webcam/images/letter_tray/frame_0018.jpg\n",
            "webcam/images/letter_tray/frame_0019.jpg\n",
            "webcam/images/mobile_phone/frame_0001.jpg\n",
            "webcam/images/mobile_phone/frame_0002.jpg\n",
            "webcam/images/mobile_phone/frame_0003.jpg\n",
            "webcam/images/mobile_phone/frame_0004.jpg\n",
            "webcam/images/mobile_phone/frame_0005.jpg\n",
            "webcam/images/mobile_phone/frame_0006.jpg\n",
            "webcam/images/mobile_phone/frame_0007.jpg\n",
            "webcam/images/mobile_phone/frame_0008.jpg\n",
            "webcam/images/mobile_phone/frame_0009.jpg\n",
            "webcam/images/mobile_phone/frame_0010.jpg\n",
            "webcam/images/mobile_phone/frame_0011.jpg\n",
            "webcam/images/mobile_phone/frame_0012.jpg\n",
            "webcam/images/mobile_phone/frame_0013.jpg\n",
            "webcam/images/mobile_phone/frame_0014.jpg\n",
            "webcam/images/mobile_phone/frame_0015.jpg\n",
            "webcam/images/mobile_phone/frame_0016.jpg\n",
            "webcam/images/mobile_phone/frame_0017.jpg\n",
            "webcam/images/mobile_phone/frame_0018.jpg\n",
            "webcam/images/mobile_phone/frame_0019.jpg\n",
            "webcam/images/mobile_phone/frame_0020.jpg\n",
            "webcam/images/mobile_phone/frame_0021.jpg\n",
            "webcam/images/mobile_phone/frame_0022.jpg\n",
            "webcam/images/mobile_phone/frame_0023.jpg\n",
            "webcam/images/mobile_phone/frame_0024.jpg\n",
            "webcam/images/mobile_phone/frame_0025.jpg\n",
            "webcam/images/mobile_phone/frame_0026.jpg\n",
            "webcam/images/mobile_phone/frame_0027.jpg\n",
            "webcam/images/mobile_phone/frame_0028.jpg\n",
            "webcam/images/mobile_phone/frame_0029.jpg\n",
            "webcam/images/mobile_phone/frame_0030.jpg\n",
            "webcam/images/monitor/frame_0001.jpg\n",
            "webcam/images/monitor/frame_0002.jpg\n",
            "webcam/images/monitor/frame_0003.jpg\n",
            "webcam/images/monitor/frame_0004.jpg\n",
            "webcam/images/monitor/frame_0005.jpg\n",
            "webcam/images/monitor/frame_0006.jpg\n",
            "webcam/images/monitor/frame_0007.jpg\n",
            "webcam/images/monitor/frame_0008.jpg\n",
            "webcam/images/monitor/frame_0009.jpg\n",
            "webcam/images/monitor/frame_0010.jpg\n",
            "webcam/images/monitor/frame_0011.jpg\n",
            "webcam/images/monitor/frame_0012.jpg\n",
            "webcam/images/monitor/frame_0013.jpg\n",
            "webcam/images/monitor/frame_0014.jpg\n",
            "webcam/images/monitor/frame_0015.jpg\n",
            "webcam/images/monitor/frame_0016.jpg\n",
            "webcam/images/monitor/frame_0017.jpg\n",
            "webcam/images/monitor/frame_0018.jpg\n",
            "webcam/images/monitor/frame_0019.jpg\n",
            "webcam/images/monitor/frame_0020.jpg\n",
            "webcam/images/monitor/frame_0021.jpg\n",
            "webcam/images/monitor/frame_0022.jpg\n",
            "webcam/images/monitor/frame_0023.jpg\n",
            "webcam/images/monitor/frame_0024.jpg\n",
            "webcam/images/monitor/frame_0025.jpg\n",
            "webcam/images/monitor/frame_0026.jpg\n",
            "webcam/images/monitor/frame_0027.jpg\n",
            "webcam/images/monitor/frame_0028.jpg\n",
            "webcam/images/monitor/frame_0029.jpg\n",
            "webcam/images/monitor/frame_0030.jpg\n",
            "webcam/images/monitor/frame_0031.jpg\n",
            "webcam/images/monitor/frame_0032.jpg\n",
            "webcam/images/monitor/frame_0033.jpg\n",
            "webcam/images/monitor/frame_0034.jpg\n",
            "webcam/images/monitor/frame_0035.jpg\n",
            "webcam/images/monitor/frame_0036.jpg\n",
            "webcam/images/monitor/frame_0037.jpg\n",
            "webcam/images/monitor/frame_0038.jpg\n",
            "webcam/images/monitor/frame_0039.jpg\n",
            "webcam/images/monitor/frame_0040.jpg\n",
            "webcam/images/monitor/frame_0041.jpg\n",
            "webcam/images/monitor/frame_0042.jpg\n",
            "webcam/images/monitor/frame_0043.jpg\n",
            "webcam/images/mouse/frame_0001.jpg\n",
            "webcam/images/mouse/frame_0002.jpg\n",
            "webcam/images/mouse/frame_0003.jpg\n",
            "webcam/images/mouse/frame_0004.jpg\n",
            "webcam/images/mouse/frame_0005.jpg\n",
            "webcam/images/mouse/frame_0006.jpg\n",
            "webcam/images/mouse/frame_0007.jpg\n",
            "webcam/images/mouse/frame_0008.jpg\n",
            "webcam/images/mouse/frame_0009.jpg\n",
            "webcam/images/mouse/frame_0010.jpg\n",
            "webcam/images/mouse/frame_0011.jpg\n",
            "webcam/images/mouse/frame_0012.jpg\n",
            "webcam/images/mouse/frame_0013.jpg\n",
            "webcam/images/mouse/frame_0014.jpg\n",
            "webcam/images/mouse/frame_0015.jpg\n",
            "webcam/images/mouse/frame_0016.jpg\n",
            "webcam/images/mouse/frame_0017.jpg\n",
            "webcam/images/mouse/frame_0018.jpg\n",
            "webcam/images/mouse/frame_0019.jpg\n",
            "webcam/images/mouse/frame_0020.jpg\n",
            "webcam/images/mouse/frame_0021.jpg\n",
            "webcam/images/mouse/frame_0022.jpg\n",
            "webcam/images/mouse/frame_0023.jpg\n",
            "webcam/images/mouse/frame_0024.jpg\n",
            "webcam/images/mouse/frame_0025.jpg\n",
            "webcam/images/mouse/frame_0026.jpg\n",
            "webcam/images/mouse/frame_0027.jpg\n",
            "webcam/images/mouse/frame_0028.jpg\n",
            "webcam/images/mouse/frame_0029.jpg\n",
            "webcam/images/mouse/frame_0030.jpg\n",
            "webcam/images/mug/frame_0001.jpg\n",
            "webcam/images/mug/frame_0002.jpg\n",
            "webcam/images/mug/frame_0003.jpg\n",
            "webcam/images/mug/frame_0004.jpg\n",
            "webcam/images/mug/frame_0005.jpg\n",
            "webcam/images/mug/frame_0006.jpg\n",
            "webcam/images/mug/frame_0007.jpg\n",
            "webcam/images/mug/frame_0008.jpg\n",
            "webcam/images/mug/frame_0009.jpg\n",
            "webcam/images/mug/frame_0010.jpg\n",
            "webcam/images/mug/frame_0011.jpg\n",
            "webcam/images/mug/frame_0012.jpg\n",
            "webcam/images/mug/frame_0013.jpg\n",
            "webcam/images/mug/frame_0014.jpg\n",
            "webcam/images/mug/frame_0015.jpg\n",
            "webcam/images/mug/frame_0016.jpg\n",
            "webcam/images/mug/frame_0017.jpg\n",
            "webcam/images/mug/frame_0018.jpg\n",
            "webcam/images/mug/frame_0019.jpg\n",
            "webcam/images/mug/frame_0020.jpg\n",
            "webcam/images/mug/frame_0021.jpg\n",
            "webcam/images/mug/frame_0022.jpg\n",
            "webcam/images/mug/frame_0023.jpg\n",
            "webcam/images/mug/frame_0024.jpg\n",
            "webcam/images/mug/frame_0025.jpg\n",
            "webcam/images/mug/frame_0026.jpg\n",
            "webcam/images/mug/frame_0027.jpg\n",
            "webcam/images/paper_notebook/frame_0001.jpg\n",
            "webcam/images/paper_notebook/frame_0002.jpg\n",
            "webcam/images/paper_notebook/frame_0003.jpg\n",
            "webcam/images/paper_notebook/frame_0004.jpg\n",
            "webcam/images/paper_notebook/frame_0005.jpg\n",
            "webcam/images/paper_notebook/frame_0006.jpg\n",
            "webcam/images/paper_notebook/frame_0007.jpg\n",
            "webcam/images/paper_notebook/frame_0008.jpg\n",
            "webcam/images/paper_notebook/frame_0009.jpg\n",
            "webcam/images/paper_notebook/frame_0010.jpg\n",
            "webcam/images/paper_notebook/frame_0011.jpg\n",
            "webcam/images/paper_notebook/frame_0012.jpg\n",
            "webcam/images/paper_notebook/frame_0013.jpg\n",
            "webcam/images/paper_notebook/frame_0014.jpg\n",
            "webcam/images/paper_notebook/frame_0015.jpg\n",
            "webcam/images/paper_notebook/frame_0016.jpg\n",
            "webcam/images/paper_notebook/frame_0017.jpg\n",
            "webcam/images/paper_notebook/frame_0018.jpg\n",
            "webcam/images/paper_notebook/frame_0019.jpg\n",
            "webcam/images/paper_notebook/frame_0020.jpg\n",
            "webcam/images/paper_notebook/frame_0021.jpg\n",
            "webcam/images/paper_notebook/frame_0022.jpg\n",
            "webcam/images/paper_notebook/frame_0023.jpg\n",
            "webcam/images/paper_notebook/frame_0024.jpg\n",
            "webcam/images/paper_notebook/frame_0025.jpg\n",
            "webcam/images/paper_notebook/frame_0026.jpg\n",
            "webcam/images/paper_notebook/frame_0027.jpg\n",
            "webcam/images/paper_notebook/frame_0028.jpg\n",
            "webcam/images/pen/frame_0001.jpg\n",
            "webcam/images/pen/frame_0002.jpg\n",
            "webcam/images/pen/frame_0003.jpg\n",
            "webcam/images/pen/frame_0004.jpg\n",
            "webcam/images/pen/frame_0005.jpg\n",
            "webcam/images/pen/frame_0006.jpg\n",
            "webcam/images/pen/frame_0007.jpg\n",
            "webcam/images/pen/frame_0008.jpg\n",
            "webcam/images/pen/frame_0009.jpg\n",
            "webcam/images/pen/frame_0010.jpg\n",
            "webcam/images/pen/frame_0011.jpg\n",
            "webcam/images/pen/frame_0012.jpg\n",
            "webcam/images/pen/frame_0013.jpg\n",
            "webcam/images/pen/frame_0014.jpg\n",
            "webcam/images/pen/frame_0015.jpg\n",
            "webcam/images/pen/frame_0016.jpg\n",
            "webcam/images/pen/frame_0017.jpg\n",
            "webcam/images/pen/frame_0018.jpg\n",
            "webcam/images/pen/frame_0019.jpg\n",
            "webcam/images/pen/frame_0020.jpg\n",
            "webcam/images/pen/frame_0021.jpg\n",
            "webcam/images/pen/frame_0022.jpg\n",
            "webcam/images/pen/frame_0023.jpg\n",
            "webcam/images/pen/frame_0024.jpg\n",
            "webcam/images/pen/frame_0025.jpg\n",
            "webcam/images/pen/frame_0026.jpg\n",
            "webcam/images/pen/frame_0027.jpg\n",
            "webcam/images/pen/frame_0028.jpg\n",
            "webcam/images/pen/frame_0029.jpg\n",
            "webcam/images/pen/frame_0030.jpg\n",
            "webcam/images/pen/frame_0031.jpg\n",
            "webcam/images/pen/frame_0032.jpg\n",
            "webcam/images/phone/frame_0001.jpg\n",
            "webcam/images/phone/frame_0002.jpg\n",
            "webcam/images/phone/frame_0003.jpg\n",
            "webcam/images/phone/frame_0004.jpg\n",
            "webcam/images/phone/frame_0005.jpg\n",
            "webcam/images/phone/frame_0006.jpg\n",
            "webcam/images/phone/frame_0007.jpg\n",
            "webcam/images/phone/frame_0008.jpg\n",
            "webcam/images/phone/frame_0009.jpg\n",
            "webcam/images/phone/frame_0010.jpg\n",
            "webcam/images/phone/frame_0011.jpg\n",
            "webcam/images/phone/frame_0012.jpg\n",
            "webcam/images/phone/frame_0013.jpg\n",
            "webcam/images/phone/frame_0014.jpg\n",
            "webcam/images/phone/frame_0015.jpg\n",
            "webcam/images/phone/frame_0016.jpg\n",
            "webcam/images/printer/frame_0001.jpg\n",
            "webcam/images/printer/frame_0002.jpg\n",
            "webcam/images/printer/frame_0003.jpg\n",
            "webcam/images/printer/frame_0004.jpg\n",
            "webcam/images/printer/frame_0005.jpg\n",
            "webcam/images/printer/frame_0006.jpg\n",
            "webcam/images/printer/frame_0007.jpg\n",
            "webcam/images/printer/frame_0008.jpg\n",
            "webcam/images/printer/frame_0009.jpg\n",
            "webcam/images/printer/frame_0010.jpg\n",
            "webcam/images/printer/frame_0011.jpg\n",
            "webcam/images/printer/frame_0012.jpg\n",
            "webcam/images/printer/frame_0013.jpg\n",
            "webcam/images/printer/frame_0014.jpg\n",
            "webcam/images/printer/frame_0015.jpg\n",
            "webcam/images/printer/frame_0016.jpg\n",
            "webcam/images/printer/frame_0017.jpg\n",
            "webcam/images/printer/frame_0018.jpg\n",
            "webcam/images/printer/frame_0019.jpg\n",
            "webcam/images/printer/frame_0020.jpg\n",
            "webcam/images/projector/frame_0001.jpg\n",
            "webcam/images/projector/frame_0002.jpg\n",
            "webcam/images/projector/frame_0003.jpg\n",
            "webcam/images/projector/frame_0004.jpg\n",
            "webcam/images/projector/frame_0005.jpg\n",
            "webcam/images/projector/frame_0006.jpg\n",
            "webcam/images/projector/frame_0007.jpg\n",
            "webcam/images/projector/frame_0008.jpg\n",
            "webcam/images/projector/frame_0009.jpg\n",
            "webcam/images/projector/frame_0010.jpg\n",
            "webcam/images/projector/frame_0011.jpg\n",
            "webcam/images/projector/frame_0012.jpg\n",
            "webcam/images/projector/frame_0013.jpg\n",
            "webcam/images/projector/frame_0014.jpg\n",
            "webcam/images/projector/frame_0015.jpg\n",
            "webcam/images/projector/frame_0016.jpg\n",
            "webcam/images/projector/frame_0017.jpg\n",
            "webcam/images/projector/frame_0018.jpg\n",
            "webcam/images/projector/frame_0019.jpg\n",
            "webcam/images/projector/frame_0020.jpg\n",
            "webcam/images/projector/frame_0021.jpg\n",
            "webcam/images/projector/frame_0022.jpg\n",
            "webcam/images/projector/frame_0023.jpg\n",
            "webcam/images/projector/frame_0024.jpg\n",
            "webcam/images/projector/frame_0025.jpg\n",
            "webcam/images/projector/frame_0026.jpg\n",
            "webcam/images/projector/frame_0027.jpg\n",
            "webcam/images/projector/frame_0028.jpg\n",
            "webcam/images/projector/frame_0029.jpg\n",
            "webcam/images/projector/frame_0030.jpg\n",
            "webcam/images/punchers/frame_0001.jpg\n",
            "webcam/images/punchers/frame_0002.jpg\n",
            "webcam/images/punchers/frame_0003.jpg\n",
            "webcam/images/punchers/frame_0004.jpg\n",
            "webcam/images/punchers/frame_0005.jpg\n",
            "webcam/images/punchers/frame_0006.jpg\n",
            "webcam/images/punchers/frame_0007.jpg\n",
            "webcam/images/punchers/frame_0008.jpg\n",
            "webcam/images/punchers/frame_0009.jpg\n",
            "webcam/images/punchers/frame_0010.jpg\n",
            "webcam/images/punchers/frame_0011.jpg\n",
            "webcam/images/punchers/frame_0012.jpg\n",
            "webcam/images/punchers/frame_0013.jpg\n",
            "webcam/images/punchers/frame_0014.jpg\n",
            "webcam/images/punchers/frame_0015.jpg\n",
            "webcam/images/punchers/frame_0016.jpg\n",
            "webcam/images/punchers/frame_0017.jpg\n",
            "webcam/images/punchers/frame_0018.jpg\n",
            "webcam/images/punchers/frame_0019.jpg\n",
            "webcam/images/punchers/frame_0020.jpg\n",
            "webcam/images/punchers/frame_0021.jpg\n",
            "webcam/images/punchers/frame_0022.jpg\n",
            "webcam/images/punchers/frame_0023.jpg\n",
            "webcam/images/punchers/frame_0024.jpg\n",
            "webcam/images/punchers/frame_0025.jpg\n",
            "webcam/images/punchers/frame_0026.jpg\n",
            "webcam/images/punchers/frame_0027.jpg\n",
            "webcam/images/ring_binder/frame_0001.jpg\n",
            "webcam/images/ring_binder/frame_0002.jpg\n",
            "webcam/images/ring_binder/frame_0003.jpg\n",
            "webcam/images/ring_binder/frame_0004.jpg\n",
            "webcam/images/ring_binder/frame_0005.jpg\n",
            "webcam/images/ring_binder/frame_0006.jpg\n",
            "webcam/images/ring_binder/frame_0007.jpg\n",
            "webcam/images/ring_binder/frame_0008.jpg\n",
            "webcam/images/ring_binder/frame_0009.jpg\n",
            "webcam/images/ring_binder/frame_0010.jpg\n",
            "webcam/images/ring_binder/frame_0011.jpg\n",
            "webcam/images/ring_binder/frame_0012.jpg\n",
            "webcam/images/ring_binder/frame_0013.jpg\n",
            "webcam/images/ring_binder/frame_0014.jpg\n",
            "webcam/images/ring_binder/frame_0015.jpg\n",
            "webcam/images/ring_binder/frame_0016.jpg\n",
            "webcam/images/ring_binder/frame_0017.jpg\n",
            "webcam/images/ring_binder/frame_0018.jpg\n",
            "webcam/images/ring_binder/frame_0019.jpg\n",
            "webcam/images/ring_binder/frame_0020.jpg\n",
            "webcam/images/ring_binder/frame_0021.jpg\n",
            "webcam/images/ring_binder/frame_0022.jpg\n",
            "webcam/images/ring_binder/frame_0023.jpg\n",
            "webcam/images/ring_binder/frame_0024.jpg\n",
            "webcam/images/ring_binder/frame_0025.jpg\n",
            "webcam/images/ring_binder/frame_0026.jpg\n",
            "webcam/images/ring_binder/frame_0027.jpg\n",
            "webcam/images/ring_binder/frame_0028.jpg\n",
            "webcam/images/ring_binder/frame_0029.jpg\n",
            "webcam/images/ring_binder/frame_0030.jpg\n",
            "webcam/images/ring_binder/frame_0031.jpg\n",
            "webcam/images/ring_binder/frame_0032.jpg\n",
            "webcam/images/ring_binder/frame_0033.jpg\n",
            "webcam/images/ring_binder/frame_0034.jpg\n",
            "webcam/images/ring_binder/frame_0035.jpg\n",
            "webcam/images/ring_binder/frame_0036.jpg\n",
            "webcam/images/ring_binder/frame_0037.jpg\n",
            "webcam/images/ring_binder/frame_0038.jpg\n",
            "webcam/images/ring_binder/frame_0039.jpg\n",
            "webcam/images/ring_binder/frame_0040.jpg\n",
            "webcam/images/ruler/frame_0001.jpg\n",
            "webcam/images/ruler/frame_0002.jpg\n",
            "webcam/images/ruler/frame_0003.jpg\n",
            "webcam/images/ruler/frame_0004.jpg\n",
            "webcam/images/ruler/frame_0005.jpg\n",
            "webcam/images/ruler/frame_0006.jpg\n",
            "webcam/images/ruler/frame_0007.jpg\n",
            "webcam/images/ruler/frame_0008.jpg\n",
            "webcam/images/ruler/frame_0009.jpg\n",
            "webcam/images/ruler/frame_0010.jpg\n",
            "webcam/images/ruler/frame_0011.jpg\n",
            "webcam/images/scissors/frame_0001.jpg\n",
            "webcam/images/scissors/frame_0002.jpg\n",
            "webcam/images/scissors/frame_0003.jpg\n",
            "webcam/images/scissors/frame_0004.jpg\n",
            "webcam/images/scissors/frame_0005.jpg\n",
            "webcam/images/scissors/frame_0006.jpg\n",
            "webcam/images/scissors/frame_0007.jpg\n",
            "webcam/images/scissors/frame_0008.jpg\n",
            "webcam/images/scissors/frame_0009.jpg\n",
            "webcam/images/scissors/frame_0010.jpg\n",
            "webcam/images/scissors/frame_0011.jpg\n",
            "webcam/images/scissors/frame_0012.jpg\n",
            "webcam/images/scissors/frame_0013.jpg\n",
            "webcam/images/scissors/frame_0014.jpg\n",
            "webcam/images/scissors/frame_0015.jpg\n",
            "webcam/images/scissors/frame_0016.jpg\n",
            "webcam/images/scissors/frame_0017.jpg\n",
            "webcam/images/scissors/frame_0018.jpg\n",
            "webcam/images/scissors/frame_0019.jpg\n",
            "webcam/images/scissors/frame_0020.jpg\n",
            "webcam/images/scissors/frame_0021.jpg\n",
            "webcam/images/scissors/frame_0022.jpg\n",
            "webcam/images/scissors/frame_0023.jpg\n",
            "webcam/images/scissors/frame_0024.jpg\n",
            "webcam/images/scissors/frame_0025.jpg\n",
            "webcam/images/speaker/frame_0001.jpg\n",
            "webcam/images/speaker/frame_0002.jpg\n",
            "webcam/images/speaker/frame_0003.jpg\n",
            "webcam/images/speaker/frame_0004.jpg\n",
            "webcam/images/speaker/frame_0005.jpg\n",
            "webcam/images/speaker/frame_0006.jpg\n",
            "webcam/images/speaker/frame_0007.jpg\n",
            "webcam/images/speaker/frame_0008.jpg\n",
            "webcam/images/speaker/frame_0009.jpg\n",
            "webcam/images/speaker/frame_0010.jpg\n",
            "webcam/images/speaker/frame_0011.jpg\n",
            "webcam/images/speaker/frame_0012.jpg\n",
            "webcam/images/speaker/frame_0013.jpg\n",
            "webcam/images/speaker/frame_0014.jpg\n",
            "webcam/images/speaker/frame_0015.jpg\n",
            "webcam/images/speaker/frame_0016.jpg\n",
            "webcam/images/speaker/frame_0017.jpg\n",
            "webcam/images/speaker/frame_0018.jpg\n",
            "webcam/images/speaker/frame_0019.jpg\n",
            "webcam/images/speaker/frame_0020.jpg\n",
            "webcam/images/speaker/frame_0021.jpg\n",
            "webcam/images/speaker/frame_0022.jpg\n",
            "webcam/images/speaker/frame_0023.jpg\n",
            "webcam/images/speaker/frame_0024.jpg\n",
            "webcam/images/speaker/frame_0025.jpg\n",
            "webcam/images/speaker/frame_0026.jpg\n",
            "webcam/images/speaker/frame_0027.jpg\n",
            "webcam/images/speaker/frame_0028.jpg\n",
            "webcam/images/speaker/frame_0029.jpg\n",
            "webcam/images/speaker/frame_0030.jpg\n",
            "webcam/images/stapler/frame_0001.jpg\n",
            "webcam/images/stapler/frame_0002.jpg\n",
            "webcam/images/stapler/frame_0003.jpg\n",
            "webcam/images/stapler/frame_0004.jpg\n",
            "webcam/images/stapler/frame_0005.jpg\n",
            "webcam/images/stapler/frame_0006.jpg\n",
            "webcam/images/stapler/frame_0007.jpg\n",
            "webcam/images/stapler/frame_0008.jpg\n",
            "webcam/images/stapler/frame_0009.jpg\n",
            "webcam/images/stapler/frame_0010.jpg\n",
            "webcam/images/stapler/frame_0011.jpg\n",
            "webcam/images/stapler/frame_0012.jpg\n",
            "webcam/images/stapler/frame_0013.jpg\n",
            "webcam/images/stapler/frame_0014.jpg\n",
            "webcam/images/stapler/frame_0015.jpg\n",
            "webcam/images/stapler/frame_0016.jpg\n",
            "webcam/images/stapler/frame_0017.jpg\n",
            "webcam/images/stapler/frame_0018.jpg\n",
            "webcam/images/stapler/frame_0019.jpg\n",
            "webcam/images/stapler/frame_0020.jpg\n",
            "webcam/images/stapler/frame_0021.jpg\n",
            "webcam/images/stapler/frame_0022.jpg\n",
            "webcam/images/stapler/frame_0023.jpg\n",
            "webcam/images/stapler/frame_0024.jpg\n",
            "webcam/images/tape_dispenser/frame_0001.jpg\n",
            "webcam/images/tape_dispenser/frame_0002.jpg\n",
            "webcam/images/tape_dispenser/frame_0003.jpg\n",
            "webcam/images/tape_dispenser/frame_0004.jpg\n",
            "webcam/images/tape_dispenser/frame_0005.jpg\n",
            "webcam/images/tape_dispenser/frame_0006.jpg\n",
            "webcam/images/tape_dispenser/frame_0007.jpg\n",
            "webcam/images/tape_dispenser/frame_0008.jpg\n",
            "webcam/images/tape_dispenser/frame_0009.jpg\n",
            "webcam/images/tape_dispenser/frame_0010.jpg\n",
            "webcam/images/tape_dispenser/frame_0011.jpg\n",
            "webcam/images/tape_dispenser/frame_0012.jpg\n",
            "webcam/images/tape_dispenser/frame_0013.jpg\n",
            "webcam/images/tape_dispenser/frame_0014.jpg\n",
            "webcam/images/tape_dispenser/frame_0015.jpg\n",
            "webcam/images/tape_dispenser/frame_0016.jpg\n",
            "webcam/images/tape_dispenser/frame_0017.jpg\n",
            "webcam/images/tape_dispenser/frame_0018.jpg\n",
            "webcam/images/tape_dispenser/frame_0019.jpg\n",
            "webcam/images/tape_dispenser/frame_0020.jpg\n",
            "webcam/images/tape_dispenser/frame_0021.jpg\n",
            "webcam/images/tape_dispenser/frame_0022.jpg\n",
            "webcam/images/tape_dispenser/frame_0023.jpg\n",
            "webcam/images/trash_can/frame_0001.jpg\n",
            "webcam/images/trash_can/frame_0002.jpg\n",
            "webcam/images/trash_can/frame_0003.jpg\n",
            "webcam/images/trash_can/frame_0004.jpg\n",
            "webcam/images/trash_can/frame_0005.jpg\n",
            "webcam/images/trash_can/frame_0006.jpg\n",
            "webcam/images/trash_can/frame_0007.jpg\n",
            "webcam/images/trash_can/frame_0008.jpg\n",
            "webcam/images/trash_can/frame_0009.jpg\n",
            "webcam/images/trash_can/frame_0010.jpg\n",
            "webcam/images/trash_can/frame_0011.jpg\n",
            "webcam/images/trash_can/frame_0012.jpg\n",
            "webcam/images/trash_can/frame_0013.jpg\n",
            "webcam/images/trash_can/frame_0014.jpg\n",
            "webcam/images/trash_can/frame_0015.jpg\n",
            "webcam/images/trash_can/frame_0016.jpg\n",
            "webcam/images/trash_can/frame_0017.jpg\n",
            "webcam/images/trash_can/frame_0018.jpg\n",
            "webcam/images/trash_can/frame_0019.jpg\n",
            "webcam/images/trash_can/frame_0020.jpg\n",
            "webcam/images/trash_can/frame_0021.jpg\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "DomainNet dataset"
      ],
      "metadata": {
        "id": "OnCa6p7Aq_4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://csr.bu.edu/ftp/visda/2019/multi-source/groundtruth/painting.zip -O /content/painting.zip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "AWnzVgB8Ya3Y",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://csr.bu.edu/ftp/visda/2019/multi-source/real.zip -O /content/real.zip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3ZL6k_g0Ymwc",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://csr.bu.edu/ftp/visda/2019/multi-source/sketch.zip -O /content/sketch.zip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Eup-NqFsYq9B",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://csr.bu.edu/ftp/visda/2019/multi-source/quickdraw.zip -O /content/quickdraw.zip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nVJoBZ7XYsul",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://csr.bu.edu/ftp/visda/2019/multi-source/groundtruth/clipart.zip -O /content/clipart.zip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9nHNxJDjYtwM",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://csr.bu.edu/ftp/visda/2019/multi-source/infograph.zip -O /content/infograph.zip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "aKX1d8lvYuWo",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p domainnet"
      ],
      "metadata": {
        "id": "uKeH9nsUcrJN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/painting.zip -d /content/Dataset/domainnet/\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WwPyLKjRYvvx",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/real.zip -d /content/Dataset/domainnet/"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mrM7XSHxdswA",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/infograph.zip -d /content/Dataset/domainnet/"
      ],
      "metadata": {
        "collapsed": true,
        "id": "clqPzhO_dvVN",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/sketch.zip -d /content/Dataset/domainnet/"
      ],
      "metadata": {
        "collapsed": true,
        "id": "0ka7A2CDd0Io",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/clipart.zip -d /content/Dataset/domainnet/"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fIIfyz1-d1yz",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/quickdraw.zip -d /content/Dataset/domainnet/"
      ],
      "metadata": {
        "collapsed": true,
        "id": "c8ozq7dEd4Ny",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Subset creation of data"
      ],
      "metadata": {
        "id": "xy3pkuZ8tVcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/Dataset/domainnet/painting\"  # Adjust if needed"
      ],
      "metadata": {
        "id": "587oKVeYrNA-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Dictionary to store class counts\n",
        "class_counts = {}\n",
        "\n",
        "# Loop through each class folder\n",
        "for cls in os.listdir(dataset_path):\n",
        "    class_path = os.path.join(dataset_path, cls)\n",
        "\n",
        "    if os.path.isdir(class_path):  # Ensure it's a directory\n",
        "        num_images = len([f for f in os.listdir(class_path) if f.endswith((\".jpg\", \".png\"))])\n",
        "        class_counts[cls] = num_images\n",
        "\n",
        "# Print class counts\n",
        "for cls, count in class_counts.items():\n",
        "    print(f\"Class: {cls}, Images: {count}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dwVps2sarJCI",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Get list of class folders\n",
        "classes = [cls for cls in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, cls))]\n",
        "\n",
        "# Print the list of classes\n",
        "print(\"Classes Found:\", classes)\n",
        "\n",
        "print(\"Length: \", len(classes))"
      ],
      "metadata": {
        "id": "jf_fPnoerYRo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Define paths\n",
        "source_path = \"/content/Dataset/domainnet/painting\"  # Change if needed\n",
        "subset_path = \"/content/Dataset/domainnet_painting_subset\"  # Output folder\n",
        "\n",
        "# Define proportion (e.g., 30% of the dataset)\n",
        "subset_ratio = 0.3  # Adjust as needed (0.3 = 30%)\n",
        "\n",
        "# Define threshold for small classes (if class has ≤ `small_class_threshold` images, keep all)\n",
        "small_class_threshold = 20  # Adjust as needed\n",
        "\n",
        "# Create subset directory\n",
        "os.makedirs(subset_path, exist_ok=True)\n",
        "\n",
        "# Get list of all classes (folders)\n",
        "classes = [cls for cls in os.listdir(source_path) if os.path.isdir(os.path.join(source_path, cls))]\n",
        "\n",
        "# Loop through each class and select proportional images\n",
        "for cls in classes:\n",
        "    class_path = os.path.join(source_path, cls)\n",
        "    class_subset_path = os.path.join(subset_path, cls)\n",
        "    os.makedirs(class_subset_path, exist_ok=True)\n",
        "\n",
        "    # Get all image files in the class folder\n",
        "    images = [f for f in os.listdir(class_path) if f.endswith((\".jpg\", \".png\"))]\n",
        "\n",
        "    # Check if the class is small (keep all images)\n",
        "    if len(images) <= small_class_threshold:\n",
        "        selected_images = images  # Keep all images\n",
        "    else:\n",
        "        # Determine the number of images to keep (proportional to original size)\n",
        "        num_selected = max(1, int(len(images) * subset_ratio))\n",
        "        selected_images = random.sample(images, num_selected)\n",
        "\n",
        "    # Copy selected images to subset folder\n",
        "    for img in selected_images:\n",
        "        shutil.copy(os.path.join(class_path, img), os.path.join(class_subset_path, img))\n",
        "\n",
        "    print(f\"Class '{cls}': Selected {len(selected_images)} images out of {len(images)}\")\n",
        "\n",
        "print(f\"Proportional subset created successfully with {subset_ratio * 100}% of the dataset!\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6uTsGHHcr3E1",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define paths\n",
        "original_path = \"/content/Dataset/domainnet/painting\"  # Original dataset folder\n",
        "subset_path = \"/content/Dataset/domainnet_painting_subset\"  # Newly created subset folder\n",
        "\n",
        "# Remove the original dataset folder\n",
        "if os.path.exists(original_path):\n",
        "    shutil.rmtree(original_path)\n",
        "    print(f\"Deleted original dataset folder: {original_path}\")\n",
        "\n",
        "# Rename the subset folder to the original dataset folder name\n",
        "shutil.move(subset_path, original_path)\n",
        "\n",
        "print(f\"Renamed subset to: {original_path}\")"
      ],
      "metadata": {
        "id": "AP0D9abut0rA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training**"
      ],
      "metadata": {
        "id": "1DjKmyF0p4mT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.device_count())  # Number of GPUs available\n",
        "print(torch.cuda.current_device())  # Current active device index\n",
        "print(torch.cuda.get_device_name(0))  # Name of the first GPU (if available)\n"
      ],
      "metadata": {
        "id": "StJBtCOigthg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /kaggle/working/ECB/\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-01T07:53:58.548611Z",
          "iopub.status.busy": "2025-05-01T07:53:58.548284Z",
          "iopub.status.idle": "2025-05-01T07:53:58.554013Z",
          "shell.execute_reply": "2025-05-01T07:53:58.553319Z",
          "shell.execute_reply.started": "2025-05-01T07:53:58.548585Z"
        },
        "id": "p2vm0daUR6-F",
        "outputId": "9700ced0-695d-4024-dcb4-ba0d2eda1610",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/kaggle/working/ECB\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file paths\n",
        "source_file = \"/kaggle/input/trainyamlfile3/basenet.py\"\n",
        "destination_file = \"/kaggle/working/ECB/model/basenet.py\"\n",
        "\n",
        "# # Create a sample source file\n",
        "# with open(source_file, \"r\") as f:\n",
        "#     f.write(\"This is the original content.\")\n",
        "\n",
        "# Copy contents\n",
        "with open(source_file, \"r\") as src, open(destination_file, \"w\") as dest:\n",
        "    dest.write(src.read())\n",
        "\n",
        "print(f\"Copied contents from {source_file} to {destination_file}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-01T07:31:39.286034Z",
          "iopub.status.busy": "2025-05-01T07:31:39.285828Z",
          "iopub.status.idle": "2025-05-01T07:31:39.306994Z",
          "shell.execute_reply": "2025-05-01T07:31:39.306380Z",
          "shell.execute_reply.started": "2025-05-01T07:31:39.286004Z"
        },
        "trusted": true,
        "id": "u1SRVNp2Rkxg",
        "outputId": "73cf145a-3de0-4238-b682-4693b1b7a39c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copied contents from /kaggle/input/trainyamlfile3/basenet.py to /kaggle/working/ECB/model/basenet.py\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file paths\n",
        "source_file = \"/kaggle/input/trainyaml2/train.yaml\"\n",
        "destination_file = \"/kaggle/working/ECB/configs/train.yaml\"\n",
        "\n",
        "# # Create a sample source file\n",
        "# with open(source_file, \"r\") as f:\n",
        "#     f.write(\"This is the original content.\")\n",
        "\n",
        "# Copy contents\n",
        "with open(source_file, \"r\") as src, open(destination_file, \"w\") as dest:\n",
        "    dest.write(src.read())\n",
        "\n",
        "print(f\"Copied contents from {source_file} to {destination_file}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-01T11:18:15.062328Z",
          "iopub.status.busy": "2025-05-01T11:18:15.061970Z",
          "iopub.status.idle": "2025-05-01T11:18:15.072175Z",
          "shell.execute_reply": "2025-05-01T11:18:15.071364Z",
          "shell.execute_reply.started": "2025-05-01T11:18:15.062297Z"
        },
        "trusted": true,
        "id": "CDBU_ZRHRkxg",
        "outputId": "2fc11686-ca36-4c13-9b0b-022af1355ce5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copied contents from /kaggle/input/trainyaml2/train.yaml to /kaggle/working/ECB/configs/train.yaml\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reproduced Result"
      ],
      "metadata": {
        "id": "cPVzNLFVZ8SG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAT Testing"
      ],
      "metadata": {
        "id": "bXUMibyXRkxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Product to Art - Warmup"
      ],
      "metadata": {
        "id": "arTfSh_DRkxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!source activate ecb && echo \"Activated: $CONDA_DEFAULT_ENV\" && python train.py --cfg configs/train.yaml"
      ],
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-04-19T09:27:57.731940Z",
          "iopub.status.busy": "2025-04-19T09:27:57.731609Z",
          "iopub.status.idle": "2025-04-19T09:55:38.691376Z",
          "shell.execute_reply": "2025-04-19T09:55:38.690255Z",
          "shell.execute_reply.started": "2025-04-19T09:27:57.731915Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "PzWHCPVCRkxf",
        "outputId": "94f2961a-60fb-4875-c0c1-251badab053d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Activated: ecb\n",
            "========== DATA PATH ==========\n",
            "source train: ./dataset/officehome_uda/Product.txt\n",
            "source test: ./dataset/officehome_uda/Product.txt\n",
            "target train: ./dataset/officehome_uda/Art.txt\n",
            "target test: ./dataset/officehome_uda/Art.txt\n",
            "===============================\n",
            "/opt/conda/envs/ecb/lib/python3.9/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "======== LOAD PRETRAIN ========\n",
            "Loading pretrain ImageNet: VisionTransformer\n",
            "Loading pretrain ImageNet: ResNet\n",
            "Weight Init: Predictor_deep\n",
            "Weight Init: Predictor_deep\n",
            "===============================\n",
            "{'DEVICE': device(type='cuda', index=0), 'ndomains': 2, 'output_path': './results/officehome_uda/Product_to_Art_UDA_baseline', 'output_name': 'baseline', 'source_iters': 2000, 'adapt_iters': 0, 'test_interval': 500, 'seed': 1, 'warmup': True, 'pretrained_models': '', 'lamda': 0.1, 'save_models': True, 'thresh_ViT': 0.6, 'thresh_CNN': 0.9, 'dataset': {'method': 'UDA', 'data_root': '../Dataset/office_home', 'data_label': './dataset/officehome_uda', 'num_workers': 8, 'target_shot': 0, 'use_cgct_mask': True, 'source': {'name': 'Product', 'batch_size': 28}, 'target': {'name': 'Art', 'batch_size': 28}, 'prep': {'source_w': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7a7f2105cf70>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'source_str': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7a7e6a914130>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    <utils.preprocess.RandAugmentMC object at 0x7a7e6a914070>\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'target_w': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7a7e6a9140d0>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'target_str': Compose(\n",
            "    <utils.randaugment.RandAugment object at 0x7a7e6a9146a0>\n",
            "    <utils.preprocess.ResizeImage object at 0x7a7e6a914580>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'test': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7a7e6a914670>\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'val': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7a7e6a914820>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")}, 'name': 'officehome_uda'}, 'optimizer': {'lr': 1.0, 'lr_vit': 0.001, 'lr_cnn': 0.01, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}, 'Architecture': {'Backbone': {'name_1': 'vit', 'pretrained_1': '', 'name_2': 'resnet50', 'pretrained_2': ''}, 'Classifier': {'name_1': 'MLP', 'pretrained_F1': '', 'name_2': 'MLP', 'pretrained_F2': ''}, 'class_num': 65}, 'mixup_thresh': 0.7, 'alpha': 0.9, 'percentile': 60, 'lambda': 0.5, 'num_classes': 31, 'sat_alpha': 0.8, 'output_path_warmup': 'officehome_uda/Product_to_Art_UDA_pretrained_warmup', 'out_file_warmup': <_io.TextIOWrapper name='officehome_uda/Product_to_Art_UDA_pretrained_warmup/log.txt' mode='w' encoding='UTF-8'>, 'out_file': <_io.TextIOWrapper name='./results/officehome_uda/Product_to_Art_UDA_baseline/log.txt' mode='w' encoding='UTF-8'>}\n",
            "\u001b[31m==> Step 1: Pre-training on the labeled dataset ...\u001b[0m\n",
            "\u001b[31mMethod: UDA - File: trainer_warmup.py\u001b[0m\n",
            "Iters: (0/2000) \t lr_g1 0.000100   lr_g2 0.001000  CNN's loss: 4.426015   ViT's Loss: 4.261161   \n",
            "\n",
            "Iters: (20/2000) \t lr_g1 0.000100   lr_g2 0.000999  CNN's loss: 2.022685   ViT's Loss: 0.826799   \n",
            "\n",
            "Iters: (40/2000) \t lr_g1 0.000100   lr_g2 0.000997  CNN's loss: 1.279776   ViT's Loss: 0.423491   \n",
            "\n",
            "Iters: (60/2000) \t lr_g1 0.000100   lr_g2 0.000996  CNN's loss: 0.849503   ViT's Loss: 0.321808   \n",
            "\n",
            "Iters: (80/2000) \t lr_g1 0.000099   lr_g2 0.000994  CNN's loss: 0.713126   ViT's Loss: 0.280874   \n",
            "\n",
            "Iters: (100/2000) \t lr_g1 0.000099   lr_g2 0.000993  CNN's loss: 0.949260   ViT's Loss: 0.236263   \n",
            "\n",
            "Iters: (120/2000) \t lr_g1 0.000099   lr_g2 0.000991  CNN's loss: 0.951725   ViT's Loss: 0.470094   \n",
            "\n",
            "Iters: (140/2000) \t lr_g1 0.000099   lr_g2 0.000990  CNN's loss: 0.606217   ViT's Loss: 0.069983   \n",
            "\n",
            "Iters: (160/2000) \t lr_g1 0.000099   lr_g2 0.000988  CNN's loss: 0.364049   ViT's Loss: 0.022505   \n",
            "\n",
            "Iters: (180/2000) \t lr_g1 0.000099   lr_g2 0.000987  CNN's loss: 0.221600   ViT's Loss: 0.039402   \n",
            "\n",
            "Iters: (200/2000) \t lr_g1 0.000099   lr_g2 0.000985  CNN's loss: 0.763955   ViT's Loss: 0.064204   \n",
            "\n",
            "Iters: (220/2000) \t lr_g1 0.000098   lr_g2 0.000984  CNN's loss: 0.836528   ViT's Loss: 0.022066   \n",
            "\n",
            "Iters: (240/2000) \t lr_g1 0.000098   lr_g2 0.000982  CNN's loss: 0.155020   ViT's Loss: 0.045970   \n",
            "\n",
            "Iters: (260/2000) \t lr_g1 0.000098   lr_g2 0.000981  CNN's loss: 0.109631   ViT's Loss: 0.031757   \n",
            "\n",
            "Iters: (280/2000) \t lr_g1 0.000098   lr_g2 0.000980  CNN's loss: 0.570352   ViT's Loss: 0.225038   \n",
            "\n",
            "Iters: (300/2000) \t lr_g1 0.000098   lr_g2 0.000978  CNN's loss: 0.464479   ViT's Loss: 0.153843   \n",
            "\n",
            "Iters: (320/2000) \t lr_g1 0.000098   lr_g2 0.000977  CNN's loss: 0.172371   ViT's Loss: 0.041685   \n",
            "\n",
            "Iters: (340/2000) \t lr_g1 0.000098   lr_g2 0.000975  CNN's loss: 0.174691   ViT's Loss: 0.057860   \n",
            "\n",
            "Iters: (360/2000) \t lr_g1 0.000097   lr_g2 0.000974  CNN's loss: 0.120100   ViT's Loss: 0.038722   \n",
            "\n",
            "Iters: (380/2000) \t lr_g1 0.000097   lr_g2 0.000972  CNN's loss: 0.256666   ViT's Loss: 0.074694   \n",
            "\n",
            "Iters: (400/2000) \t lr_g1 0.000097   lr_g2 0.000971  CNN's loss: 0.296851   ViT's Loss: 0.055348   \n",
            "\n",
            "Iters: (420/2000) \t lr_g1 0.000097   lr_g2 0.000970  CNN's loss: 0.382657   ViT's Loss: 0.132238   \n",
            "\n",
            "Iters: (440/2000) \t lr_g1 0.000097   lr_g2 0.000968  CNN's loss: 0.150063   ViT's Loss: 0.011008   \n",
            "\n",
            "Iters: (460/2000) \t lr_g1 0.000097   lr_g2 0.000967  CNN's loss: 0.477781   ViT's Loss: 0.051450   \n",
            "\n",
            "Iters: (480/2000) \t lr_g1 0.000097   lr_g2 0.000965  CNN's loss: 0.112002   ViT's Loss: 0.059208   \n",
            "\n",
            "100%|███████████████████████████████████████████| 87/87 [00:20<00:00,  4.26it/s]\n",
            "100%|█████████████████████████████████████████| 159/159 [00:34<00:00,  4.66it/s]\n",
            "  -- Domain task [Product --> Art] \n",
            "\t-- CNN's Accuracy Source Test  = 98.0176%  ViT's Accuracy Source Test =  98.6483% \n",
            "\t-- CNN's Accuracy Target Test = 40.1731%  ViT's Accuracy Target Test = 73.7536% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at officehome_uda/Product_to_Art_UDA_pretrained_warmup\n",
            "  -- Saved ViT Branch (G1 + F1) at officehome_uda/Product_to_Art_UDA_pretrained_warmup\n",
            "\u001b[31m  -- Domain task [Product --> Art]: \n",
            "\t-- The best CNN's Acc Source Test = 98.0176% The best Vit's Acc Source Test = 98.6483% \n",
            "\t-- The best CNN's Acc Target Test = 40.1731% The best ViT's Acc Target Test = 73.7536% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.7614 Correct_Pseudo_Labels_CNN = 466 Total_Pseudo_Labels_CNN = 612        \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.8692 Correct_Pseudo_Labels_ViT = 1562 Total_Pseudo_Labels_ViT = 1797       \n",
            "\u001b[0m\n",
            "Iters: (500/2000) \t lr_g1 0.000096   lr_g2 0.000964  CNN's loss: 0.153919   ViT's Loss: 0.013778   \n",
            "\n",
            "Iters: (520/2000) \t lr_g1 0.000096   lr_g2 0.000963  CNN's loss: 0.103024   ViT's Loss: 0.013026   \n",
            "\n",
            "Iters: (540/2000) \t lr_g1 0.000096   lr_g2 0.000961  CNN's loss: 0.122729   ViT's Loss: 0.024481   \n",
            "\n",
            "Iters: (560/2000) \t lr_g1 0.000096   lr_g2 0.000960  CNN's loss: 0.077194   ViT's Loss: 0.010310   \n",
            "\n",
            "Iters: (580/2000) \t lr_g1 0.000096   lr_g2 0.000959  CNN's loss: 0.131475   ViT's Loss: 0.008782   \n",
            "\n",
            "Iters: (600/2000) \t lr_g1 0.000096   lr_g2 0.000957  CNN's loss: 0.119989   ViT's Loss: 0.024893   \n",
            "\n",
            "Iters: (620/2000) \t lr_g1 0.000096   lr_g2 0.000956  CNN's loss: 0.328261   ViT's Loss: 0.040939   \n",
            "\n",
            "Iters: (640/2000) \t lr_g1 0.000095   lr_g2 0.000955  CNN's loss: 0.111712   ViT's Loss: 0.024406   \n",
            "\n",
            "Iters: (660/2000) \t lr_g1 0.000095   lr_g2 0.000953  CNN's loss: 0.111155   ViT's Loss: 0.009494   \n",
            "\n",
            "Iters: (680/2000) \t lr_g1 0.000095   lr_g2 0.000952  CNN's loss: 0.180504   ViT's Loss: 0.017250   \n",
            "\n",
            "Iters: (700/2000) \t lr_g1 0.000095   lr_g2 0.000951  CNN's loss: 0.022235   ViT's Loss: 0.006198   \n",
            "\n",
            "Iters: (720/2000) \t lr_g1 0.000095   lr_g2 0.000949  CNN's loss: 0.044623   ViT's Loss: 0.006831   \n",
            "\n",
            "Iters: (740/2000) \t lr_g1 0.000095   lr_g2 0.000948  CNN's loss: 0.253247   ViT's Loss: 0.123496   \n",
            "\n",
            "Iters: (760/2000) \t lr_g1 0.000095   lr_g2 0.000947  CNN's loss: 0.018327   ViT's Loss: 0.044695   \n",
            "\n",
            "Iters: (780/2000) \t lr_g1 0.000095   lr_g2 0.000945  CNN's loss: 0.036114   ViT's Loss: 0.008391   \n",
            "\n",
            "Iters: (800/2000) \t lr_g1 0.000094   lr_g2 0.000944  CNN's loss: 0.134682   ViT's Loss: 0.013377   \n",
            "\n",
            "Iters: (820/2000) \t lr_g1 0.000094   lr_g2 0.000943  CNN's loss: 0.024683   ViT's Loss: 0.008542   \n",
            "\n",
            "Iters: (840/2000) \t lr_g1 0.000094   lr_g2 0.000941  CNN's loss: 0.068050   ViT's Loss: 0.013725   \n",
            "\n",
            "Iters: (860/2000) \t lr_g1 0.000094   lr_g2 0.000940  CNN's loss: 0.012364   ViT's Loss: 0.005481   \n",
            "\n",
            "Iters: (880/2000) \t lr_g1 0.000094   lr_g2 0.000939  CNN's loss: 0.079754   ViT's Loss: 0.015250   \n",
            "\n",
            "Iters: (900/2000) \t lr_g1 0.000094   lr_g2 0.000937  CNN's loss: 0.249443   ViT's Loss: 0.150256   \n",
            "\n",
            "Iters: (920/2000) \t lr_g1 0.000094   lr_g2 0.000936  CNN's loss: 0.154625   ViT's Loss: 0.166339   \n",
            "\n",
            "Iters: (940/2000) \t lr_g1 0.000093   lr_g2 0.000935  CNN's loss: 0.053085   ViT's Loss: 0.066127   \n",
            "\n",
            "Iters: (960/2000) \t lr_g1 0.000093   lr_g2 0.000934  CNN's loss: 0.029135   ViT's Loss: 0.005873   \n",
            "\n",
            "Iters: (980/2000) \t lr_g1 0.000093   lr_g2 0.000932  CNN's loss: 0.077439   ViT's Loss: 0.006499   \n",
            "\n",
            "100%|███████████████████████████████████████████| 87/87 [00:19<00:00,  4.38it/s]\n",
            "100%|█████████████████████████████████████████| 159/159 [00:33<00:00,  4.75it/s]\n",
            "  -- Domain task [Product --> Art] \n",
            "\t-- CNN's Accuracy Source Test  = 99.3467%  ViT's Accuracy Source Test =  99.5269% \n",
            "\t-- CNN's Accuracy Target Test = 39.9258%  ViT's Accuracy Target Test = 74.5365% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at officehome_uda/Product_to_Art_UDA_pretrained_warmup\n",
            "  -- Saved ViT Branch (G1 + F1) at officehome_uda/Product_to_Art_UDA_pretrained_warmup\n",
            "\u001b[31m  -- Domain task [Product --> Art]: \n",
            "\t-- The best CNN's Acc Source Test = 99.3467% The best Vit's Acc Source Test = 99.5269% \n",
            "\t-- The best CNN's Acc Target Test = 40.1731% The best ViT's Acc Target Test = 74.5365% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.7350 Correct_Pseudo_Labels_CNN = 516 Total_Pseudo_Labels_CNN = 702        \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.8644 Correct_Pseudo_Labels_ViT = 1594 Total_Pseudo_Labels_ViT = 1844       \n",
            "\u001b[0m\n",
            "Iters: (1000/2000) \t lr_g1 0.000093   lr_g2 0.000931  CNN's loss: 0.233992   ViT's Loss: 0.011194   \n",
            "\n",
            "Iters: (1020/2000) \t lr_g1 0.000093   lr_g2 0.000930  CNN's loss: 0.034750   ViT's Loss: 0.004792   \n",
            "\n",
            "Iters: (1040/2000) \t lr_g1 0.000093   lr_g2 0.000928  CNN's loss: 0.052366   ViT's Loss: 0.028065   \n",
            "\n",
            "Iters: (1060/2000) \t lr_g1 0.000093   lr_g2 0.000927  CNN's loss: 0.021433   ViT's Loss: 0.046464   \n",
            "\n",
            "Iters: (1080/2000) \t lr_g1 0.000093   lr_g2 0.000926  CNN's loss: 0.004614   ViT's Loss: 0.002819   \n",
            "\n",
            "Iters: (1100/2000) \t lr_g1 0.000092   lr_g2 0.000925  CNN's loss: 0.012169   ViT's Loss: 0.004629   \n",
            "\n",
            "Iters: (1120/2000) \t lr_g1 0.000092   lr_g2 0.000923  CNN's loss: 0.021641   ViT's Loss: 0.036676   \n",
            "\n",
            "Iters: (1140/2000) \t lr_g1 0.000092   lr_g2 0.000922  CNN's loss: 0.066622   ViT's Loss: 0.003027   \n",
            "\n",
            "Iters: (1160/2000) \t lr_g1 0.000092   lr_g2 0.000921  CNN's loss: 0.006786   ViT's Loss: 0.002588   \n",
            "\n",
            "Iters: (1180/2000) \t lr_g1 0.000092   lr_g2 0.000920  CNN's loss: 0.128769   ViT's Loss: 0.016222   \n",
            "\n",
            "Iters: (1200/2000) \t lr_g1 0.000092   lr_g2 0.000919  CNN's loss: 0.102066   ViT's Loss: 0.012315   \n",
            "\n",
            "Iters: (1220/2000) \t lr_g1 0.000092   lr_g2 0.000917  CNN's loss: 0.063281   ViT's Loss: 0.009437   \n",
            "\n",
            "Iters: (1240/2000) \t lr_g1 0.000092   lr_g2 0.000916  CNN's loss: 0.076677   ViT's Loss: 0.004075   \n",
            "\n",
            "Iters: (1260/2000) \t lr_g1 0.000091   lr_g2 0.000915  CNN's loss: 0.241062   ViT's Loss: 0.110488   \n",
            "\n",
            "Iters: (1280/2000) \t lr_g1 0.000091   lr_g2 0.000914  CNN's loss: 0.054768   ViT's Loss: 0.003772   \n",
            "\n",
            "Iters: (1300/2000) \t lr_g1 0.000091   lr_g2 0.000912  CNN's loss: 0.012504   ViT's Loss: 0.020848   \n",
            "\n",
            "Iters: (1320/2000) \t lr_g1 0.000091   lr_g2 0.000911  CNN's loss: 0.078032   ViT's Loss: 0.010528   \n",
            "\n",
            "Iters: (1340/2000) \t lr_g1 0.000091   lr_g2 0.000910  CNN's loss: 0.005348   ViT's Loss: 0.006964   \n",
            "\n",
            "Iters: (1360/2000) \t lr_g1 0.000091   lr_g2 0.000909  CNN's loss: 0.005708   ViT's Loss: 0.006432   \n",
            "\n",
            "Iters: (1380/2000) \t lr_g1 0.000091   lr_g2 0.000908  CNN's loss: 0.028909   ViT's Loss: 0.002359   \n",
            "\n",
            "Iters: (1400/2000) \t lr_g1 0.000091   lr_g2 0.000906  CNN's loss: 0.029145   ViT's Loss: 0.049402   \n",
            "\n",
            "Iters: (1420/2000) \t lr_g1 0.000091   lr_g2 0.000905  CNN's loss: 0.005341   ViT's Loss: 0.005648   \n",
            "\n",
            "Iters: (1440/2000) \t lr_g1 0.000090   lr_g2 0.000904  CNN's loss: 0.183302   ViT's Loss: 0.003895   \n",
            "\n",
            "Iters: (1460/2000) \t lr_g1 0.000090   lr_g2 0.000903  CNN's loss: 0.085178   ViT's Loss: 0.055112   \n",
            "\n",
            "Iters: (1480/2000) \t lr_g1 0.000090   lr_g2 0.000902  CNN's loss: 0.025138   ViT's Loss: 0.002430   \n",
            "\n",
            "100%|███████████████████████████████████████████| 87/87 [00:19<00:00,  4.39it/s]\n",
            "100%|█████████████████████████████████████████| 159/159 [00:33<00:00,  4.74it/s]\n",
            "  -- Domain task [Product --> Art] \n",
            "\t-- CNN's Accuracy Source Test  = 99.4819%  ViT's Accuracy Source Test =  99.7071% \n",
            "\t-- CNN's Accuracy Target Test = 38.7721%  ViT's Accuracy Target Test = 74.8249% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at officehome_uda/Product_to_Art_UDA_pretrained_warmup\n",
            "  -- Saved ViT Branch (G1 + F1) at officehome_uda/Product_to_Art_UDA_pretrained_warmup\n",
            "\u001b[31m  -- Domain task [Product --> Art]: \n",
            "\t-- The best CNN's Acc Source Test = 99.4819% The best Vit's Acc Source Test = 99.7071% \n",
            "\t-- The best CNN's Acc Target Test = 40.1731% The best ViT's Acc Target Test = 74.8249% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.7177 Correct_Pseudo_Labels_CNN = 516 Total_Pseudo_Labels_CNN = 719        \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.8700 Correct_Pseudo_Labels_ViT = 1619 Total_Pseudo_Labels_ViT = 1861       \n",
            "\u001b[0m\n",
            "Iters: (1500/2000) \t lr_g1 0.000090   lr_g2 0.000900  CNN's loss: 0.131000   ViT's Loss: 0.002565   \n",
            "\n",
            "Iters: (1520/2000) \t lr_g1 0.000090   lr_g2 0.000899  CNN's loss: 0.005049   ViT's Loss: 0.007618   \n",
            "\n",
            "Iters: (1540/2000) \t lr_g1 0.000090   lr_g2 0.000898  CNN's loss: 0.017823   ViT's Loss: 0.007703   \n",
            "\n",
            "Iters: (1560/2000) \t lr_g1 0.000090   lr_g2 0.000897  CNN's loss: 0.005681   ViT's Loss: 0.002604   \n",
            "\n",
            "Iters: (1580/2000) \t lr_g1 0.000090   lr_g2 0.000896  CNN's loss: 0.015123   ViT's Loss: 0.003358   \n",
            "\n",
            "Iters: (1600/2000) \t lr_g1 0.000089   lr_g2 0.000895  CNN's loss: 0.004327   ViT's Loss: 0.003365   \n",
            "\n",
            "Iters: (1620/2000) \t lr_g1 0.000089   lr_g2 0.000894  CNN's loss: 0.092411   ViT's Loss: 0.030297   \n",
            "\n",
            "Iters: (1640/2000) \t lr_g1 0.000089   lr_g2 0.000892  CNN's loss: 0.009714   ViT's Loss: 0.002082   \n",
            "\n",
            "Iters: (1660/2000) \t lr_g1 0.000089   lr_g2 0.000891  CNN's loss: 0.008435   ViT's Loss: 0.007865   \n",
            "\n",
            "Iters: (1680/2000) \t lr_g1 0.000089   lr_g2 0.000890  CNN's loss: 0.002334   ViT's Loss: 0.003558   \n",
            "\n",
            "Iters: (1700/2000) \t lr_g1 0.000089   lr_g2 0.000889  CNN's loss: 0.207585   ViT's Loss: 0.140808   \n",
            "\n",
            "Iters: (1720/2000) \t lr_g1 0.000089   lr_g2 0.000888  CNN's loss: 0.005811   ViT's Loss: 0.007498   \n",
            "\n",
            "Iters: (1740/2000) \t lr_g1 0.000089   lr_g2 0.000887  CNN's loss: 0.017881   ViT's Loss: 0.006700   \n",
            "\n",
            "Iters: (1760/2000) \t lr_g1 0.000089   lr_g2 0.000886  CNN's loss: 0.076002   ViT's Loss: 0.012980   \n",
            "\n",
            "Iters: (1780/2000) \t lr_g1 0.000088   lr_g2 0.000884  CNN's loss: 0.051676   ViT's Loss: 0.001560   \n",
            "\n",
            "Iters: (1800/2000) \t lr_g1 0.000088   lr_g2 0.000883  CNN's loss: 0.007011   ViT's Loss: 0.005053   \n",
            "\n",
            "Iters: (1820/2000) \t lr_g1 0.000088   lr_g2 0.000882  CNN's loss: 0.010023   ViT's Loss: 0.006023   \n",
            "\n",
            "Iters: (1840/2000) \t lr_g1 0.000088   lr_g2 0.000881  CNN's loss: 0.143907   ViT's Loss: 0.071634   \n",
            "\n",
            "Iters: (1860/2000) \t lr_g1 0.000088   lr_g2 0.000880  CNN's loss: 0.007965   ViT's Loss: 0.002165   \n",
            "\n",
            "Iters: (1880/2000) \t lr_g1 0.000088   lr_g2 0.000879  CNN's loss: 0.006011   ViT's Loss: 0.004349   \n",
            "\n",
            "Iters: (1900/2000) \t lr_g1 0.000088   lr_g2 0.000878  CNN's loss: 0.004638   ViT's Loss: 0.002614   \n",
            "\n",
            "Iters: (1920/2000) \t lr_g1 0.000088   lr_g2 0.000877  CNN's loss: 0.063706   ViT's Loss: 0.004592   \n",
            "\n",
            "Iters: (1940/2000) \t lr_g1 0.000088   lr_g2 0.000875  CNN's loss: 0.006367   ViT's Loss: 0.002017   \n",
            "\n",
            "Iters: (1960/2000) \t lr_g1 0.000087   lr_g2 0.000874  CNN's loss: 0.014054   ViT's Loss: 0.003663   \n",
            "\n",
            "Iters: (1980/2000) \t lr_g1 0.000087   lr_g2 0.000873  CNN's loss: 0.018069   ViT's Loss: 0.048962   \n",
            "\n",
            "Iters: (1999/2000) \t lr_g1 0.000087   lr_g2 0.000872  CNN's loss: 0.006379   ViT's Loss: 0.005871   \n",
            "\n",
            "100%|███████████████████████████████████████████| 87/87 [00:19<00:00,  4.41it/s]\n",
            "100%|█████████████████████████████████████████| 159/159 [00:33<00:00,  4.77it/s]\n",
            "  -- Domain task [Product --> Art] \n",
            "\t-- CNN's Accuracy Source Test  = 99.7071%  ViT's Accuracy Source Test =  99.7522% \n",
            "\t-- CNN's Accuracy Target Test = 40.0906%  ViT's Accuracy Target Test = 74.6601% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at officehome_uda/Product_to_Art_UDA_pretrained_warmup\n",
            "  -- Saved ViT Branch (G1 + F1) at officehome_uda/Product_to_Art_UDA_pretrained_warmup\n",
            "\u001b[31m  -- Domain task [Product --> Art]: \n",
            "\t-- The best CNN's Acc Source Test = 99.7071% The best Vit's Acc Source Test = 99.7522% \n",
            "\t-- The best CNN's Acc Target Test = 40.1731% The best ViT's Acc Target Test = 74.8249% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.7481 Correct_Pseudo_Labels_CNN = 588 Total_Pseudo_Labels_CNN = 786        \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.8681 Correct_Pseudo_Labels_ViT = 1619 Total_Pseudo_Labels_ViT = 1865       \n",
            "\u001b[0m\n",
            "\u001b[31m==> Finished pre-training on source!\n",
            "\u001b[0m\n",
            "======== LOAD PRETRAIN ========\n",
            "Loading: officehome_uda/Product_to_Art_UDA_pretrained_warmup/the_best_G1_pretrained.pth.tar\n",
            "Pretrain weights VisionTransformer loaded.\n",
            "Loading: officehome_uda/Product_to_Art_UDA_pretrained_warmup/the_best_G2_pretrained.pth.tar\n",
            "Pretrain weights ResNet loaded.\n",
            "Loading: officehome_uda/Product_to_Art_UDA_pretrained_warmup/the_best_F1_pretrained.pth.tar\n",
            "Pretrain weights Predictor_deep loaded.\n",
            "Loading: officehome_uda/Product_to_Art_UDA_pretrained_warmup/the_best_F2_pretrained.pth.tar\n",
            "Pretrain weights Predictor_deep loaded.\n",
            "===============================\n",
            "{'DEVICE': device(type='cuda', index=0), 'ndomains': 2, 'output_path': './results/officehome_uda/Product_to_Art_UDA_baseline', 'output_name': 'baseline', 'source_iters': 2000, 'adapt_iters': 0, 'test_interval': 500, 'seed': 1, 'warmup': True, 'pretrained_models': '', 'lamda': 0.1, 'save_models': True, 'thresh_ViT': 0.6, 'thresh_CNN': 0.9, 'dataset': {'method': 'UDA', 'data_root': '../Dataset/office_home', 'data_label': './dataset/officehome_uda', 'num_workers': 8, 'target_shot': 0, 'use_cgct_mask': True, 'source': {'name': 'Product', 'batch_size': 28}, 'target': {'name': 'Art', 'batch_size': 28}, 'prep': {'source_w': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7a7f2105cf70>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'source_str': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7a7e6a914130>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    <utils.preprocess.RandAugmentMC object at 0x7a7e6a914070>\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'target_w': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7a7e6a9140d0>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'target_str': Compose(\n",
            "    <utils.randaugment.RandAugment object at 0x7a7e6a9146a0>\n",
            "    <utils.preprocess.ResizeImage object at 0x7a7e6a914580>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'test': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7a7e6a914670>\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'val': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7a7e6a914820>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")}, 'name': 'officehome_uda'}, 'optimizer': {'lr': 1.0, 'lr_vit': 0.001, 'lr_cnn': 0.01, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}, 'Architecture': {'Backbone': {'name_1': 'vit', 'pretrained_1': 'officehome_uda/Product_to_Art_UDA_pretrained_warmup/the_best_G1_pretrained.pth.tar', 'name_2': 'resnet50', 'pretrained_2': 'officehome_uda/Product_to_Art_UDA_pretrained_warmup/the_best_G2_pretrained.pth.tar'}, 'Classifier': {'name_1': 'MLP', 'pretrained_F1': 'officehome_uda/Product_to_Art_UDA_pretrained_warmup/the_best_F1_pretrained.pth.tar', 'name_2': 'MLP', 'pretrained_F2': 'officehome_uda/Product_to_Art_UDA_pretrained_warmup/the_best_F2_pretrained.pth.tar'}, 'class_num': 65}, 'mixup_thresh': 0.7, 'alpha': 0.9, 'percentile': 60, 'lambda': 0.5, 'num_classes': 31, 'sat_alpha': 0.8, 'output_path_warmup': 'officehome_uda/Product_to_Art_UDA_pretrained_warmup', 'out_file_warmup': <_io.TextIOWrapper name='officehome_uda/Product_to_Art_UDA_pretrained_warmup/log.txt' mode='w' encoding='UTF-8'>, 'out_file': <_io.TextIOWrapper name='./results/officehome_uda/Product_to_Art_UDA_baseline/log.txt' mode='w' encoding='UTF-8'>}\n",
            "\u001b[31m==> Starting the adaptation\u001b[0m\n",
            "\u001b[31mMethod: UDA - File: trainer.py\u001b[0m\n",
            "\u001b[31mFinished training and evaluation!\u001b[0m\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import shutil\n",
        "\n",
        "# Replace 'folder_to_zip' with your folder name\n",
        "shutil.make_archive('product_to_art', 'zip', '/kaggle/working/ECB/officehome_uda')"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-19T10:27:35.466655Z",
          "iopub.status.busy": "2025-04-19T10:27:35.466227Z",
          "iopub.status.idle": "2025-04-19T10:27:57.724558Z",
          "shell.execute_reply": "2025-04-19T10:27:57.723785Z",
          "shell.execute_reply.started": "2025-04-19T10:27:35.466620Z"
        },
        "trusted": true,
        "id": "v4Cf2vXfRkxh",
        "outputId": "7f878b0a-773e-4cf3-8ce5-cc5ac73a9879"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/kaggle/working/ECB/product_to_art.zip'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the destination directory\n",
        "dest_dir = '/kaggle/working/ECB/pretrained/officehome_uda/Product_to_Art_UDA_pretrained_warmup/'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(dest_dir, exist_ok=True)\n",
        "\n",
        "# Unzip files to the destination, flattening the structure (-j)\n",
        "!unzip -j \"/kaggle/working/ECB/product_to_art.zip\" -d \"{dest_dir}\"\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-19T10:29:26.419533Z",
          "iopub.status.busy": "2025-04-19T10:29:26.419141Z",
          "iopub.status.idle": "2025-04-19T10:29:30.863282Z",
          "shell.execute_reply": "2025-04-19T10:29:30.862260Z",
          "shell.execute_reply.started": "2025-04-19T10:29:26.419503Z"
        },
        "trusted": true,
        "id": "ZL49hBaaRkxh",
        "outputId": "5d255b01-6d60-4498-aa4a-de845347bc97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /kaggle/working/ECB/product_to_art.zip\n",
            "  inflating: /kaggle/working/ECB/pretrained/officehome_uda/Product_to_Art_UDA_pretrained_warmup/log.txt  \n",
            "  inflating: /kaggle/working/ECB/pretrained/officehome_uda/Product_to_Art_UDA_pretrained_warmup/trainer_warmup.py  \n",
            "  inflating: /kaggle/working/ECB/pretrained/officehome_uda/Product_to_Art_UDA_pretrained_warmup/the_best_G2_pretrained.pth.tar  \n",
            "  inflating: /kaggle/working/ECB/pretrained/officehome_uda/Product_to_Art_UDA_pretrained_warmup/the_best_F2_pretrained.pth.tar  \n",
            "  inflating: /kaggle/working/ECB/pretrained/officehome_uda/Product_to_Art_UDA_pretrained_warmup/the_best_F1_pretrained.pth.tar  \n",
            "  inflating: /kaggle/working/ECB/pretrained/officehome_uda/Product_to_Art_UDA_pretrained_warmup/the_best_G1_pretrained.pth.tar  \n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Product to Art - Adapt"
      ],
      "metadata": {
        "id": "N4kiJhI4Rkxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!source activate ecb && echo \"Activated: $CONDA_DEFAULT_ENV\" && python train.py --cfg configs/train.yaml"
      ],
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-04-19T10:30:22.888051Z",
          "iopub.status.busy": "2025-04-19T10:30:22.887758Z",
          "iopub.status.idle": "2025-04-19T11:53:31.041507Z",
          "shell.execute_reply": "2025-04-19T11:53:31.040470Z",
          "shell.execute_reply.started": "2025-04-19T10:30:22.888031Z"
        },
        "id": "c8KOMmm4RmpL",
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "outputId": "a8765a69-1ed4-43d6-8bb1-21cffaf09b6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Activated: ecb\n",
            "========== DATA PATH ==========\n",
            "source train: ./dataset/officehome_uda/Product.txt\n",
            "source test: ./dataset/officehome_uda/Product.txt\n",
            "target train: ./dataset/officehome_uda/Art.txt\n",
            "target test: ./dataset/officehome_uda/Art.txt\n",
            "===============================\n",
            "/opt/conda/envs/ecb/lib/python3.9/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "======== LOAD PRETRAIN ========\n",
            "Loading pretrain ImageNet: VisionTransformer\n",
            "Loading pretrain ImageNet: ResNet\n",
            "Weight Init: Predictor_deep\n",
            "Weight Init: Predictor_deep\n",
            "===============================\n",
            "{'DEVICE': device(type='cuda', index=0), 'ndomains': 2, 'output_path': './results/officehome_uda/Product_to_Art_UDA_baseline', 'output_name': 'baseline', 'source_iters': 0, 'adapt_iters': 1000, 'test_interval': 500, 'seed': 1, 'warmup': True, 'pretrained_models': './pretrained/', 'lamda': 0.1, 'save_models': True, 'thresh_ViT': 0.6, 'thresh_CNN': 0.9, 'dataset': {'method': 'UDA', 'data_root': '../Dataset/office_home', 'data_label': './dataset/officehome_uda', 'num_workers': 8, 'target_shot': 0, 'use_cgct_mask': True, 'source': {'name': 'Product', 'batch_size': 28}, 'target': {'name': 'Art', 'batch_size': 28}, 'prep': {'source_w': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x78b0b8c29f70>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'source_str': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x78b0024dd160>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    <utils.preprocess.RandAugmentMC object at 0x78b0024dd2e0>\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'target_w': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x78b0024dd460>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'target_str': Compose(\n",
            "    <utils.randaugment.RandAugment object at 0x78b0024dd280>\n",
            "    <utils.preprocess.ResizeImage object at 0x78b0024dd700>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'test': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x78b0024dd580>\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'val': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x78b0024dd9a0>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")}, 'name': 'officehome_uda'}, 'optimizer': {'lr': 1.0, 'lr_vit': 0.001, 'lr_cnn': 0.01, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}, 'Architecture': {'Backbone': {'name_1': 'vit', 'pretrained_1': '', 'name_2': 'resnet50', 'pretrained_2': ''}, 'Classifier': {'name_1': 'MLP', 'pretrained_F1': '', 'name_2': 'MLP', 'pretrained_F2': ''}, 'class_num': 65}, 'mixup_thresh': 0.7, 'alpha': 0.9, 'percentile': 60, 'lambda': 0.5, 'num_classes': 31, 'sat_alpha': 0.8, 'output_path_warmup': './pretrained/officehome_uda/Product_to_Art_UDA_pretrained_warmup', 'out_file_warmup': <_io.TextIOWrapper name='./pretrained/officehome_uda/Product_to_Art_UDA_pretrained_warmup/log.txt' mode='w' encoding='UTF-8'>, 'out_file': <_io.TextIOWrapper name='./results/officehome_uda/Product_to_Art_UDA_baseline/log.txt' mode='w' encoding='UTF-8'>}\n",
            "\u001b[31m==> Step 1: Pre-training on the labeled dataset ...\u001b[0m\n",
            "\u001b[31mMethod: UDA - File: trainer_warmup.py\u001b[0m\n",
            "\u001b[31m==> Finished pre-training on source!\n",
            "\u001b[0m\n",
            "======== LOAD PRETRAIN ========\n",
            "Loading: ./pretrained/officehome_uda/Product_to_Art_UDA_pretrained_warmup/the_best_G1_pretrained.pth.tar\n",
            "Pretrain weights VisionTransformer loaded.\n",
            "Loading: ./pretrained/officehome_uda/Product_to_Art_UDA_pretrained_warmup/the_best_G2_pretrained.pth.tar\n",
            "Pretrain weights ResNet loaded.\n",
            "Loading: ./pretrained/officehome_uda/Product_to_Art_UDA_pretrained_warmup/the_best_F1_pretrained.pth.tar\n",
            "Pretrain weights Predictor_deep loaded.\n",
            "Loading: ./pretrained/officehome_uda/Product_to_Art_UDA_pretrained_warmup/the_best_F2_pretrained.pth.tar\n",
            "Pretrain weights Predictor_deep loaded.\n",
            "===============================\n",
            "{'DEVICE': device(type='cuda', index=0), 'ndomains': 2, 'output_path': './results/officehome_uda/Product_to_Art_UDA_baseline', 'output_name': 'baseline', 'source_iters': 0, 'adapt_iters': 1000, 'test_interval': 500, 'seed': 1, 'warmup': True, 'pretrained_models': './pretrained/', 'lamda': 0.1, 'save_models': True, 'thresh_ViT': 0.6, 'thresh_CNN': 0.9, 'dataset': {'method': 'UDA', 'data_root': '../Dataset/office_home', 'data_label': './dataset/officehome_uda', 'num_workers': 8, 'target_shot': 0, 'use_cgct_mask': True, 'source': {'name': 'Product', 'batch_size': 28}, 'target': {'name': 'Art', 'batch_size': 28}, 'prep': {'source_w': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x78b0b8c29f70>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'source_str': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x78b0024dd160>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    <utils.preprocess.RandAugmentMC object at 0x78b0024dd2e0>\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'target_w': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x78b0024dd460>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'target_str': Compose(\n",
            "    <utils.randaugment.RandAugment object at 0x78b0024dd280>\n",
            "    <utils.preprocess.ResizeImage object at 0x78b0024dd700>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'test': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x78b0024dd580>\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'val': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x78b0024dd9a0>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")}, 'name': 'officehome_uda'}, 'optimizer': {'lr': 1.0, 'lr_vit': 0.001, 'lr_cnn': 0.01, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}, 'Architecture': {'Backbone': {'name_1': 'vit', 'pretrained_1': './pretrained/officehome_uda/Product_to_Art_UDA_pretrained_warmup/the_best_G1_pretrained.pth.tar', 'name_2': 'resnet50', 'pretrained_2': './pretrained/officehome_uda/Product_to_Art_UDA_pretrained_warmup/the_best_G2_pretrained.pth.tar'}, 'Classifier': {'name_1': 'MLP', 'pretrained_F1': './pretrained/officehome_uda/Product_to_Art_UDA_pretrained_warmup/the_best_F1_pretrained.pth.tar', 'name_2': 'MLP', 'pretrained_F2': './pretrained/officehome_uda/Product_to_Art_UDA_pretrained_warmup/the_best_F2_pretrained.pth.tar'}, 'class_num': 65}, 'mixup_thresh': 0.7, 'alpha': 0.9, 'percentile': 60, 'lambda': 0.5, 'num_classes': 31, 'sat_alpha': 0.8, 'output_path_warmup': './pretrained/officehome_uda/Product_to_Art_UDA_pretrained_warmup', 'out_file_warmup': <_io.TextIOWrapper name='./pretrained/officehome_uda/Product_to_Art_UDA_pretrained_warmup/log.txt' mode='w' encoding='UTF-8'>, 'out_file': <_io.TextIOWrapper name='./results/officehome_uda/Product_to_Art_UDA_baseline/log.txt' mode='w' encoding='UTF-8'>}\n",
            "\u001b[31m==> Starting the adaptation\u001b[0m\n",
            "\u001b[31mMethod: UDA - File: trainer.py\u001b[0m\n",
            "Iters: (0/1000) \t lr_g1 = 0.000100   lr_g2 = 0.001000   CNN's loss = 0.002966   ViT's Loss = 0.005156   loss_vit_to_cnn = 2.339170   loss_cnn_to_vit = 0.834691   \n",
            "\n",
            "Iters: (20/1000) \t lr_g1 = 0.000100   lr_g2 = 0.000999   CNN's loss = 0.206846   ViT's Loss = 0.015537   loss_vit_to_cnn = 1.858491   loss_cnn_to_vit = 0.022900   \n",
            "\n",
            "Iters: (40/1000) \t lr_g1 = 0.000100   lr_g2 = 0.000997   CNN's loss = 0.097806   ViT's Loss = 0.005805   loss_vit_to_cnn = 2.172206   loss_cnn_to_vit = 0.234130   \n",
            "\n",
            "Iters: (60/1000) \t lr_g1 = 0.000100   lr_g2 = 0.000996   CNN's loss = 0.348326   ViT's Loss = 0.060196   loss_vit_to_cnn = 1.404499   loss_cnn_to_vit = 0.175744   \n",
            "\n",
            "Iters: (80/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000994   CNN's loss = 0.280737   ViT's Loss = 0.168589   loss_vit_to_cnn = 1.256513   loss_cnn_to_vit = 0.067735   \n",
            "\n",
            "Iters: (100/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000993   CNN's loss = 0.404711   ViT's Loss = 0.101847   loss_vit_to_cnn = 1.326093   loss_cnn_to_vit = 0.012686   \n",
            "\n",
            "Iters: (120/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000991   CNN's loss = 0.088938   ViT's Loss = 0.012036   loss_vit_to_cnn = 1.933015   loss_cnn_to_vit = 0.061443   \n",
            "\n",
            "Iters: (140/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000990   CNN's loss = 0.285634   ViT's Loss = 0.087197   loss_vit_to_cnn = 1.841436   loss_cnn_to_vit = 0.210386   \n",
            "\n",
            "Iters: (160/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000988   CNN's loss = 0.255787   ViT's Loss = 0.077105   loss_vit_to_cnn = 1.586955   loss_cnn_to_vit = 0.203736   \n",
            "\n",
            "Iters: (180/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000987   CNN's loss = 0.156502   ViT's Loss = 0.073361   loss_vit_to_cnn = 0.790082   loss_cnn_to_vit = 0.118590   \n",
            "\n",
            "Iters: (200/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000985   CNN's loss = 0.543462   ViT's Loss = 0.044438   loss_vit_to_cnn = 0.862631   loss_cnn_to_vit = 0.163423   \n",
            "\n",
            "Iters: (220/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000984   CNN's loss = 0.104558   ViT's Loss = 0.101781   loss_vit_to_cnn = 1.797248   loss_cnn_to_vit = 0.143980   \n",
            "\n",
            "Iters: (240/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000982   CNN's loss = 0.202213   ViT's Loss = 0.084202   loss_vit_to_cnn = 0.892973   loss_cnn_to_vit = 0.080997   \n",
            "\n",
            "Iters: (260/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000981   CNN's loss = 0.414273   ViT's Loss = 0.071845   loss_vit_to_cnn = 1.138634   loss_cnn_to_vit = 0.021983   \n",
            "\n",
            "Iters: (280/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000980   CNN's loss = 0.276223   ViT's Loss = 0.026110   loss_vit_to_cnn = 1.293358   loss_cnn_to_vit = 0.190772   \n",
            "\n",
            "Iters: (300/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000978   CNN's loss = 0.280365   ViT's Loss = 0.062700   loss_vit_to_cnn = 1.015141   loss_cnn_to_vit = 0.026036   \n",
            "\n",
            "Iters: (320/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000977   CNN's loss = 0.236587   ViT's Loss = 0.003693   loss_vit_to_cnn = 1.546817   loss_cnn_to_vit = 0.022163   \n",
            "\n",
            "Iters: (340/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000975   CNN's loss = 0.175910   ViT's Loss = 0.006161   loss_vit_to_cnn = 0.614856   loss_cnn_to_vit = 0.216903   \n",
            "\n",
            "Iters: (360/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000974   CNN's loss = 0.053870   ViT's Loss = 0.006826   loss_vit_to_cnn = 0.765433   loss_cnn_to_vit = 0.062929   \n",
            "\n",
            "Iters: (380/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000972   CNN's loss = 0.161921   ViT's Loss = 0.008802   loss_vit_to_cnn = 1.074465   loss_cnn_to_vit = 0.175475   \n",
            "\n",
            "Iters: (400/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000971   CNN's loss = 0.198886   ViT's Loss = 0.026302   loss_vit_to_cnn = 1.125380   loss_cnn_to_vit = 0.080176   \n",
            "\n",
            "Iters: (420/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000970   CNN's loss = 0.095528   ViT's Loss = 0.004788   loss_vit_to_cnn = 0.662293   loss_cnn_to_vit = 0.062573   \n",
            "\n",
            "Iters: (440/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000968   CNN's loss = 0.269322   ViT's Loss = 0.007748   loss_vit_to_cnn = 1.340596   loss_cnn_to_vit = 0.219091   \n",
            "\n",
            "Iters: (460/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000967   CNN's loss = 0.058341   ViT's Loss = 0.001688   loss_vit_to_cnn = 0.730862   loss_cnn_to_vit = 0.103404   \n",
            "\n",
            "Iters: (480/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000965   CNN's loss = 0.111955   ViT's Loss = 0.080810   loss_vit_to_cnn = 0.870171   loss_cnn_to_vit = 0.026152   \n",
            "\n",
            "100%|███████████████████████████████████████████| 87/87 [00:20<00:00,  4.17it/s]\n",
            "  -- Domain task [Product --> Art] \n",
            "\t-- CNN's Accuracy Target Test = 74.1656%  ViT's Accuracy Target Test = 78.8628% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/officehome_uda/Product_to_Art_UDA_baseline\n",
            "  -- Saved ViT Branch (G1 + F1) at ./results/officehome_uda/Product_to_Art_UDA_baseline\n",
            "\u001b[31m  -- Domain task [Product --> Art]: \n",
            "\t-- The best CNN's Acc Target Test = 74.1656% The best ViT's Acc Target Test = 78.8628% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8779 Correct_Pseudo_Labels_CNN = 1488 Total_Pseudo_Labels_CNN = 1695       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.8360 Correct_Pseudo_Labels_ViT = 1845 Total_Pseudo_Labels_ViT = 2207       \n",
            "\u001b[0m\n",
            "Iters: (500/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000964   CNN's loss = 0.216392   ViT's Loss = 0.013656   loss_vit_to_cnn = 1.236970   loss_cnn_to_vit = 0.304311   \n",
            "\n",
            "Iters: (520/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000963   CNN's loss = 0.111353   ViT's Loss = 0.034711   loss_vit_to_cnn = 0.845576   loss_cnn_to_vit = 0.151214   \n",
            "\n",
            "Iters: (540/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000961   CNN's loss = 0.468525   ViT's Loss = 0.299709   loss_vit_to_cnn = 1.256024   loss_cnn_to_vit = 0.016487   \n",
            "\n",
            "Iters: (560/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000960   CNN's loss = 0.173788   ViT's Loss = 0.003286   loss_vit_to_cnn = 0.866011   loss_cnn_to_vit = 0.377132   \n",
            "\n",
            "Iters: (580/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000959   CNN's loss = 0.085177   ViT's Loss = 0.013794   loss_vit_to_cnn = 0.465947   loss_cnn_to_vit = 0.194827   \n",
            "\n",
            "Iters: (600/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000957   CNN's loss = 0.098722   ViT's Loss = 0.038034   loss_vit_to_cnn = 1.037170   loss_cnn_to_vit = 0.231524   \n",
            "\n",
            "Iters: (620/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000956   CNN's loss = 0.155800   ViT's Loss = 0.288442   loss_vit_to_cnn = 0.969778   loss_cnn_to_vit = 0.363822   \n",
            "\n",
            "Iters: (640/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000955   CNN's loss = 0.271702   ViT's Loss = 0.005728   loss_vit_to_cnn = 0.937855   loss_cnn_to_vit = 0.196911   \n",
            "\n",
            "Iters: (660/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000953   CNN's loss = 0.254426   ViT's Loss = 0.232950   loss_vit_to_cnn = 1.538148   loss_cnn_to_vit = 0.291164   \n",
            "\n",
            "Iters: (680/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000952   CNN's loss = 0.327084   ViT's Loss = 0.030515   loss_vit_to_cnn = 0.379968   loss_cnn_to_vit = 0.004604   \n",
            "\n",
            "Iters: (700/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000951   CNN's loss = 0.141552   ViT's Loss = 0.096704   loss_vit_to_cnn = 0.526444   loss_cnn_to_vit = 0.206372   \n",
            "\n",
            "Iters: (720/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000949   CNN's loss = 0.021940   ViT's Loss = 0.009009   loss_vit_to_cnn = 0.711148   loss_cnn_to_vit = 0.014216   \n",
            "\n",
            "Iters: (740/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000948   CNN's loss = 0.072204   ViT's Loss = 0.030568   loss_vit_to_cnn = 0.809509   loss_cnn_to_vit = 0.167090   \n",
            "\n",
            "Iters: (760/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000947   CNN's loss = 0.093119   ViT's Loss = 0.187090   loss_vit_to_cnn = 0.614638   loss_cnn_to_vit = 0.174804   \n",
            "\n",
            "Iters: (780/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000945   CNN's loss = 0.106630   ViT's Loss = 0.035944   loss_vit_to_cnn = 0.212176   loss_cnn_to_vit = 0.014241   \n",
            "\n",
            "Iters: (800/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000944   CNN's loss = 0.058544   ViT's Loss = 0.032198   loss_vit_to_cnn = 0.716956   loss_cnn_to_vit = 0.074067   \n",
            "\n",
            "Iters: (820/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000943   CNN's loss = 0.074493   ViT's Loss = 0.004049   loss_vit_to_cnn = 0.967940   loss_cnn_to_vit = 0.004697   \n",
            "\n",
            "Iters: (840/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000941   CNN's loss = 0.095843   ViT's Loss = 0.002638   loss_vit_to_cnn = 0.904440   loss_cnn_to_vit = 0.380790   \n",
            "\n",
            "Iters: (860/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000940   CNN's loss = 0.076827   ViT's Loss = 0.082820   loss_vit_to_cnn = 0.400354   loss_cnn_to_vit = 0.295454   \n",
            "\n",
            "Iters: (880/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000939   CNN's loss = 0.152319   ViT's Loss = 0.007730   loss_vit_to_cnn = 0.500607   loss_cnn_to_vit = 0.191145   \n",
            "\n",
            "Iters: (900/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000937   CNN's loss = 0.100004   ViT's Loss = 0.079446   loss_vit_to_cnn = 1.062871   loss_cnn_to_vit = 0.575005   \n",
            "\n",
            "Iters: (920/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000936   CNN's loss = 0.043672   ViT's Loss = 0.016905   loss_vit_to_cnn = 1.091759   loss_cnn_to_vit = 0.030105   \n",
            "\n",
            "Iters: (940/1000) \t lr_g1 = 0.000093   lr_g2 = 0.000935   CNN's loss = 0.628727   ViT's Loss = 0.565585   loss_vit_to_cnn = 0.797504   loss_cnn_to_vit = 0.146688   \n",
            "\n",
            "Iters: (960/1000) \t lr_g1 = 0.000093   lr_g2 = 0.000934   CNN's loss = 0.110320   ViT's Loss = 0.053027   loss_vit_to_cnn = 0.915865   loss_cnn_to_vit = 0.233103   \n",
            "\n",
            "Iters: (980/1000) \t lr_g1 = 0.000093   lr_g2 = 0.000932   CNN's loss = 0.143845   ViT's Loss = 0.026459   loss_vit_to_cnn = 1.125531   loss_cnn_to_vit = 0.137137   \n",
            "\n",
            "Iters: (999/1000) \t lr_g1 = 0.000093   lr_g2 = 0.000931   CNN's loss = 0.125894   ViT's Loss = 0.006298   loss_vit_to_cnn = 0.592139   loss_cnn_to_vit = 0.342756   \n",
            "\n",
            "100%|███████████████████████████████████████████| 87/87 [00:20<00:00,  4.35it/s]\n",
            "  -- Domain task [Product --> Art] \n",
            "\t-- CNN's Accuracy Target Test = 78.6980%  ViT's Accuracy Target Test = 80.2225% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/officehome_uda/Product_to_Art_UDA_baseline\n",
            "  -- Saved ViT Branch (G1 + F1) at ./results/officehome_uda/Product_to_Art_UDA_baseline\n",
            "\u001b[31m  -- Domain task [Product --> Art]: \n",
            "\t-- The best CNN's Acc Target Test = 78.6980% The best ViT's Acc Target Test = 80.2225% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8526 Correct_Pseudo_Labels_CNN = 1752 Total_Pseudo_Labels_CNN = 2055       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.8325 Correct_Pseudo_Labels_ViT = 1903 Total_Pseudo_Labels_ViT = 2286       \n",
            "\u001b[0m\n",
            "\u001b[31mFinished training and evaluation!\u001b[0m\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Novelty tries"
      ],
      "metadata": {
        "id": "65bhzS-6R0Xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file paths\n",
        "source_file = \"/kaggle/input/trainyamlfle4/trainer.py\"\n",
        "destination_file = \"/kaggle/working/ECB/trainer.py\"\n",
        "\n",
        "# # Create a sample source file\n",
        "# with open(source_file, \"r\") as f:\n",
        "#     f.write(\"This is the original content.\")\n",
        "\n",
        "# Copy contents\n",
        "with open(source_file, \"r\") as src, open(destination_file, \"w\") as dest:\n",
        "    dest.write(src.read())\n",
        "\n",
        "print(f\"Copied contents from {source_file} to {destination_file}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-01T11:11:12.889287Z",
          "iopub.status.busy": "2025-05-01T11:11:12.888962Z",
          "iopub.status.idle": "2025-05-01T11:11:12.901884Z",
          "shell.execute_reply": "2025-05-01T11:11:12.901023Z",
          "shell.execute_reply.started": "2025-05-01T11:11:12.889263Z"
        },
        "trusted": true,
        "id": "d0_l0t5RRkxg",
        "outputId": "665717d8-cc03-446a-f311-8ee71cfa5ba1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copied contents from /kaggle/input/trainyamlfle4/trainer.py to /kaggle/working/ECB/trainer.py\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file paths\n",
        "source_file = \"/kaggle/input/trainyaml2/train.yaml\"\n",
        "destination_file = \"/kaggle/working/ECB/configs/train.yaml\"\n",
        "\n",
        "# # Create a sample source file\n",
        "# with open(source_file, \"r\") as f:\n",
        "#     f.write(\"This is the original content.\")\n",
        "\n",
        "# Copy contents\n",
        "with open(source_file, \"r\") as src, open(destination_file, \"w\") as dest:\n",
        "    dest.write(src.read())\n",
        "\n",
        "print(f\"Copied contents from {source_file} to {destination_file}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-01T11:18:15.062328Z",
          "iopub.status.busy": "2025-05-01T11:18:15.061970Z",
          "iopub.status.idle": "2025-05-01T11:18:15.072175Z",
          "shell.execute_reply": "2025-05-01T11:18:15.071364Z",
          "shell.execute_reply.started": "2025-05-01T11:18:15.062297Z"
        },
        "trusted": true,
        "outputId": "2fc11686-ca36-4c13-9b0b-022af1355ce5",
        "id": "E31ohTgPSFYd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copied contents from /kaggle/input/trainyaml2/train.yaml to /kaggle/working/ECB/configs/train.yaml\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file paths\n",
        "source_file = \"/kaggle/input/trainyamlfile/utils.py\"\n",
        "destination_file = \"/kaggle/working/ECB/utils/utils.py\"\n",
        "\n",
        "# # Create a sample source file\n",
        "# with open(source_file, \"r\") as f:\n",
        "#     f.write(\"This is the original content.\")\n",
        "\n",
        "# Copy contents\n",
        "with open(source_file, \"r\") as src, open(destination_file, \"w\") as dest:\n",
        "    dest.write(src.read())\n",
        "\n",
        "print(f\"Copied contents from {source_file} to {destination_file}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-01T07:31:39.313685Z",
          "iopub.status.busy": "2025-05-01T07:31:39.313435Z",
          "iopub.status.idle": "2025-05-01T07:31:39.337043Z",
          "shell.execute_reply": "2025-05-01T07:31:39.336462Z",
          "shell.execute_reply.started": "2025-05-01T07:31:39.313665Z"
        },
        "trusted": true,
        "id": "n3LHqW1FRkxg",
        "outputId": "4cb32fe4-544a-4f44-e1a7-1414f2eed765"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copied contents from /kaggle/input/trainyamlfile/utils.py to /kaggle/working/ECB/utils/utils.py\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file paths\n",
        "source_file = \"/kaggle/input/trainyamlfile/loss.py\"\n",
        "destination_file = \"/kaggle/working/ECB/utils/loss.py\"\n",
        "\n",
        "# # Create a sample source file\n",
        "# with open(source_file, \"r\") as f:\n",
        "#     f.write(\"This is the original content.\")\n",
        "\n",
        "# Copy contents\n",
        "with open(source_file, \"r\") as src, open(destination_file, \"w\") as dest:\n",
        "    dest.write(src.read())\n",
        "\n",
        "print(f\"Copied contents from {source_file} to {destination_file}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-01T07:31:39.337858Z",
          "iopub.status.busy": "2025-05-01T07:31:39.337678Z",
          "iopub.status.idle": "2025-05-01T07:31:39.348512Z",
          "shell.execute_reply": "2025-05-01T07:31:39.347753Z",
          "shell.execute_reply.started": "2025-05-01T07:31:39.337842Z"
        },
        "trusted": true,
        "id": "a9O4ODS8Rkxg",
        "outputId": "fdd7de39-c6ed-4e8e-c44d-20a0f3dfe085"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copied contents from /kaggle/input/trainyamlfile/loss.py to /kaggle/working/ECB/utils/loss.py\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAT and USCL ( 1000 epochs without warmup phase, 26 batch size, SSDA, Office31 )"
      ],
      "metadata": {
        "id": "V7-qmdEaRkxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!source activate ecb && echo \"Activated: $CONDA_DEFAULT_ENV\" && python train.py --cfg configs/train.yaml"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-01T11:18:20.938967Z",
          "iopub.status.busy": "2025-05-01T11:18:20.938622Z",
          "iopub.status.idle": "2025-05-01T12:54:15.568278Z",
          "shell.execute_reply": "2025-05-01T12:54:15.567142Z",
          "shell.execute_reply.started": "2025-05-01T11:18:20.938938Z"
        },
        "trusted": true,
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "F4ayqOjHRkxh",
        "outputId": "936a8f59-ca36-484a-f890-cb6a740c63c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Activated: ecb\n",
            "/opt/conda/envs/ecb/lib/python3.9/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "========== DATA PATH ==========\n",
            "source train: ./dataset/office31_ssda/labeled_source_images_webcam.txt\n",
            "source test: ./dataset/office31_ssda/validation_target_images_webcam_3.txt\n",
            "target train: ./dataset/office31_ssda/unlabeled_target_images_amazon_3.txt\n",
            "target test: ./dataset/office31_ssda/unlabeled_target_images_amazon_3.txt\n",
            "===============================\n",
            "/opt/conda/envs/ecb/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/opt/conda/envs/ecb/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "======== LOAD PRETRAIN ========\n",
            "Loading pretrain ImageNet: VisionTransformer\n",
            "Loading pretrain ImageNet: AlexNetBase\n",
            "Weight Init: Predictor_deep\n",
            "Weight Init: Predictor_deep\n",
            "===============================\n",
            "{'DEVICE': device(type='cuda', index=0), 'ndomains': 2, 'output_path': './results/office31_ssda/webcam_to_amazon_SSDA_3_baseline', 'output_name': 'baseline', 'source_iters': 0, 'adapt_iters': 1000, 'test_interval': 100, 'seed': 1, 'warmup': True, 'pretrained_models': '', 'lamda': 0.1, 'save_models': True, 'thresh_ViT': 0.6, 'thresh_CNN': 0.8, 'dataset': {'method': 'SSDA', 'data_root': '../Dataset/office31', 'data_label': './dataset/office31_ssda', 'num_workers': 8, 'target_shot': 3, 'use_cgct_mask': True, 'source': {'name': 'webcam', 'batch_size': 26}, 'target': {'name': 'amazon', 'batch_size': 26}, 'prep': {'source_w': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x78502d7d7f70>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'source_str': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x784f7709f0a0>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    <utils.preprocess.RandAugmentMC object at 0x784f7709f160>\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'target_w': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x784f7709f2e0>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'target_str': Compose(\n",
            "    <utils.randaugment.RandAugment object at 0x784f7709f6a0>\n",
            "    <utils.preprocess.ResizeImage object at 0x784f7709f490>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'test': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x784f7709f700>\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'val': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x784f7709f5e0>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")}, 'name': 'office31_ssda'}, 'optimizer': {'lr': 1.0, 'lr_vit': 0.001, 'lr_cnn': 0.01, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}, 'Architecture': {'Backbone': {'name_1': 'vit', 'pretrained_1': '', 'name_2': 'alexnet', 'pretrained_2': ''}, 'Classifier': {'name_1': 'MLP', 'pretrained_F1': '', 'name_2': 'MLP', 'pretrained_F2': ''}, 'class_num': 31}, 'mixup_thresh': 0.7, 'alpha': 0.2, 'lambda_mixup': 0.8, 'percentile': 60, 'lambda': 0.5, 'num_classes': 31, 'sat_alpha': 0.85, 'warmup_iters': 200, 'output_path_warmup': 'office31_ssda/webcam_to_amazon_SSDA_3_pretrained_warmup', 'out_file_warmup': <_io.TextIOWrapper name='office31_ssda/webcam_to_amazon_SSDA_3_pretrained_warmup/log.txt' mode='w' encoding='UTF-8'>, 'out_file': <_io.TextIOWrapper name='./results/office31_ssda/webcam_to_amazon_SSDA_3_baseline/log.txt' mode='w' encoding='UTF-8'>}\n",
            "\u001b[31m==> Step 1: Pre-training on the labeled dataset ...\u001b[0m\n",
            "\u001b[31mMethod: SSDA - File: trainer_warmup.py\u001b[0m\n",
            "\u001b[31m==> Finished pre-training on source!\n",
            "\u001b[0m\n",
            "======== LOAD PRETRAIN ========\n",
            "Loading: office31_ssda/webcam_to_amazon_SSDA_3_pretrained_warmup/the_best_G1_pretrained.pth.tar\n",
            "Pretrain weights VisionTransformer loaded.\n",
            "Loading: office31_ssda/webcam_to_amazon_SSDA_3_pretrained_warmup/the_best_G2_pretrained.pth.tar\n",
            "Pretrain weights AlexNetBase loaded.\n",
            "Loading: office31_ssda/webcam_to_amazon_SSDA_3_pretrained_warmup/the_best_F1_pretrained.pth.tar\n",
            "Pretrain weights Predictor_deep loaded.\n",
            "Loading: office31_ssda/webcam_to_amazon_SSDA_3_pretrained_warmup/the_best_F2_pretrained.pth.tar\n",
            "Pretrain weights Predictor_deep loaded.\n",
            "===============================\n",
            "{'DEVICE': device(type='cuda', index=0), 'ndomains': 2, 'output_path': './results/office31_ssda/webcam_to_amazon_SSDA_3_baseline', 'output_name': 'baseline', 'source_iters': 0, 'adapt_iters': 1000, 'test_interval': 100, 'seed': 1, 'warmup': True, 'pretrained_models': '', 'lamda': 0.1, 'save_models': True, 'thresh_ViT': 0.6, 'thresh_CNN': 0.8, 'dataset': {'method': 'SSDA', 'data_root': '../Dataset/office31', 'data_label': './dataset/office31_ssda', 'num_workers': 8, 'target_shot': 3, 'use_cgct_mask': True, 'source': {'name': 'webcam', 'batch_size': 26}, 'target': {'name': 'amazon', 'batch_size': 26}, 'prep': {'source_w': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x78502d7d7f70>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'source_str': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x784f7709f0a0>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    <utils.preprocess.RandAugmentMC object at 0x784f7709f160>\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'target_w': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x784f7709f2e0>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'target_str': Compose(\n",
            "    <utils.randaugment.RandAugment object at 0x784f7709f6a0>\n",
            "    <utils.preprocess.ResizeImage object at 0x784f7709f490>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'test': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x784f7709f700>\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'val': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x784f7709f5e0>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")}, 'name': 'office31_ssda'}, 'optimizer': {'lr': 1.0, 'lr_vit': 0.001, 'lr_cnn': 0.01, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}, 'Architecture': {'Backbone': {'name_1': 'vit', 'pretrained_1': 'office31_ssda/webcam_to_amazon_SSDA_3_pretrained_warmup/the_best_G1_pretrained.pth.tar', 'name_2': 'alexnet', 'pretrained_2': 'office31_ssda/webcam_to_amazon_SSDA_3_pretrained_warmup/the_best_G2_pretrained.pth.tar'}, 'Classifier': {'name_1': 'MLP', 'pretrained_F1': 'office31_ssda/webcam_to_amazon_SSDA_3_pretrained_warmup/the_best_F1_pretrained.pth.tar', 'name_2': 'MLP', 'pretrained_F2': 'office31_ssda/webcam_to_amazon_SSDA_3_pretrained_warmup/the_best_F2_pretrained.pth.tar'}, 'class_num': 31}, 'mixup_thresh': 0.7, 'alpha': 0.2, 'lambda_mixup': 0.8, 'percentile': 60, 'lambda': 0.5, 'num_classes': 31, 'sat_alpha': 0.85, 'warmup_iters': 200, 'output_path_warmup': 'office31_ssda/webcam_to_amazon_SSDA_3_pretrained_warmup', 'out_file_warmup': <_io.TextIOWrapper name='office31_ssda/webcam_to_amazon_SSDA_3_pretrained_warmup/log.txt' mode='w' encoding='UTF-8'>, 'out_file': <_io.TextIOWrapper name='./results/office31_ssda/webcam_to_amazon_SSDA_3_baseline/log.txt' mode='w' encoding='UTF-8'>}\n",
            "\u001b[31m==> Starting the adaptation\u001b[0m\n",
            "\u001b[31mMethod: SSDA - File: trainer.py\u001b[0m\n",
            "Iters: (0/1000) \t lr_g1 = 0.000100   lr_g2 = 0.001000   CNN's loss = 0.771216   ViT's Loss = 0.126114   loss_vit_to_cnn = 2.038557   loss_cnn_to_vit = 3.040396   \n",
            "\n",
            "Iters: (20/1000) \t lr_g1 = 0.000100   lr_g2 = 0.000999   CNN's loss = 1.037495   ViT's Loss = 0.143240   loss_vit_to_cnn = 2.364200   loss_cnn_to_vit = 2.394882   \n",
            "\n",
            "Iters: (40/1000) \t lr_g1 = 0.000100   lr_g2 = 0.000997   CNN's loss = 0.261476   ViT's Loss = 0.101974   loss_vit_to_cnn = 1.967731   loss_cnn_to_vit = 1.525841   \n",
            "\n",
            "Iters: (60/1000) \t lr_g1 = 0.000100   lr_g2 = 0.000996   CNN's loss = 0.333999   ViT's Loss = 0.061359   loss_vit_to_cnn = 2.400054   loss_cnn_to_vit = 0.934072   \n",
            "\n",
            "Iters: (80/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000994   CNN's loss = 0.191075   ViT's Loss = 0.027389   loss_vit_to_cnn = 2.125129   loss_cnn_to_vit = 0.901139   \n",
            "\n",
            "Number of classes:  31\n",
            "100%|█████████████████████████████████████████| 105/105 [00:17<00:00,  5.89it/s]\n",
            "Number of classes:  31\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.73it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 64.5161%  ViT's Accuracy Target Val =  74.1935% \n",
            "\t-- CNN's Accuracy Target Test = 64.4273%  ViT's Accuracy Target Test = 74.4493% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/office31_ssda/webcam_to_amazon_SSDA_3_baseline\n",
            "  -- Saved ViT Branch (G1 + F1) at ./results/office31_ssda/webcam_to_amazon_SSDA_3_baseline\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 64.5161% The best Vit's Acc Target Val = 74.1935% \n",
            "\t-- The best CNN's Acc Target Test = 64.4273% The best ViT's Acc Target Test = 74.4493% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8110 Correct_Pseudo_Labels_CNN = 1412 Total_Pseudo_Labels_CNN = 1741       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.9083 Correct_Pseudo_Labels_ViT = 1673 Total_Pseudo_Labels_ViT = 1842       \n",
            "\u001b[0m\n",
            "Iters: (100/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000993   CNN's loss = 0.277665   ViT's Loss = 0.028162   loss_vit_to_cnn = 1.959789   loss_cnn_to_vit = 1.536362   \n",
            "\n",
            "Iters: (120/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000991   CNN's loss = 0.158859   ViT's Loss = 0.021356   loss_vit_to_cnn = 1.945522   loss_cnn_to_vit = 1.333808   \n",
            "\n",
            "Iters: (140/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000990   CNN's loss = 0.338916   ViT's Loss = 0.057552   loss_vit_to_cnn = 1.600249   loss_cnn_to_vit = 1.563039   \n",
            "\n",
            "Iters: (160/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000988   CNN's loss = 0.143241   ViT's Loss = 0.035001   loss_vit_to_cnn = 2.565219   loss_cnn_to_vit = 1.232372   \n",
            "\n",
            "Iters: (180/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000987   CNN's loss = 0.114527   ViT's Loss = 0.033686   loss_vit_to_cnn = 1.661959   loss_cnn_to_vit = 0.955383   \n",
            "\n",
            "Number of classes:  31\n",
            "100%|█████████████████████████████████████████| 105/105 [00:17<00:00,  6.02it/s]\n",
            "Number of classes:  31\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.58it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 61.2903%  ViT's Accuracy Target Val =  79.5699% \n",
            "\t-- CNN's Accuracy Target Test = 64.7577%  ViT's Accuracy Target Test = 75.9912% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/office31_ssda/webcam_to_amazon_SSDA_3_baseline\n",
            "  -- Saved ViT Branch (G1 + F1) at ./results/office31_ssda/webcam_to_amazon_SSDA_3_baseline\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 64.5161% The best Vit's Acc Target Val = 79.5699% \n",
            "\t-- The best CNN's Acc Target Test = 64.7577% The best ViT's Acc Target Test = 75.9912% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8139 Correct_Pseudo_Labels_CNN = 1483 Total_Pseudo_Labels_CNN = 1822       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.8992 Correct_Pseudo_Labels_ViT = 1669 Total_Pseudo_Labels_ViT = 1856       \n",
            "\u001b[0m\n",
            "Iters: (200/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000985   CNN's loss = 0.163277   ViT's Loss = 0.033874   loss_vit_to_cnn = 1.925472   loss_cnn_to_vit = 1.178829   \n",
            "\n",
            "Iters: (220/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000984   CNN's loss = 0.115245   ViT's Loss = 0.022025   loss_vit_to_cnn = 1.327691   loss_cnn_to_vit = 0.900409   \n",
            "\n",
            "Iters: (240/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000982   CNN's loss = 0.159490   ViT's Loss = 0.029897   loss_vit_to_cnn = 2.082920   loss_cnn_to_vit = 1.259236   \n",
            "\n",
            "Iters: (260/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000981   CNN's loss = 0.057092   ViT's Loss = 0.017844   loss_vit_to_cnn = 1.873300   loss_cnn_to_vit = 1.087066   \n",
            "\n",
            "Iters: (280/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000980   CNN's loss = 0.050148   ViT's Loss = 0.015239   loss_vit_to_cnn = 1.661674   loss_cnn_to_vit = 1.069471   \n",
            "\n",
            "Number of classes:  31\n",
            "100%|█████████████████████████████████████████| 105/105 [00:17<00:00,  6.06it/s]\n",
            "Number of classes:  31\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.72it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 66.6667%  ViT's Accuracy Target Val =  73.1183% \n",
            "\t-- CNN's Accuracy Target Test = 67.1439%  ViT's Accuracy Target Test = 72.0631% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/office31_ssda/webcam_to_amazon_SSDA_3_baseline\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 66.6667% The best Vit's Acc Target Val = 79.5699% \n",
            "\t-- The best CNN's Acc Target Test = 67.1439% The best ViT's Acc Target Test = 75.9912% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8289 Correct_Pseudo_Labels_CNN = 1507 Total_Pseudo_Labels_CNN = 1818       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.8649 Correct_Pseudo_Labels_ViT = 1600 Total_Pseudo_Labels_ViT = 1850       \n",
            "\u001b[0m\n",
            "Iters: (300/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000978   CNN's loss = 0.103831   ViT's Loss = 0.047428   loss_vit_to_cnn = 1.834472   loss_cnn_to_vit = 1.695447   \n",
            "\n",
            "Iters: (320/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000977   CNN's loss = 0.109585   ViT's Loss = 0.023748   loss_vit_to_cnn = 0.794397   loss_cnn_to_vit = 0.781446   \n",
            "\n",
            "Iters: (340/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000975   CNN's loss = 0.117950   ViT's Loss = 0.032470   loss_vit_to_cnn = 1.464939   loss_cnn_to_vit = 1.059253   \n",
            "\n",
            "Iters: (360/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000974   CNN's loss = 0.069151   ViT's Loss = 0.026814   loss_vit_to_cnn = 1.782315   loss_cnn_to_vit = 0.684385   \n",
            "\n",
            "Iters: (380/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000972   CNN's loss = 0.159389   ViT's Loss = 0.025159   loss_vit_to_cnn = 1.033726   loss_cnn_to_vit = 0.876666   \n",
            "\n",
            "Number of classes:  31\n",
            "100%|█████████████████████████████████████████| 105/105 [00:17<00:00,  6.07it/s]\n",
            "Number of classes:  31\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.80it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 68.8172%  ViT's Accuracy Target Val =  76.3441% \n",
            "\t-- CNN's Accuracy Target Test = 67.6579%  ViT's Accuracy Target Test = 72.6505% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/office31_ssda/webcam_to_amazon_SSDA_3_baseline\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 68.8172% The best Vit's Acc Target Val = 79.5699% \n",
            "\t-- The best CNN's Acc Target Test = 67.6579% The best ViT's Acc Target Test = 75.9912% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8262 Correct_Pseudo_Labels_CNN = 1569 Total_Pseudo_Labels_CNN = 1899       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.8624 Correct_Pseudo_Labels_ViT = 1680 Total_Pseudo_Labels_ViT = 1948       \n",
            "\u001b[0m\n",
            "Iters: (400/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000971   CNN's loss = 0.062222   ViT's Loss = 0.019862   loss_vit_to_cnn = 1.645693   loss_cnn_to_vit = 0.977482   \n",
            "\n",
            "Iters: (420/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000970   CNN's loss = 0.152419   ViT's Loss = 0.019985   loss_vit_to_cnn = 2.155160   loss_cnn_to_vit = 1.855119   \n",
            "\n",
            "Iters: (440/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000968   CNN's loss = 0.159083   ViT's Loss = 0.036629   loss_vit_to_cnn = 1.818016   loss_cnn_to_vit = 0.912648   \n",
            "\n",
            "Iters: (460/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000967   CNN's loss = 0.025078   ViT's Loss = 0.025665   loss_vit_to_cnn = 1.965109   loss_cnn_to_vit = 1.188177   \n",
            "\n",
            "Iters: (480/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000965   CNN's loss = 0.058861   ViT's Loss = 0.015119   loss_vit_to_cnn = 1.139857   loss_cnn_to_vit = 0.635514   \n",
            "\n",
            "Number of classes:  31\n",
            "100%|█████████████████████████████████████████| 105/105 [00:17<00:00,  5.96it/s]\n",
            "Number of classes:  31\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.70it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 73.1183%  ViT's Accuracy Target Val =  73.1183% \n",
            "\t-- CNN's Accuracy Target Test = 69.7504%  ViT's Accuracy Target Test = 73.7518% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/office31_ssda/webcam_to_amazon_SSDA_3_baseline\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 73.1183% The best Vit's Acc Target Val = 79.5699% \n",
            "\t-- The best CNN's Acc Target Test = 69.7504% The best ViT's Acc Target Test = 75.9912% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8197 Correct_Pseudo_Labels_CNN = 1637 Total_Pseudo_Labels_CNN = 1997       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.8822 Correct_Pseudo_Labels_ViT = 1723 Total_Pseudo_Labels_ViT = 1953       \n",
            "\u001b[0m\n",
            "Iters: (500/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000964   CNN's loss = 0.114892   ViT's Loss = 0.021324   loss_vit_to_cnn = 1.307977   loss_cnn_to_vit = 1.401946   \n",
            "\n",
            "Iters: (520/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000963   CNN's loss = 0.089840   ViT's Loss = 0.016557   loss_vit_to_cnn = 1.013186   loss_cnn_to_vit = 1.247937   \n",
            "\n",
            "Iters: (540/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000961   CNN's loss = 0.244104   ViT's Loss = 0.014868   loss_vit_to_cnn = 1.800300   loss_cnn_to_vit = 1.039887   \n",
            "\n",
            "Iters: (560/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000960   CNN's loss = 0.024633   ViT's Loss = 0.022364   loss_vit_to_cnn = 1.328517   loss_cnn_to_vit = 0.759389   \n",
            "\n",
            "Iters: (580/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000959   CNN's loss = 0.120275   ViT's Loss = 0.028487   loss_vit_to_cnn = 1.508675   loss_cnn_to_vit = 1.027885   \n",
            "\n",
            "Number of classes:  31\n",
            "100%|█████████████████████████████████████████| 105/105 [00:17<00:00,  6.02it/s]\n",
            "Number of classes:  31\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.59it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 73.1183%  ViT's Accuracy Target Val =  75.2688% \n",
            "\t-- CNN's Accuracy Target Test = 69.8238%  ViT's Accuracy Target Test = 74.3025% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/office31_ssda/webcam_to_amazon_SSDA_3_baseline\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 73.1183% The best Vit's Acc Target Val = 79.5699% \n",
            "\t-- The best CNN's Acc Target Test = 69.8238% The best ViT's Acc Target Test = 75.9912% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8238 Correct_Pseudo_Labels_CNN = 1655 Total_Pseudo_Labels_CNN = 2009       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.8702 Correct_Pseudo_Labels_ViT = 1729 Total_Pseudo_Labels_ViT = 1987       \n",
            "\u001b[0m\n",
            "Iters: (600/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000957   CNN's loss = 0.021403   ViT's Loss = 0.016219   loss_vit_to_cnn = 1.420638   loss_cnn_to_vit = 0.869802   \n",
            "\n",
            "Iters: (620/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000956   CNN's loss = 0.024585   ViT's Loss = 0.014381   loss_vit_to_cnn = 0.768562   loss_cnn_to_vit = 0.198091   \n",
            "\n",
            "Iters: (640/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000955   CNN's loss = 0.036600   ViT's Loss = 0.012288   loss_vit_to_cnn = 0.730405   loss_cnn_to_vit = 0.928505   \n",
            "\n",
            "Iters: (660/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000953   CNN's loss = 0.054132   ViT's Loss = 0.017440   loss_vit_to_cnn = 0.858435   loss_cnn_to_vit = 0.323467   \n",
            "\n",
            "Iters: (680/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000952   CNN's loss = 0.012758   ViT's Loss = 0.013672   loss_vit_to_cnn = 1.432920   loss_cnn_to_vit = 0.319866   \n",
            "\n",
            "Number of classes:  31\n",
            "100%|█████████████████████████████████████████| 105/105 [00:17<00:00,  5.98it/s]\n",
            "Number of classes:  31\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.75it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 77.4194%  ViT's Accuracy Target Val =  75.2688% \n",
            "\t-- CNN's Accuracy Target Test = 71.8429%  ViT's Accuracy Target Test = 76.1013% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/office31_ssda/webcam_to_amazon_SSDA_3_baseline\n",
            "  -- Saved ViT Branch (G1 + F1) at ./results/office31_ssda/webcam_to_amazon_SSDA_3_baseline\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 77.4194% The best Vit's Acc Target Val = 79.5699% \n",
            "\t-- The best CNN's Acc Target Test = 71.8429% The best ViT's Acc Target Test = 76.1013% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8222 Correct_Pseudo_Labels_CNN = 1669 Total_Pseudo_Labels_CNN = 2030       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.8656 Correct_Pseudo_Labels_ViT = 1777 Total_Pseudo_Labels_ViT = 2053       \n",
            "\u001b[0m\n",
            "Iters: (700/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000951   CNN's loss = 0.028392   ViT's Loss = 0.008128   loss_vit_to_cnn = 1.510647   loss_cnn_to_vit = 0.685341   \n",
            "\n",
            "Iters: (720/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000949   CNN's loss = 0.034456   ViT's Loss = 0.021150   loss_vit_to_cnn = 1.124308   loss_cnn_to_vit = 0.939788   \n",
            "\n",
            "Iters: (740/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000948   CNN's loss = 0.025401   ViT's Loss = 0.023404   loss_vit_to_cnn = 0.740436   loss_cnn_to_vit = 0.122634   \n",
            "\n",
            "Iters: (760/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000947   CNN's loss = 0.010628   ViT's Loss = 0.007037   loss_vit_to_cnn = 1.277657   loss_cnn_to_vit = 0.781020   \n",
            "\n",
            "Iters: (780/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000945   CNN's loss = 0.245119   ViT's Loss = 0.026096   loss_vit_to_cnn = 1.250736   loss_cnn_to_vit = 0.385939   \n",
            "\n",
            "Number of classes:  31\n",
            "100%|█████████████████████████████████████████| 105/105 [00:17<00:00,  6.07it/s]\n",
            "Number of classes:  31\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.69it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 77.4194%  ViT's Accuracy Target Val =  76.3441% \n",
            "\t-- CNN's Accuracy Target Test = 73.2012%  ViT's Accuracy Target Test = 75.0734% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/office31_ssda/webcam_to_amazon_SSDA_3_baseline\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 77.4194% The best Vit's Acc Target Val = 79.5699% \n",
            "\t-- The best CNN's Acc Target Test = 73.2012% The best ViT's Acc Target Test = 76.1013% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8412 Correct_Pseudo_Labels_CNN = 1774 Total_Pseudo_Labels_CNN = 2109       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.8301 Correct_Pseudo_Labels_ViT = 1730 Total_Pseudo_Labels_ViT = 2084       \n",
            "\u001b[0m\n",
            "Iters: (800/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000944   CNN's loss = 0.130393   ViT's Loss = 0.006091   loss_vit_to_cnn = 1.158294   loss_cnn_to_vit = 0.752328   \n",
            "\n",
            "Iters: (820/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000943   CNN's loss = 0.033521   ViT's Loss = 0.032945   loss_vit_to_cnn = 1.720539   loss_cnn_to_vit = 0.772590   \n",
            "\n",
            "Iters: (840/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000941   CNN's loss = 0.082286   ViT's Loss = 0.007662   loss_vit_to_cnn = 1.440254   loss_cnn_to_vit = 1.014474   \n",
            "\n",
            "Iters: (860/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000940   CNN's loss = 0.013251   ViT's Loss = 0.006748   loss_vit_to_cnn = 1.316305   loss_cnn_to_vit = 0.234052   \n",
            "\n",
            "Iters: (880/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000939   CNN's loss = 0.057414   ViT's Loss = 0.008236   loss_vit_to_cnn = 1.111116   loss_cnn_to_vit = 0.708445   \n",
            "\n",
            "Number of classes:  31\n",
            "100%|█████████████████████████████████████████| 105/105 [00:17<00:00,  6.01it/s]\n",
            "Number of classes:  31\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.70it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 74.1935%  ViT's Accuracy Target Val =  74.1935% \n",
            "\t-- CNN's Accuracy Target Test = 73.2379%  ViT's Accuracy Target Test = 75.6608% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/office31_ssda/webcam_to_amazon_SSDA_3_baseline\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 77.4194% The best Vit's Acc Target Val = 79.5699% \n",
            "\t-- The best CNN's Acc Target Test = 73.2379% The best ViT's Acc Target Test = 76.1013% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8295 Correct_Pseudo_Labels_CNN = 1688 Total_Pseudo_Labels_CNN = 2035       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.8699 Correct_Pseudo_Labels_ViT = 1772 Total_Pseudo_Labels_ViT = 2037       \n",
            "\u001b[0m\n",
            "Iters: (900/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000937   CNN's loss = 0.020508   ViT's Loss = 0.008772   loss_vit_to_cnn = 1.455301   loss_cnn_to_vit = 0.446429   \n",
            "\n",
            "Iters: (920/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000936   CNN's loss = 0.062476   ViT's Loss = 0.013608   loss_vit_to_cnn = 0.545508   loss_cnn_to_vit = 0.427699   \n",
            "\n",
            "Iters: (940/1000) \t lr_g1 = 0.000093   lr_g2 = 0.000935   CNN's loss = 0.128761   ViT's Loss = 0.018471   loss_vit_to_cnn = 1.453187   loss_cnn_to_vit = 0.198929   \n",
            "\n",
            "Iters: (960/1000) \t lr_g1 = 0.000093   lr_g2 = 0.000934   CNN's loss = 0.053417   ViT's Loss = 0.006943   loss_vit_to_cnn = 1.439521   loss_cnn_to_vit = 0.667478   \n",
            "\n",
            "Iters: (980/1000) \t lr_g1 = 0.000093   lr_g2 = 0.000932   CNN's loss = 0.038239   ViT's Loss = 0.006821   loss_vit_to_cnn = 1.409682   loss_cnn_to_vit = 0.324200   \n",
            "\n",
            "Iters: (999/1000) \t lr_g1 = 0.000093   lr_g2 = 0.000931   CNN's loss = 0.024243   ViT's Loss = 0.004935   loss_vit_to_cnn = 1.882565   loss_cnn_to_vit = 0.556369   \n",
            "\n",
            "Number of classes:  31\n",
            "100%|█████████████████████████████████████████| 105/105 [00:17<00:00,  6.03it/s]\n",
            "Number of classes:  31\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.62it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 75.2688%  ViT's Accuracy Target Val =  74.1935% \n",
            "\t-- CNN's Accuracy Target Test = 74.1557%  ViT's Accuracy Target Test = 75.7709% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/office31_ssda/webcam_to_amazon_SSDA_3_baseline\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 77.4194% The best Vit's Acc Target Val = 79.5699% \n",
            "\t-- The best CNN's Acc Target Test = 74.1557% The best ViT's Acc Target Test = 76.1013% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8219 Correct_Pseudo_Labels_CNN = 1758 Total_Pseudo_Labels_CNN = 2139       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.8649 Correct_Pseudo_Labels_ViT = 1805 Total_Pseudo_Labels_ViT = 2087       \n",
            "\u001b[0m\n",
            "\u001b[31mFinished training and evaluation!\u001b[0m\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAT with Class aware - modified novelty"
      ],
      "metadata": {
        "id": "UAGJ4xpSRkxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!source activate ecb && echo \"Activated: $CONDA_DEFAULT_ENV\" && python train.py --cfg configs/train.yaml"
      ],
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-04-21T18:06:42.761144Z",
          "iopub.status.busy": "2025-04-21T18:06:42.760879Z",
          "iopub.status.idle": "2025-04-21T19:36:19.476198Z",
          "shell.execute_reply": "2025-04-21T19:36:19.475126Z",
          "shell.execute_reply.started": "2025-04-21T18:06:42.761118Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "7YlA5A4ORkxi",
        "outputId": "7f526362-b428-43c6-c91c-4988d988d1b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Activated: ecb\n",
            "/opt/conda/envs/ecb/lib/python3.9/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "========== DATA PATH ==========\n",
            "source train: ./dataset/office31_ssda/labeled_source_images_webcam.txt\n",
            "source test: ./dataset/office31_ssda/validation_target_images_webcam_3.txt\n",
            "target train: ./dataset/office31_ssda/unlabeled_target_images_amazon_1.txt\n",
            "target test: ./dataset/office31_ssda/unlabeled_target_images_amazon_1.txt\n",
            "===============================\n",
            "Downloading model.safetensors: 100%|██████████| 346M/346M [00:01<00:00, 341MB/s]\n",
            "/opt/conda/envs/ecb/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/opt/conda/envs/ecb/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|█████████████████████████████████████████| 233M/233M [00:00<00:00, 306MB/s]\n",
            "======== LOAD PRETRAIN ========\n",
            "Loading pretrain ImageNet: VisionTransformer\n",
            "Loading pretrain ImageNet: AlexNetBase\n",
            "Weight Init: Predictor_deep\n",
            "Weight Init: Predictor_deep\n",
            "===============================\n",
            "{'DEVICE': device(type='cuda', index=0), 'ndomains': 2, 'output_path': './results/office31_ssda/webcam_to_amazon_SSDA_1_baseline', 'output_name': 'baseline', 'source_iters': 0, 'adapt_iters': 1000, 'test_interval': 100, 'seed': 1, 'warmup': True, 'pretrained_models': './pretrained/', 'lamda': 0.1, 'save_models': True, 'thresh_ViT': 0.6, 'thresh_CNN': 0.9, 'dataset': {'method': 'SSDA', 'data_root': '../Dataset/office31', 'data_label': './dataset/office31_ssda', 'num_workers': 8, 'target_shot': 1, 'use_cgct_mask': True, 'source': {'name': 'webcam', 'batch_size': 26}, 'target': {'name': 'amazon', 'batch_size': 26}, 'prep': {'source_w': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7814d1deae20>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'source_str': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7814c5e50eb0>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    <utils.preprocess.RandAugmentMC object at 0x7814c5e50fd0>\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'target_w': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7814c6904940>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'target_str': Compose(\n",
            "    <utils.randaugment.RandAugment object at 0x7814c6904c40>\n",
            "    <utils.preprocess.ResizeImage object at 0x7814c6904a00>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'test': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7814c5e54190>\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'val': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7814c5e548b0>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")}, 'name': 'office31_ssda'}, 'optimizer': {'lr': 1.0, 'lr_vit': 0.001, 'lr_cnn': 0.01, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}, 'Architecture': {'Backbone': {'name_1': 'vit', 'pretrained_1': '', 'name_2': 'alexnet', 'pretrained_2': ''}, 'Classifier': {'name_1': 'MLP', 'pretrained_F1': '', 'name_2': 'MLP', 'pretrained_F2': ''}, 'class_num': 31}, 'mixup_thresh': 0.7, 'alpha': 0.9, 'percentile': 60, 'lambda': 0.5, 'num_classes': 31, 'sat_alpha': 0.8, 'warmup_iters': 400, 'output_path_warmup': './pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup', 'out_file_warmup': <_io.TextIOWrapper name='./pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/log.txt' mode='w' encoding='UTF-8'>, 'out_file': <_io.TextIOWrapper name='./results/office31_ssda/webcam_to_amazon_SSDA_1_baseline/log.txt' mode='w' encoding='UTF-8'>}\n",
            "\u001b[31m==> Step 1: Pre-training on the labeled dataset ...\u001b[0m\n",
            "\u001b[31mMethod: SSDA - File: trainer_warmup.py\u001b[0m\n",
            "\u001b[31m==> Finished pre-training on source!\n",
            "\u001b[0m\n",
            "======== LOAD PRETRAIN ========\n",
            "Loading: ./pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/the_best_G1_pretrained.pth.tar\n",
            "Pretrain weights VisionTransformer loaded.\n",
            "Loading: ./pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/the_best_G2_pretrained.pth.tar\n",
            "Pretrain weights AlexNetBase loaded.\n",
            "Loading: ./pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/the_best_F1_pretrained.pth.tar\n",
            "Pretrain weights Predictor_deep loaded.\n",
            "Loading: ./pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/the_best_F2_pretrained.pth.tar\n",
            "Pretrain weights Predictor_deep loaded.\n",
            "===============================\n",
            "{'DEVICE': device(type='cuda', index=0), 'ndomains': 2, 'output_path': './results/office31_ssda/webcam_to_amazon_SSDA_1_baseline', 'output_name': 'baseline', 'source_iters': 0, 'adapt_iters': 1000, 'test_interval': 100, 'seed': 1, 'warmup': True, 'pretrained_models': './pretrained/', 'lamda': 0.1, 'save_models': True, 'thresh_ViT': 0.6, 'thresh_CNN': 0.9, 'dataset': {'method': 'SSDA', 'data_root': '../Dataset/office31', 'data_label': './dataset/office31_ssda', 'num_workers': 8, 'target_shot': 1, 'use_cgct_mask': True, 'source': {'name': 'webcam', 'batch_size': 26}, 'target': {'name': 'amazon', 'batch_size': 26}, 'prep': {'source_w': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7814d1deae20>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'source_str': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7814c5e50eb0>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    <utils.preprocess.RandAugmentMC object at 0x7814c5e50fd0>\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'target_w': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7814c6904940>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'target_str': Compose(\n",
            "    <utils.randaugment.RandAugment object at 0x7814c6904c40>\n",
            "    <utils.preprocess.ResizeImage object at 0x7814c6904a00>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'test': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7814c5e54190>\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'val': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7814c5e548b0>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")}, 'name': 'office31_ssda'}, 'optimizer': {'lr': 1.0, 'lr_vit': 0.001, 'lr_cnn': 0.01, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}, 'Architecture': {'Backbone': {'name_1': 'vit', 'pretrained_1': './pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/the_best_G1_pretrained.pth.tar', 'name_2': 'alexnet', 'pretrained_2': './pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/the_best_G2_pretrained.pth.tar'}, 'Classifier': {'name_1': 'MLP', 'pretrained_F1': './pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/the_best_F1_pretrained.pth.tar', 'name_2': 'MLP', 'pretrained_F2': './pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/the_best_F2_pretrained.pth.tar'}, 'class_num': 31}, 'mixup_thresh': 0.7, 'alpha': 0.9, 'percentile': 60, 'lambda': 0.5, 'num_classes': 31, 'sat_alpha': 0.8, 'warmup_iters': 400, 'output_path_warmup': './pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup', 'out_file_warmup': <_io.TextIOWrapper name='./pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/log.txt' mode='w' encoding='UTF-8'>, 'out_file': <_io.TextIOWrapper name='./results/office31_ssda/webcam_to_amazon_SSDA_1_baseline/log.txt' mode='w' encoding='UTF-8'>}\n",
            "\u001b[31m==> Starting the adaptation\u001b[0m\n",
            "\u001b[31mMethod: SSDA - File: trainer.py\u001b[0m\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.50\n",
            "Iters: (0/1000) \t lr_g1 = 0.000100   lr_g2 = 0.001000   CNN's loss = 0.001567   ViT's Loss = 0.001024   loss_vit_to_cnn = 3.149143   loss_cnn_to_vit = 0.744502   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.38\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.38\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.38\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.35\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.35\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.38\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.31\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.42\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.31\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.50, CNN: 0.46\n",
            "Iters: (20/1000) \t lr_g1 = 0.000100   lr_g2 = 0.000999   CNN's loss = 0.475023   ViT's Loss = 0.105666   loss_vit_to_cnn = 2.652003   loss_cnn_to_vit = 1.575793   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.46, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.46, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.42\n",
            "Iters: (40/1000) \t lr_g1 = 0.000100   lr_g2 = 0.000997   CNN's loss = 0.480167   ViT's Loss = 0.056557   loss_vit_to_cnn = 2.277833   loss_cnn_to_vit = 1.259937   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.42\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Iters: (60/1000) \t lr_g1 = 0.000100   lr_g2 = 0.000996   CNN's loss = 0.284025   ViT's Loss = 0.022975   loss_vit_to_cnn = 2.167526   loss_cnn_to_vit = 0.929167   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.50, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.73\n",
            "Iters: (80/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000994   CNN's loss = 0.365961   ViT's Loss = 0.041565   loss_vit_to_cnn = 1.431383   loss_cnn_to_vit = 0.199014   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.50, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "100%|█████████████████████████████████████████| 108/108 [00:17<00:00,  6.10it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.77it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 63.4409%  ViT's Accuracy Target Val =  73.1183% \n",
            "\t-- CNN's Accuracy Target Test = 60.4810%  ViT's Accuracy Target Test = 74.9462% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/office31_ssda/webcam_to_amazon_SSDA_1_baseline\n",
            "  -- Saved ViT Branch (G1 + F1) at ./results/office31_ssda/webcam_to_amazon_SSDA_1_baseline\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 63.4409% The best Vit's Acc Target Val = 73.1183% \n",
            "\t-- The best CNN's Acc Target Test = 60.4810% The best ViT's Acc Target Test = 74.9462% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8298 Correct_Pseudo_Labels_CNN = 1141 Total_Pseudo_Labels_CNN = 1375       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.8179 Correct_Pseudo_Labels_ViT = 1999 Total_Pseudo_Labels_ViT = 2444       \n",
            "\u001b[0m\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Iters: (100/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000993   CNN's loss = 0.220275   ViT's Loss = 0.007135   loss_vit_to_cnn = 2.857398   loss_cnn_to_vit = 1.149419   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.38\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Iters: (120/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000991   CNN's loss = 0.034433   ViT's Loss = 0.041589   loss_vit_to_cnn = 2.565381   loss_cnn_to_vit = 1.303373   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.42\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.46, CNN: 0.35\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.69\n",
            "Iters: (140/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000990   CNN's loss = 0.222597   ViT's Loss = 0.030935   loss_vit_to_cnn = 1.555671   loss_cnn_to_vit = 2.501392   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.58\n",
            "Iters: (160/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000988   CNN's loss = 0.143874   ViT's Loss = 0.018718   loss_vit_to_cnn = 1.907278   loss_cnn_to_vit = 0.763225   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.54\n",
            "Iters: (180/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000987   CNN's loss = 0.318956   ViT's Loss = 0.013940   loss_vit_to_cnn = 2.177406   loss_cnn_to_vit = 0.779499   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.58\n",
            "100%|█████████████████████████████████████████| 108/108 [00:17<00:00,  6.09it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.87it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 70.9677%  ViT's Accuracy Target Val =  72.0430% \n",
            "\t-- CNN's Accuracy Target Test = 63.7473%  ViT's Accuracy Target Test = 73.3668% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/office31_ssda/webcam_to_amazon_SSDA_1_baseline\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 70.9677% The best Vit's Acc Target Val = 73.1183% \n",
            "\t-- The best CNN's Acc Target Test = 63.7473% The best ViT's Acc Target Test = 74.9462% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8354 Correct_Pseudo_Labels_CNN = 1416 Total_Pseudo_Labels_CNN = 1695       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.8041 Correct_Pseudo_Labels_ViT = 1962 Total_Pseudo_Labels_ViT = 2440       \n",
            "\u001b[0m\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Iters: (200/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000985   CNN's loss = 0.042032   ViT's Loss = 0.011589   loss_vit_to_cnn = 1.492409   loss_cnn_to_vit = 0.628485   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Iters: (220/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000984   CNN's loss = 0.105486   ViT's Loss = 0.009895   loss_vit_to_cnn = 1.029528   loss_cnn_to_vit = 0.679820   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.50, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Iters: (240/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000982   CNN's loss = 0.070445   ViT's Loss = 0.050892   loss_vit_to_cnn = 1.200528   loss_cnn_to_vit = 0.184192   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.65\n",
            "Iters: (260/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000981   CNN's loss = 0.179027   ViT's Loss = 0.005687   loss_vit_to_cnn = 1.625832   loss_cnn_to_vit = 0.474578   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.50, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.42\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.92\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Iters: (280/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000980   CNN's loss = 0.108735   ViT's Loss = 0.004983   loss_vit_to_cnn = 1.471725   loss_cnn_to_vit = 0.281366   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.50, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "100%|█████████████████████████████████████████| 108/108 [00:17<00:00,  6.14it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.76it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 65.5914%  ViT's Accuracy Target Val =  69.8925% \n",
            "\t-- CNN's Accuracy Target Test = 63.2089%  ViT's Accuracy Target Test = 71.4645% \n",
            "\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 70.9677% The best Vit's Acc Target Val = 73.1183% \n",
            "\t-- The best CNN's Acc Target Test = 63.7473% The best ViT's Acc Target Test = 74.9462% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.7880 Correct_Pseudo_Labels_CNN = 1457 Total_Pseudo_Labels_CNN = 1849       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.7704 Correct_Pseudo_Labels_ViT = 1926 Total_Pseudo_Labels_ViT = 2500       \n",
            "\u001b[0m\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Iters: (300/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000978   CNN's loss = 0.017000   ViT's Loss = 0.012749   loss_vit_to_cnn = 1.906384   loss_cnn_to_vit = 0.268905   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.92\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Iters: (320/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000977   CNN's loss = 0.137642   ViT's Loss = 0.012447   loss_vit_to_cnn = 1.511658   loss_cnn_to_vit = 0.541880   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Iters: (340/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000975   CNN's loss = 0.047669   ViT's Loss = 0.015516   loss_vit_to_cnn = 1.246725   loss_cnn_to_vit = 0.533312   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.50, CNN: 0.73\n",
            "Iters: (360/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000974   CNN's loss = 0.065948   ViT's Loss = 0.003960   loss_vit_to_cnn = 0.842125   loss_cnn_to_vit = 1.355196   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.46, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.96, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Iters: (380/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000972   CNN's loss = 0.153874   ViT's Loss = 0.011747   loss_vit_to_cnn = 1.086802   loss_cnn_to_vit = 0.222865   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "100%|█████████████████████████████████████████| 108/108 [00:17<00:00,  6.09it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.71it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 68.8172%  ViT's Accuracy Target Val =  68.8172% \n",
            "\t-- CNN's Accuracy Target Test = 65.6497%  ViT's Accuracy Target Test = 71.6080% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/office31_ssda/webcam_to_amazon_SSDA_1_baseline\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 70.9677% The best Vit's Acc Target Val = 73.1183% \n",
            "\t-- The best CNN's Acc Target Test = 65.6497% The best ViT's Acc Target Test = 74.9462% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8344 Correct_Pseudo_Labels_CNN = 1522 Total_Pseudo_Labels_CNN = 1824       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.7693 Correct_Pseudo_Labels_ViT = 1934 Total_Pseudo_Labels_ViT = 2514       \n",
            "\u001b[0m\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Iters: (400/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000971   CNN's loss = 0.088558   ViT's Loss = 0.013008   loss_vit_to_cnn = 1.202637   loss_cnn_to_vit = 0.195370   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Iters: (420/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000970   CNN's loss = 0.182902   ViT's Loss = 0.005760   loss_vit_to_cnn = 1.712045   loss_cnn_to_vit = 0.749436   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.31\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.88\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.54\n",
            "Iters: (440/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000968   CNN's loss = 0.145057   ViT's Loss = 0.016828   loss_vit_to_cnn = 0.433447   loss_cnn_to_vit = 0.989295   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Iters: (460/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000967   CNN's loss = 0.083483   ViT's Loss = 0.010609   loss_vit_to_cnn = 0.469270   loss_cnn_to_vit = 0.019741   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.88\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Iters: (480/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000965   CNN's loss = 0.170118   ViT's Loss = 0.004810   loss_vit_to_cnn = 0.900777   loss_cnn_to_vit = 0.487702   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.92\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.88\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.96, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.58\n",
            "100%|█████████████████████████████████████████| 108/108 [00:17<00:00,  6.11it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.79it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 65.5914%  ViT's Accuracy Target Val =  69.8925% \n",
            "\t-- CNN's Accuracy Target Test = 65.3984%  ViT's Accuracy Target Test = 71.8234% \n",
            "\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 70.9677% The best Vit's Acc Target Val = 73.1183% \n",
            "\t-- The best CNN's Acc Target Test = 65.6497% The best ViT's Acc Target Test = 74.9462% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8086 Correct_Pseudo_Labels_CNN = 1483 Total_Pseudo_Labels_CNN = 1834       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.7620 Correct_Pseudo_Labels_ViT = 1943 Total_Pseudo_Labels_ViT = 2550       \n",
            "\u001b[0m\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.54\n",
            "Iters: (500/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000964   CNN's loss = 0.085336   ViT's Loss = 0.004211   loss_vit_to_cnn = 0.989699   loss_cnn_to_vit = 0.518457   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.96\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.50\n",
            "Iters: (520/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000963   CNN's loss = 0.009644   ViT's Loss = 0.004616   loss_vit_to_cnn = 1.555478   loss_cnn_to_vit = 0.685859   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Iters: (540/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000961   CNN's loss = 0.051700   ViT's Loss = 0.003563   loss_vit_to_cnn = 1.284337   loss_cnn_to_vit = 0.073808   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.88\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Iters: (560/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000960   CNN's loss = 0.154664   ViT's Loss = 0.003458   loss_vit_to_cnn = 1.085735   loss_cnn_to_vit = 0.490938   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Iters: (580/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000959   CNN's loss = 0.071467   ViT's Loss = 0.007609   loss_vit_to_cnn = 2.191111   loss_cnn_to_vit = 0.124514   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.85\n",
            "100%|█████████████████████████████████████████| 108/108 [00:17<00:00,  6.11it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.75it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 69.8925%  ViT's Accuracy Target Val =  72.0430% \n",
            "\t-- CNN's Accuracy Target Test = 68.5571%  ViT's Accuracy Target Test = 72.0388% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/office31_ssda/webcam_to_amazon_SSDA_1_baseline\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 70.9677% The best Vit's Acc Target Val = 73.1183% \n",
            "\t-- The best CNN's Acc Target Test = 68.5571% The best ViT's Acc Target Test = 74.9462% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8282 Correct_Pseudo_Labels_CNN = 1673 Total_Pseudo_Labels_CNN = 2020       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.7653 Correct_Pseudo_Labels_ViT = 1950 Total_Pseudo_Labels_ViT = 2548       \n",
            "\u001b[0m\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.92\n",
            "Iters: (600/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000957   CNN's loss = 0.013718   ViT's Loss = 0.004178   loss_vit_to_cnn = 0.363627   loss_cnn_to_vit = 0.178485   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.88\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Iters: (620/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000956   CNN's loss = 0.033540   ViT's Loss = 0.005227   loss_vit_to_cnn = 0.815080   loss_cnn_to_vit = 0.026474   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.81\n",
            "Iters: (640/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000955   CNN's loss = 0.144762   ViT's Loss = 0.002622   loss_vit_to_cnn = 1.291107   loss_cnn_to_vit = 0.560872   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Iters: (660/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000953   CNN's loss = 0.063051   ViT's Loss = 0.006636   loss_vit_to_cnn = 1.049562   loss_cnn_to_vit = 0.173797   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.69\n",
            "Iters: (680/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000952   CNN's loss = 0.047857   ViT's Loss = 0.006167   loss_vit_to_cnn = 1.311275   loss_cnn_to_vit = 0.011334   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.88\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "100%|█████████████████████████████████████████| 108/108 [00:17<00:00,  6.15it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.73it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 70.9677%  ViT's Accuracy Target Val =  74.1935% \n",
            "\t-- CNN's Accuracy Target Test = 68.3776%  ViT's Accuracy Target Test = 73.6899% \n",
            "\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 70.9677% The best Vit's Acc Target Val = 74.1935% \n",
            "\t-- The best CNN's Acc Target Test = 68.5571% The best ViT's Acc Target Test = 74.9462% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8285 Correct_Pseudo_Labels_CNN = 1531 Total_Pseudo_Labels_CNN = 1848       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.7901 Correct_Pseudo_Labels_ViT = 1999 Total_Pseudo_Labels_ViT = 2530       \n",
            "\u001b[0m\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Iters: (700/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000951   CNN's loss = 0.090226   ViT's Loss = 0.007895   loss_vit_to_cnn = 1.138951   loss_cnn_to_vit = 0.460570   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 1.00, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.92\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.58\n",
            "Iters: (720/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000949   CNN's loss = 0.075019   ViT's Loss = 0.003644   loss_vit_to_cnn = 1.996980   loss_cnn_to_vit = 0.075904   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.88\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.92\n",
            "Iters: (740/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000948   CNN's loss = 0.088792   ViT's Loss = 0.003044   loss_vit_to_cnn = 1.482414   loss_cnn_to_vit = 0.217779   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Iters: (760/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000947   CNN's loss = 0.027478   ViT's Loss = 0.015614   loss_vit_to_cnn = 1.228842   loss_cnn_to_vit = 0.020011   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.77\n",
            "Iters: (780/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000945   CNN's loss = 0.100636   ViT's Loss = 0.005465   loss_vit_to_cnn = 1.175801   loss_cnn_to_vit = 0.570342   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.92\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.58\n",
            "100%|█████████████████████████████████████████| 108/108 [00:17<00:00,  6.11it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.70it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 73.1183%  ViT's Accuracy Target Val =  68.8172% \n",
            "\t-- CNN's Accuracy Target Test = 67.5520%  ViT's Accuracy Target Test = 73.1156% \n",
            "\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 73.1183% The best Vit's Acc Target Val = 74.1935% \n",
            "\t-- The best CNN's Acc Target Test = 68.5571% The best ViT's Acc Target Test = 74.9462% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.7993 Correct_Pseudo_Labels_CNN = 1625 Total_Pseudo_Labels_CNN = 2033       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.7704 Correct_Pseudo_Labels_ViT = 1983 Total_Pseudo_Labels_ViT = 2574       \n",
            "\u001b[0m\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Iters: (800/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000944   CNN's loss = 0.097283   ViT's Loss = 0.021638   loss_vit_to_cnn = 1.391799   loss_cnn_to_vit = 0.471878   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.92\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.65\n",
            "Iters: (820/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000943   CNN's loss = 0.448303   ViT's Loss = 0.002012   loss_vit_to_cnn = 0.906114   loss_cnn_to_vit = 0.733893   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.92\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.96, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.81\n",
            "Iters: (840/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000941   CNN's loss = 0.029348   ViT's Loss = 0.002564   loss_vit_to_cnn = 0.666653   loss_cnn_to_vit = 0.171109   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.88\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.88\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.92\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Iters: (860/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000940   CNN's loss = 0.042011   ViT's Loss = 0.002788   loss_vit_to_cnn = 1.598103   loss_cnn_to_vit = 0.433922   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.88\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.42\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Iters: (880/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000939   CNN's loss = 0.043414   ViT's Loss = 0.003168   loss_vit_to_cnn = 1.458743   loss_cnn_to_vit = 0.102179   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 1.00\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "100%|█████████████████████████████████████████| 108/108 [00:17<00:00,  6.05it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.79it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 74.1935%  ViT's Accuracy Target Val =  76.3441% \n",
            "\t-- CNN's Accuracy Target Test = 71.4286%  ViT's Accuracy Target Test = 74.7667% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/office31_ssda/webcam_to_amazon_SSDA_1_baseline\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 74.1935% The best Vit's Acc Target Val = 76.3441% \n",
            "\t-- The best CNN's Acc Target Test = 71.4286% The best ViT's Acc Target Test = 74.9462% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8303 Correct_Pseudo_Labels_CNN = 1771 Total_Pseudo_Labels_CNN = 2133       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.7819 Correct_Pseudo_Labels_ViT = 2047 Total_Pseudo_Labels_ViT = 2618       \n",
            "\u001b[0m\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Iters: (900/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000937   CNN's loss = 0.009655   ViT's Loss = 0.003194   loss_vit_to_cnn = 0.944785   loss_cnn_to_vit = 0.257136   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.96, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.88\n",
            "Iters: (920/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000936   CNN's loss = 0.020763   ViT's Loss = 0.003895   loss_vit_to_cnn = 0.296152   loss_cnn_to_vit = 0.237213   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.88\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.88\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Iters: (940/1000) \t lr_g1 = 0.000093   lr_g2 = 0.000935   CNN's loss = 0.041574   ViT's Loss = 0.006730   loss_vit_to_cnn = 0.753032   loss_cnn_to_vit = 0.187579   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Iters: (960/1000) \t lr_g1 = 0.000093   lr_g2 = 0.000934   CNN's loss = 0.042389   ViT's Loss = 0.002155   loss_vit_to_cnn = 1.293766   loss_cnn_to_vit = 0.801223   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.88\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.96, CNN: 0.96\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.73\n",
            "Iters: (980/1000) \t lr_g1 = 0.000093   lr_g2 = 0.000932   CNN's loss = 0.027223   ViT's Loss = 0.019275   loss_vit_to_cnn = 1.141240   loss_cnn_to_vit = 0.194870   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.81\n",
            "Iters: (999/1000) \t lr_g1 = 0.000093   lr_g2 = 0.000931   CNN's loss = 0.101204   ViT's Loss = 0.001422   loss_vit_to_cnn = 1.353380   loss_cnn_to_vit = 1.024902   \n",
            "\n",
            "100%|█████████████████████████████████████████| 108/108 [00:17<00:00,  6.01it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.83it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 72.0430%  ViT's Accuracy Target Val =  74.1935% \n",
            "\t-- CNN's Accuracy Target Test = 70.1005%  ViT's Accuracy Target Test = 73.7617% \n",
            "\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 74.1935% The best Vit's Acc Target Val = 76.3441% \n",
            "\t-- The best CNN's Acc Target Test = 71.4286% The best ViT's Acc Target Test = 74.9462% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8045 Correct_Pseudo_Labels_CNN = 1745 Total_Pseudo_Labels_CNN = 2169       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.7749 Correct_Pseudo_Labels_ViT = 2028 Total_Pseudo_Labels_ViT = 2617       \n",
            "\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/kaggle/working/ECB/train.py\", line 116, in <module>\n",
            "    main(args)\n",
            "  File \"/kaggle/working/ECB/train.py\", line 107, in main\n",
            "    G1, G2, F1, F2 = trainer.train(config, G1, G2, F1, F2, dset_loaders)\n",
            "  File \"/kaggle/working/ECB/trainer.py\", line 691, in train\n",
            "    plt.figure(figsize=(14, 5))\n",
            "  File \"/opt/conda/envs/ecb/lib/python3.9/site-packages/matplotlib/_api/deprecation.py\", line 454, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/opt/conda/envs/ecb/lib/python3.9/site-packages/matplotlib/pyplot.py\", line 840, in figure\n",
            "    manager = new_figure_manager(\n",
            "  File \"/opt/conda/envs/ecb/lib/python3.9/site-packages/matplotlib/pyplot.py\", line 383, in new_figure_manager\n",
            "    _warn_if_gui_out_of_main_thread()\n",
            "  File \"/opt/conda/envs/ecb/lib/python3.9/site-packages/matplotlib/pyplot.py\", line 361, in _warn_if_gui_out_of_main_thread\n",
            "    if _get_required_interactive_framework(_get_backend_mod()):\n",
            "  File \"/opt/conda/envs/ecb/lib/python3.9/site-packages/matplotlib/pyplot.py\", line 208, in _get_backend_mod\n",
            "    switch_backend(rcParams._get(\"backend\"))\n",
            "  File \"/opt/conda/envs/ecb/lib/python3.9/site-packages/matplotlib/pyplot.py\", line 271, in switch_backend\n",
            "    backend_mod = importlib.import_module(\n",
            "  File \"/opt/conda/envs/ecb/lib/python3.9/importlib/__init__.py\", line 127, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"<frozen importlib._bootstrap>\", line 1030, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 972, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
            "  File \"<frozen importlib._bootstrap>\", line 1030, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 972, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
            "  File \"<frozen importlib._bootstrap>\", line 1030, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 984, in _find_and_load_unlocked\n",
            "ModuleNotFoundError: No module named 'ipykernel'\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "alpha - 0.85, clamp, threshcnn -0.8"
      ],
      "metadata": {
        "id": "uCCD0oWZRkxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!source activate ecb && echo \"Activated: $CONDA_DEFAULT_ENV\" && python train.py --cfg configs/train.yaml"
      ],
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-04-21T19:59:29.928209Z",
          "iopub.status.busy": "2025-04-21T19:59:29.927929Z",
          "iopub.status.idle": "2025-04-21T21:29:25.364231Z",
          "shell.execute_reply": "2025-04-21T21:29:25.363321Z",
          "shell.execute_reply.started": "2025-04-21T19:59:29.928186Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "kZ9FtFd0Rkxi",
        "outputId": "2e5de3eb-866d-463b-eece-1a3e3f467d82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Activated: ecb\n",
            "/opt/conda/envs/ecb/lib/python3.9/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "========== DATA PATH ==========\n",
            "source train: ./dataset/office31_ssda/labeled_source_images_webcam.txt\n",
            "source test: ./dataset/office31_ssda/validation_target_images_webcam_3.txt\n",
            "target train: ./dataset/office31_ssda/unlabeled_target_images_amazon_1.txt\n",
            "target test: ./dataset/office31_ssda/unlabeled_target_images_amazon_1.txt\n",
            "===============================\n",
            "/opt/conda/envs/ecb/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/opt/conda/envs/ecb/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "======== LOAD PRETRAIN ========\n",
            "Loading pretrain ImageNet: VisionTransformer\n",
            "Loading pretrain ImageNet: AlexNetBase\n",
            "Weight Init: Predictor_deep\n",
            "Weight Init: Predictor_deep\n",
            "===============================\n",
            "{'DEVICE': device(type='cuda', index=0), 'ndomains': 2, 'output_path': './results/office31_ssda/webcam_to_amazon_SSDA_1_baseline', 'output_name': 'baseline', 'source_iters': 0, 'adapt_iters': 1000, 'test_interval': 100, 'seed': 1, 'warmup': True, 'pretrained_models': './pretrained/', 'lamda': 0.1, 'save_models': True, 'thresh_ViT': 0.6, 'thresh_CNN': 0.8, 'dataset': {'method': 'SSDA', 'data_root': '../Dataset/office31', 'data_label': './dataset/office31_ssda', 'num_workers': 8, 'target_shot': 1, 'use_cgct_mask': True, 'source': {'name': 'webcam', 'batch_size': 26}, 'target': {'name': 'amazon', 'batch_size': 26}, 'prep': {'source_w': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7b32bc9ec910>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'source_str': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7b32ada312b0>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    <utils.preprocess.RandAugmentMC object at 0x7b32ada310a0>\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'target_w': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7b32ada31280>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'target_str': Compose(\n",
            "    <utils.randaugment.RandAugment object at 0x7b32ada31070>\n",
            "    <utils.preprocess.ResizeImage object at 0x7b32ada31640>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'test': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7b32ada31820>\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'val': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7b32ada317c0>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")}, 'name': 'office31_ssda'}, 'optimizer': {'lr': 1.0, 'lr_vit': 0.001, 'lr_cnn': 0.01, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}, 'Architecture': {'Backbone': {'name_1': 'vit', 'pretrained_1': '', 'name_2': 'alexnet', 'pretrained_2': ''}, 'Classifier': {'name_1': 'MLP', 'pretrained_F1': '', 'name_2': 'MLP', 'pretrained_F2': ''}, 'class_num': 31}, 'mixup_thresh': 0.7, 'alpha': 0.9, 'percentile': 60, 'lambda': 0.5, 'num_classes': 31, 'sat_alpha': 0.85, 'warmup_iters': 400, 'output_path_warmup': './pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup', 'out_file_warmup': <_io.TextIOWrapper name='./pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/log.txt' mode='w' encoding='UTF-8'>, 'out_file': <_io.TextIOWrapper name='./results/office31_ssda/webcam_to_amazon_SSDA_1_baseline/log.txt' mode='w' encoding='UTF-8'>}\n",
            "\u001b[31m==> Step 1: Pre-training on the labeled dataset ...\u001b[0m\n",
            "\u001b[31mMethod: SSDA - File: trainer_warmup.py\u001b[0m\n",
            "\u001b[31m==> Finished pre-training on source!\n",
            "\u001b[0m\n",
            "======== LOAD PRETRAIN ========\n",
            "Loading: ./pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/the_best_G1_pretrained.pth.tar\n",
            "Pretrain weights VisionTransformer loaded.\n",
            "Loading: ./pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/the_best_G2_pretrained.pth.tar\n",
            "Pretrain weights AlexNetBase loaded.\n",
            "Loading: ./pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/the_best_F1_pretrained.pth.tar\n",
            "Pretrain weights Predictor_deep loaded.\n",
            "Loading: ./pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/the_best_F2_pretrained.pth.tar\n",
            "Pretrain weights Predictor_deep loaded.\n",
            "===============================\n",
            "{'DEVICE': device(type='cuda', index=0), 'ndomains': 2, 'output_path': './results/office31_ssda/webcam_to_amazon_SSDA_1_baseline', 'output_name': 'baseline', 'source_iters': 0, 'adapt_iters': 1000, 'test_interval': 100, 'seed': 1, 'warmup': True, 'pretrained_models': './pretrained/', 'lamda': 0.1, 'save_models': True, 'thresh_ViT': 0.6, 'thresh_CNN': 0.8, 'dataset': {'method': 'SSDA', 'data_root': '../Dataset/office31', 'data_label': './dataset/office31_ssda', 'num_workers': 8, 'target_shot': 1, 'use_cgct_mask': True, 'source': {'name': 'webcam', 'batch_size': 26}, 'target': {'name': 'amazon', 'batch_size': 26}, 'prep': {'source_w': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7b32bc9ec910>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'source_str': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7b32ada312b0>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    <utils.preprocess.RandAugmentMC object at 0x7b32ada310a0>\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'target_w': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7b32ada31280>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'target_str': Compose(\n",
            "    <utils.randaugment.RandAugment object at 0x7b32ada31070>\n",
            "    <utils.preprocess.ResizeImage object at 0x7b32ada31640>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'test': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7b32ada31820>\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'val': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x7b32ada317c0>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")}, 'name': 'office31_ssda'}, 'optimizer': {'lr': 1.0, 'lr_vit': 0.001, 'lr_cnn': 0.01, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}, 'Architecture': {'Backbone': {'name_1': 'vit', 'pretrained_1': './pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/the_best_G1_pretrained.pth.tar', 'name_2': 'alexnet', 'pretrained_2': './pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/the_best_G2_pretrained.pth.tar'}, 'Classifier': {'name_1': 'MLP', 'pretrained_F1': './pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/the_best_F1_pretrained.pth.tar', 'name_2': 'MLP', 'pretrained_F2': './pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/the_best_F2_pretrained.pth.tar'}, 'class_num': 31}, 'mixup_thresh': 0.7, 'alpha': 0.9, 'percentile': 60, 'lambda': 0.5, 'num_classes': 31, 'sat_alpha': 0.85, 'warmup_iters': 400, 'output_path_warmup': './pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup', 'out_file_warmup': <_io.TextIOWrapper name='./pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/log.txt' mode='w' encoding='UTF-8'>, 'out_file': <_io.TextIOWrapper name='./results/office31_ssda/webcam_to_amazon_SSDA_1_baseline/log.txt' mode='w' encoding='UTF-8'>}\n",
            "\u001b[31m==> Starting the adaptation\u001b[0m\n",
            "\u001b[31mMethod: SSDA - File: trainer.py\u001b[0m\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.62\n",
            "Iters: (0/1000) \t lr_g1 = 0.000100   lr_g2 = 0.001000   CNN's loss = 0.001567   ViT's Loss = 0.001024   loss_vit_to_cnn = 3.584153   loss_cnn_to_vit = 1.696889   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.96, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.42\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.31\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.42\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.23\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.27\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.23\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.42\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.46, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.50, CNN: 0.42\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.42\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.50, CNN: 0.35\n",
            "Iters: (20/1000) \t lr_g1 = 0.000100   lr_g2 = 0.000999   CNN's loss = 0.180115   ViT's Loss = 0.016381   loss_vit_to_cnn = 2.540582   loss_cnn_to_vit = 1.736734   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.46, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.42\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.46, CNN: 0.23\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.46, CNN: 0.42\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.81\n",
            "Iters: (40/1000) \t lr_g1 = 0.000100   lr_g2 = 0.000997   CNN's loss = 0.173600   ViT's Loss = 0.070026   loss_vit_to_cnn = 2.450826   loss_cnn_to_vit = 1.749369   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.42\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.50, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.50, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.54\n",
            "Iters: (60/1000) \t lr_g1 = 0.000100   lr_g2 = 0.000996   CNN's loss = 0.178946   ViT's Loss = 0.020539   loss_vit_to_cnn = 2.286083   loss_cnn_to_vit = 1.333178   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.46, CNN: 0.38\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Iters: (80/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000994   CNN's loss = 0.082328   ViT's Loss = 0.058606   loss_vit_to_cnn = 0.956059   loss_cnn_to_vit = 0.746235   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.50, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.38, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.54\n",
            "100%|█████████████████████████████████████████| 108/108 [00:18<00:00,  5.78it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.69it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 63.4409%  ViT's Accuracy Target Val =  73.1183% \n",
            "\t-- CNN's Accuracy Target Test = 60.9117%  ViT's Accuracy Target Test = 69.7775% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/office31_ssda/webcam_to_amazon_SSDA_1_baseline\n",
            "  -- Saved ViT Branch (G1 + F1) at ./results/office31_ssda/webcam_to_amazon_SSDA_1_baseline\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 63.4409% The best Vit's Acc Target Val = 73.1183% \n",
            "\t-- The best CNN's Acc Target Test = 60.9117% The best ViT's Acc Target Test = 69.7775% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8066 Correct_Pseudo_Labels_CNN = 1318 Total_Pseudo_Labels_CNN = 1634       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.7984 Correct_Pseudo_Labels_ViT = 1814 Total_Pseudo_Labels_ViT = 2272       \n",
            "\u001b[0m\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.54\n",
            "Iters: (100/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000993   CNN's loss = 0.170730   ViT's Loss = 0.019995   loss_vit_to_cnn = 2.625528   loss_cnn_to_vit = 1.447506   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.38\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.69\n",
            "Iters: (120/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000991   CNN's loss = 0.063377   ViT's Loss = 0.019099   loss_vit_to_cnn = 2.423162   loss_cnn_to_vit = 1.562671   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.46, CNN: 0.35\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Iters: (140/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000990   CNN's loss = 0.179479   ViT's Loss = 0.018957   loss_vit_to_cnn = 1.268051   loss_cnn_to_vit = 0.632947   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.50, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.42, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.50, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.54\n",
            "Iters: (160/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000988   CNN's loss = 0.056954   ViT's Loss = 0.018074   loss_vit_to_cnn = 2.835005   loss_cnn_to_vit = 0.867478   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.46, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.50, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.42\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.46, CNN: 0.42\n",
            "Iters: (180/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000987   CNN's loss = 0.157019   ViT's Loss = 0.017463   loss_vit_to_cnn = 1.364836   loss_cnn_to_vit = 1.520034   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.73\n",
            "100%|█████████████████████████████████████████| 108/108 [00:17<00:00,  6.14it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.72it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 69.8925%  ViT's Accuracy Target Val =  68.8172% \n",
            "\t-- CNN's Accuracy Target Test = 65.3266%  ViT's Accuracy Target Test = 69.5621% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/office31_ssda/webcam_to_amazon_SSDA_1_baseline\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 69.8925% The best Vit's Acc Target Val = 73.1183% \n",
            "\t-- The best CNN's Acc Target Test = 65.3266% The best ViT's Acc Target Test = 69.7775% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8178 Correct_Pseudo_Labels_CNN = 1616 Total_Pseudo_Labels_CNN = 1976       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.7911 Correct_Pseudo_Labels_ViT = 1833 Total_Pseudo_Labels_ViT = 2317       \n",
            "\u001b[0m\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Iters: (200/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000985   CNN's loss = 0.037932   ViT's Loss = 0.009162   loss_vit_to_cnn = 1.211853   loss_cnn_to_vit = 0.527569   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Iters: (220/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000984   CNN's loss = 0.045169   ViT's Loss = 0.009016   loss_vit_to_cnn = 0.811317   loss_cnn_to_vit = 0.547848   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.42, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.50, CNN: 0.58\n",
            "Iters: (240/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000982   CNN's loss = 0.067741   ViT's Loss = 0.013943   loss_vit_to_cnn = 1.945631   loss_cnn_to_vit = 0.668728   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Iters: (260/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000981   CNN's loss = 0.296189   ViT's Loss = 0.007379   loss_vit_to_cnn = 1.089556   loss_cnn_to_vit = 0.830003   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.42, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.38\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.73\n",
            "Iters: (280/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000980   CNN's loss = 0.032993   ViT's Loss = 0.009455   loss_vit_to_cnn = 1.097087   loss_cnn_to_vit = 0.563113   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "100%|█████████████████████████████████████████| 108/108 [00:17<00:00,  6.10it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.80it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 66.6667%  ViT's Accuracy Target Val =  75.2688% \n",
            "\t-- CNN's Accuracy Target Test = 65.8291%  ViT's Accuracy Target Test = 73.1874% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/office31_ssda/webcam_to_amazon_SSDA_1_baseline\n",
            "  -- Saved ViT Branch (G1 + F1) at ./results/office31_ssda/webcam_to_amazon_SSDA_1_baseline\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 69.8925% The best Vit's Acc Target Val = 75.2688% \n",
            "\t-- The best CNN's Acc Target Test = 65.8291% The best ViT's Acc Target Test = 73.1874% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.7934 Correct_Pseudo_Labels_CNN = 1624 Total_Pseudo_Labels_CNN = 2047       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.7952 Correct_Pseudo_Labels_ViT = 1930 Total_Pseudo_Labels_ViT = 2427       \n",
            "\u001b[0m\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Iters: (300/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000978   CNN's loss = 0.063271   ViT's Loss = 0.005416   loss_vit_to_cnn = 1.767118   loss_cnn_to_vit = 0.639442   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.62\n",
            "Iters: (320/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000977   CNN's loss = 0.040305   ViT's Loss = 0.010408   loss_vit_to_cnn = 1.733983   loss_cnn_to_vit = 0.479699   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Iters: (340/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000975   CNN's loss = 0.020221   ViT's Loss = 0.006463   loss_vit_to_cnn = 1.319015   loss_cnn_to_vit = 0.482057   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Iters: (360/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000974   CNN's loss = 0.017952   ViT's Loss = 0.005073   loss_vit_to_cnn = 1.255044   loss_cnn_to_vit = 0.716539   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.77\n",
            "Iters: (380/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000972   CNN's loss = 0.056947   ViT's Loss = 0.008287   loss_vit_to_cnn = 0.787455   loss_cnn_to_vit = 0.501131   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.69\n",
            "100%|█████████████████████████████████████████| 108/108 [00:18<00:00,  5.98it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.69it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 68.8172%  ViT's Accuracy Target Val =  73.1183% \n",
            "\t-- CNN's Accuracy Target Test = 65.1831%  ViT's Accuracy Target Test = 69.4544% \n",
            "\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 69.8925% The best Vit's Acc Target Val = 75.2688% \n",
            "\t-- The best CNN's Acc Target Test = 65.8291% The best ViT's Acc Target Test = 73.1874% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.7648 Correct_Pseudo_Labels_CNN = 1623 Total_Pseudo_Labels_CNN = 2122       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.7537 Correct_Pseudo_Labels_ViT = 1861 Total_Pseudo_Labels_ViT = 2469       \n",
            "\u001b[0m\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Iters: (400/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000971   CNN's loss = 0.057647   ViT's Loss = 0.005874   loss_vit_to_cnn = 1.738095   loss_cnn_to_vit = 0.219831   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.46, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.88\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.50\n",
            "Iters: (420/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000970   CNN's loss = 0.013721   ViT's Loss = 0.007913   loss_vit_to_cnn = 1.383966   loss_cnn_to_vit = 0.852937   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.46, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Iters: (440/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000968   CNN's loss = 0.076885   ViT's Loss = 0.007251   loss_vit_to_cnn = 1.105717   loss_cnn_to_vit = 1.104086   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.96, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.92\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Iters: (460/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000967   CNN's loss = 0.086188   ViT's Loss = 0.007361   loss_vit_to_cnn = 1.458327   loss_cnn_to_vit = 0.653141   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.88\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Iters: (480/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000965   CNN's loss = 0.037833   ViT's Loss = 0.004729   loss_vit_to_cnn = 1.144942   loss_cnn_to_vit = 0.751125   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.31\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.50\n",
            "100%|█████████████████████████████████████████| 108/108 [00:17<00:00,  6.09it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.72it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 66.6667%  ViT's Accuracy Target Val =  70.9677% \n",
            "\t-- CNN's Accuracy Target Test = 68.0905%  ViT's Accuracy Target Test = 70.7466% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/office31_ssda/webcam_to_amazon_SSDA_1_baseline\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 69.8925% The best Vit's Acc Target Val = 75.2688% \n",
            "\t-- The best CNN's Acc Target Test = 68.0905% The best ViT's Acc Target Test = 73.1874% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8052 Correct_Pseudo_Labels_CNN = 1699 Total_Pseudo_Labels_CNN = 2110       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.7677 Correct_Pseudo_Labels_ViT = 1890 Total_Pseudo_Labels_ViT = 2462       \n",
            "\u001b[0m\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Iters: (500/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000964   CNN's loss = 0.041113   ViT's Loss = 0.005968   loss_vit_to_cnn = 1.086234   loss_cnn_to_vit = 0.448575   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.92\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.50, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Iters: (520/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000963   CNN's loss = 0.017463   ViT's Loss = 0.004898   loss_vit_to_cnn = 1.290413   loss_cnn_to_vit = 0.483057   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.38\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.50, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.88\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.69\n",
            "Iters: (540/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000961   CNN's loss = 0.154799   ViT's Loss = 0.007723   loss_vit_to_cnn = 1.081506   loss_cnn_to_vit = 0.289524   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.42\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.85\n",
            "Iters: (560/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000960   CNN's loss = 0.054078   ViT's Loss = 0.006741   loss_vit_to_cnn = 1.027772   loss_cnn_to_vit = 0.411803   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Iters: (580/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000959   CNN's loss = 0.018994   ViT's Loss = 0.007223   loss_vit_to_cnn = 1.628905   loss_cnn_to_vit = 0.687360   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.46\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.81\n",
            "100%|█████████████████████████████████████████| 108/108 [00:17<00:00,  6.12it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.28it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 69.8925%  ViT's Accuracy Target Val =  68.8172% \n",
            "\t-- CNN's Accuracy Target Test = 67.1931%  ViT's Accuracy Target Test = 69.3467% \n",
            "\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 69.8925% The best Vit's Acc Target Val = 75.2688% \n",
            "\t-- The best CNN's Acc Target Test = 68.0905% The best ViT's Acc Target Test = 73.1874% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.7936 Correct_Pseudo_Labels_CNN = 1723 Total_Pseudo_Labels_CNN = 2171       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.7445 Correct_Pseudo_Labels_ViT = 1862 Total_Pseudo_Labels_ViT = 2501       \n",
            "\u001b[0m\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.77\n",
            "Iters: (600/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000957   CNN's loss = 0.014886   ViT's Loss = 0.005756   loss_vit_to_cnn = 0.730161   loss_cnn_to_vit = 0.256839   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Iters: (620/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000956   CNN's loss = 0.074576   ViT's Loss = 0.003671   loss_vit_to_cnn = 0.798308   loss_cnn_to_vit = 0.706145   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.96, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Iters: (640/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000955   CNN's loss = 0.007075   ViT's Loss = 0.006402   loss_vit_to_cnn = 0.742308   loss_cnn_to_vit = 0.358303   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.42\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.96\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Iters: (660/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000953   CNN's loss = 0.013820   ViT's Loss = 0.003808   loss_vit_to_cnn = 1.058208   loss_cnn_to_vit = 0.364349   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.88\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Iters: (680/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000952   CNN's loss = 0.034035   ViT's Loss = 0.010604   loss_vit_to_cnn = 1.089524   loss_cnn_to_vit = 0.288845   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "100%|█████████████████████████████████████████| 108/108 [00:17<00:00,  6.14it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.82it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 67.7419%  ViT's Accuracy Target Val =  67.7419% \n",
            "\t-- CNN's Accuracy Target Test = 68.6289%  ViT's Accuracy Target Test = 69.7057% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/office31_ssda/webcam_to_amazon_SSDA_1_baseline\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 69.8925% The best Vit's Acc Target Val = 75.2688% \n",
            "\t-- The best CNN's Acc Target Test = 68.6289% The best ViT's Acc Target Test = 73.1874% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.7788 Correct_Pseudo_Labels_CNN = 1736 Total_Pseudo_Labels_CNN = 2229       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.7505 Correct_Pseudo_Labels_ViT = 1886 Total_Pseudo_Labels_ViT = 2513       \n",
            "\u001b[0m\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.50\n",
            "Iters: (700/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000951   CNN's loss = 0.128715   ViT's Loss = 0.004961   loss_vit_to_cnn = 1.123627   loss_cnn_to_vit = 0.693921   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Iters: (720/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000949   CNN's loss = 0.018673   ViT's Loss = 0.006011   loss_vit_to_cnn = 1.185683   loss_cnn_to_vit = 0.708791   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.81\n",
            "Iters: (740/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000948   CNN's loss = 0.013066   ViT's Loss = 0.006652   loss_vit_to_cnn = 0.924979   loss_cnn_to_vit = 0.244150   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.88\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.88\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.88\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.58\n",
            "Iters: (760/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000947   CNN's loss = 0.096453   ViT's Loss = 0.008633   loss_vit_to_cnn = 1.602752   loss_cnn_to_vit = 0.348924   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.50, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Iters: (780/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000945   CNN's loss = 0.011138   ViT's Loss = 0.003792   loss_vit_to_cnn = 0.907476   loss_cnn_to_vit = 0.424094   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.50\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.54, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.88\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "100%|█████████████████████████████████████████| 108/108 [00:17<00:00,  6.14it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.68it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 73.1183%  ViT's Accuracy Target Val =  69.8925% \n",
            "\t-- CNN's Accuracy Target Test = 68.5571%  ViT's Accuracy Target Test = 69.8492% \n",
            "\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 73.1183% The best Vit's Acc Target Val = 75.2688% \n",
            "\t-- The best CNN's Acc Target Test = 68.6289% The best ViT's Acc Target Test = 73.1874% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.7795 Correct_Pseudo_Labels_CNN = 1761 Total_Pseudo_Labels_CNN = 2259       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.7411 Correct_Pseudo_Labels_ViT = 1886 Total_Pseudo_Labels_ViT = 2545       \n",
            "\u001b[0m\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Iters: (800/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000944   CNN's loss = 0.041832   ViT's Loss = 0.008265   loss_vit_to_cnn = 1.353375   loss_cnn_to_vit = 0.477793   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.88\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.88\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.46, CNN: 0.54\n",
            "Iters: (820/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000943   CNN's loss = 0.012861   ViT's Loss = 0.003111   loss_vit_to_cnn = 1.304117   loss_cnn_to_vit = 1.078050   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.88\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.77\n",
            "Iters: (840/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000941   CNN's loss = 0.008133   ViT's Loss = 0.010134   loss_vit_to_cnn = 0.587611   loss_cnn_to_vit = 0.196825   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Iters: (860/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000940   CNN's loss = 0.009796   ViT's Loss = 0.003038   loss_vit_to_cnn = 1.307421   loss_cnn_to_vit = 0.248852   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.54\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Iters: (880/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000939   CNN's loss = 0.015544   ViT's Loss = 0.003816   loss_vit_to_cnn = 1.085192   loss_cnn_to_vit = 0.427759   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.92\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.88\n",
            "100%|█████████████████████████████████████████| 108/108 [00:17<00:00,  6.13it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.67it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 70.9677%  ViT's Accuracy Target Val =  77.4194% \n",
            "\t-- CNN's Accuracy Target Test = 67.9110%  ViT's Accuracy Target Test = 72.9002% \n",
            "\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 73.1183% The best Vit's Acc Target Val = 77.4194% \n",
            "\t-- The best CNN's Acc Target Test = 68.6289% The best ViT's Acc Target Test = 73.1874% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.7729 Correct_Pseudo_Labels_CNN = 1763 Total_Pseudo_Labels_CNN = 2281       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.7786 Correct_Pseudo_Labels_ViT = 1980 Total_Pseudo_Labels_ViT = 2543       \n",
            "\u001b[0m\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.92\n",
            "Iters: (900/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000937   CNN's loss = 0.004446   ViT's Loss = 0.008503   loss_vit_to_cnn = 0.566169   loss_cnn_to_vit = 0.222332   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.50, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Iters: (920/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000936   CNN's loss = 0.070641   ViT's Loss = 0.002898   loss_vit_to_cnn = 0.429972   loss_cnn_to_vit = 0.616326   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.96, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.96\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.88, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.85\n",
            "Iters: (940/1000) \t lr_g1 = 0.000093   lr_g2 = 0.000935   CNN's loss = 0.015610   ViT's Loss = 0.005771   loss_vit_to_cnn = 0.978321   loss_cnn_to_vit = 0.170317   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.92\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.46, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.77\n",
            "Iters: (960/1000) \t lr_g1 = 0.000093   lr_g2 = 0.000934   CNN's loss = 0.037576   ViT's Loss = 0.007972   loss_vit_to_cnn = 0.916501   loss_cnn_to_vit = 0.183991   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.85\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.65, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.62, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.96\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.88\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.58\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.77\n",
            "Iters: (980/1000) \t lr_g1 = 0.000093   lr_g2 = 0.000932   CNN's loss = 0.006081   ViT's Loss = 0.004284   loss_vit_to_cnn = 0.893449   loss_cnn_to_vit = 0.602638   \n",
            "\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.58, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.88\n",
            "Pseudo-label ratio — ViT: 0.92, CNN: 0.96\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.65\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.81\n",
            "Pseudo-label ratio — ViT: 0.77, CNN: 0.62\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.69\n",
            "Pseudo-label ratio — ViT: 0.73, CNN: 0.77\n",
            "Pseudo-label ratio — ViT: 0.81, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.69, CNN: 0.73\n",
            "Pseudo-label ratio — ViT: 0.85, CNN: 0.73\n",
            "Iters: (999/1000) \t lr_g1 = 0.000093   lr_g2 = 0.000931   CNN's loss = 0.125027   ViT's Loss = 0.003143   loss_vit_to_cnn = 0.932374   loss_cnn_to_vit = 0.530643   \n",
            "\n",
            "100%|█████████████████████████████████████████| 108/108 [00:17<00:00,  6.05it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.74it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 68.8172%  ViT's Accuracy Target Val =  70.9677% \n",
            "\t-- CNN's Accuracy Target Test = 67.9469%  ViT's Accuracy Target Test = 69.2391% \n",
            "\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 73.1183% The best Vit's Acc Target Val = 77.4194% \n",
            "\t-- The best CNN's Acc Target Test = 68.6289% The best ViT's Acc Target Test = 73.1874% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.7669 Correct_Pseudo_Labels_CNN = 1767 Total_Pseudo_Labels_CNN = 2304       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.7345 Correct_Pseudo_Labels_ViT = 1884 Total_Pseudo_Labels_ViT = 2565       \n",
            "\u001b[0m\n",
            "\u001b[31mFinished training and evaluation!\u001b[0m\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Novelty try"
      ],
      "metadata": {
        "id": "QfhXV1yDSPhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Define source and destination directories\n",
        "source_dir = '/kaggle/input/webcam-to-amazon/webcam_to_amazon_SSDA_1_pretrained_warmup'\n",
        "destination_dir = '/kaggle/working/ECB/pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/'\n",
        "\n",
        "# Check if the source directory exists\n",
        "if os.path.exists(source_dir):\n",
        "    # Check if the destination directory exists, if not create it\n",
        "    if not os.path.exists(destination_dir):\n",
        "        os.makedirs(destination_dir)\n",
        "\n",
        "    # Loop through all files in the source directory\n",
        "    for filename in os.listdir(source_dir):\n",
        "        source_file = os.path.join(source_dir, filename)\n",
        "\n",
        "        # Check if it's a file and then copy it to the destination directory\n",
        "        if os.path.isfile(source_file):\n",
        "            shutil.copy(source_file, destination_dir)\n",
        "            print(f\"Copied: {filename}\")\n",
        "else:\n",
        "    print(f\"Source directory '{source_dir}' does not exist.\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-21T18:06:36.222983Z",
          "iopub.status.busy": "2025-04-21T18:06:36.222760Z",
          "iopub.status.idle": "2025-04-21T18:06:42.701994Z",
          "shell.execute_reply": "2025-04-21T18:06:42.701044Z",
          "shell.execute_reply.started": "2025-04-21T18:06:36.222964Z"
        },
        "trusted": true,
        "id": "qAgpPRqLRkxi",
        "outputId": "76ab3f72-edd8-4fae-b2aa-66f97d9afc9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copied: the_best_F1_pretrained.pth.tar\n",
            "Copied: trainer_warmup.py\n",
            "Copied: the_best_G2_pretrained.pth.tar\n",
            "Copied: the_best_F2_pretrained.pth.tar\n",
            "Copied: log.txt\n",
            "Copied: the_best_G1_pretrained.pth.tar\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file paths\n",
        "source_file = \"/kaggle/input/trainyamlfle4/trainer.py\"\n",
        "destination_file = \"/kaggle/working/ECB/trainer.py\"\n",
        "\n",
        "# # Create a sample source file\n",
        "# with open(source_file, \"r\") as f:\n",
        "#     f.write(\"This is the original content.\")\n",
        "\n",
        "# Copy contents\n",
        "with open(source_file, \"r\") as src, open(destination_file, \"w\") as dest:\n",
        "    dest.write(src.read())\n",
        "\n",
        "print(f\"Copied contents from {source_file} to {destination_file}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-21T19:59:14.559161Z",
          "iopub.status.busy": "2025-04-21T19:59:14.558869Z",
          "iopub.status.idle": "2025-04-21T19:59:14.570631Z",
          "shell.execute_reply": "2025-04-21T19:59:14.569782Z",
          "shell.execute_reply.started": "2025-04-21T19:59:14.559137Z"
        },
        "trusted": true,
        "id": "xv9BxP5mRkxj",
        "outputId": "1207af62-64bd-4788-8eeb-89ee960a7914"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copied contents from /kaggle/input/trainyamlfle4/trainer.py to /kaggle/working/ECB/trainer.py\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file paths\n",
        "source_file = \"/kaggle/input/trainyamlfile/loss.py\"\n",
        "destination_file = \"/kaggle/working/ECB/utils/loss.py\"\n",
        "\n",
        "# # Create a sample source file\n",
        "# with open(source_file, \"r\") as f:\n",
        "#     f.write(\"This is the original content.\")\n",
        "\n",
        "# Copy contents\n",
        "with open(source_file, \"r\") as src, open(destination_file, \"w\") as dest:\n",
        "    dest.write(src.read())\n",
        "\n",
        "print(f\"Copied contents from {source_file} to {destination_file}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-21T19:59:03.852550Z",
          "iopub.status.busy": "2025-04-21T19:59:03.852278Z",
          "iopub.status.idle": "2025-04-21T19:59:03.860850Z",
          "shell.execute_reply": "2025-04-21T19:59:03.860225Z",
          "shell.execute_reply.started": "2025-04-21T19:59:03.852523Z"
        },
        "trusted": true,
        "id": "369mJdCeRkxj",
        "outputId": "9fbb1d73-3a08-4b9f-fb0e-67a876c4f882"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copied contents from /kaggle/input/trainyamlfile/loss.py to /kaggle/working/ECB/utils/loss.py\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file paths\n",
        "source_file = \"/kaggle/input/trainyaml2/train.yaml\"\n",
        "destination_file = \"/kaggle/working/ECB/configs/train.yaml\"\n",
        "\n",
        "# # Create a sample source file\n",
        "# with open(source_file, \"r\") as f:\n",
        "#     f.write(\"This is the original content.\")\n",
        "\n",
        "# Copy contents\n",
        "with open(source_file, \"r\") as src, open(destination_file, \"w\") as dest:\n",
        "    dest.write(src.read())\n",
        "\n",
        "print(f\"Copied contents from {source_file} to {destination_file}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-21T19:59:07.062430Z",
          "iopub.status.busy": "2025-04-21T19:59:07.062111Z",
          "iopub.status.idle": "2025-04-21T19:59:07.067839Z",
          "shell.execute_reply": "2025-04-21T19:59:07.067003Z",
          "shell.execute_reply.started": "2025-04-21T19:59:07.062403Z"
        },
        "trusted": true,
        "id": "Ms3X2ddQRkxj",
        "outputId": "6d87eb56-38a8-410c-9f0c-84a2214e0495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copied contents from /kaggle/input/trainyaml2/train.yaml to /kaggle/working/ECB/configs/train.yaml\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file paths\n",
        "source_file = \"/kaggle/input/trainyamlfile3/basenet.py\"\n",
        "destination_file = \"/kaggle/working/ECB/model/basenet.py\"\n",
        "\n",
        "# # Create a sample source file\n",
        "# with open(source_file, \"r\") as f:\n",
        "#     f.write(\"This is the original content.\")\n",
        "\n",
        "# Copy contents\n",
        "with open(source_file, \"r\") as src, open(destination_file, \"w\") as dest:\n",
        "    dest.write(src.read())\n",
        "\n",
        "print(f\"Copied contents from {source_file} to {destination_file}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-21T19:59:09.582906Z",
          "iopub.status.busy": "2025-04-21T19:59:09.582600Z",
          "iopub.status.idle": "2025-04-21T19:59:09.592130Z",
          "shell.execute_reply": "2025-04-21T19:59:09.591424Z",
          "shell.execute_reply.started": "2025-04-21T19:59:09.582882Z"
        },
        "trusted": true,
        "id": "aeECtGxlRkxj",
        "outputId": "88c64285-42bd-48e4-9e51-abce22a78c8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copied contents from /kaggle/input/trainyamlfile3/basenet.py to /kaggle/working/ECB/model/basenet.py\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!source activate ecb && echo \"Activated: $CONDA_DEFAULT_ENV\" && python train.py --cfg configs/train.yaml"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-19T22:51:35.555552Z",
          "iopub.status.busy": "2025-04-19T22:51:35.555179Z",
          "iopub.status.idle": "2025-04-20T00:15:10.019969Z",
          "shell.execute_reply": "2025-04-20T00:15:10.019078Z",
          "shell.execute_reply.started": "2025-04-19T22:51:35.555492Z"
        },
        "trusted": true,
        "id": "yr4TBZmtRkxj",
        "outputId": "6c929273-bda9-49ab-ba6c-2eeb17ec1a32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Activated: ecb\n",
            "/opt/conda/envs/ecb/lib/python3.9/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "========== DATA PATH ==========\n",
            "source train: ./dataset/office31_ssda/labeled_source_images_webcam.txt\n",
            "source test: ./dataset/office31_ssda/validation_target_images_webcam_3.txt\n",
            "target train: ./dataset/office31_ssda/unlabeled_target_images_amazon_1.txt\n",
            "target test: ./dataset/office31_ssda/unlabeled_target_images_amazon_1.txt\n",
            "===============================\n",
            "Downloading model.safetensors: 100%|██████████| 346M/346M [00:01<00:00, 338MB/s]\n",
            "/opt/conda/envs/ecb/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/opt/conda/envs/ecb/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|█████████████████████████████████████████| 233M/233M [00:00<00:00, 272MB/s]\n",
            "======== LOAD PRETRAIN ========\n",
            "Loading pretrain ImageNet: VisionTransformer\n",
            "Loading pretrain ImageNet: AlexNetBase\n",
            "Weight Init: Predictor_deep\n",
            "Weight Init: Predictor_deep\n",
            "===============================\n",
            "{'DEVICE': device(type='cuda', index=0), 'ndomains': 2, 'output_path': './results/office31_ssda/webcam_to_amazon_SSDA_1_baseline', 'output_name': 'baseline', 'source_iters': 0, 'adapt_iters': 1000, 'test_interval': 100, 'seed': 1, 'warmup': True, 'pretrained_models': './pretrained/', 'lamda': 0.1, 'save_models': True, 'thresh_ViT': 0.6, 'thresh_CNN': 0.9, 'dataset': {'method': 'SSDA', 'data_root': '../Dataset/office31', 'data_label': './dataset/office31_ssda', 'num_workers': 8, 'target_shot': 1, 'use_cgct_mask': True, 'source': {'name': 'webcam', 'batch_size': 26}, 'target': {'name': 'amazon', 'batch_size': 26}, 'prep': {'source_w': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x79b182394b80>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'source_str': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x79b176a928b0>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    <utils.preprocess.RandAugmentMC object at 0x79b176a92640>\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'target_w': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x79b176a928e0>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'target_str': Compose(\n",
            "    <utils.randaugment.RandAugment object at 0x79b176a92970>\n",
            "    <utils.preprocess.ResizeImage object at 0x79b176a92c40>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'test': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x79b176a92c70>\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'val': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x79b176a92f40>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")}, 'name': 'office31_ssda'}, 'optimizer': {'lr': 1.0, 'lr_vit': 0.001, 'lr_cnn': 0.01, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}, 'Architecture': {'Backbone': {'name_1': 'vit', 'pretrained_1': '', 'name_2': 'alexnet', 'pretrained_2': ''}, 'Classifier': {'name_1': 'MLP', 'pretrained_F1': '', 'name_2': 'MLP', 'pretrained_F2': ''}, 'class_num': 31}, 'mixup_thresh': 0.7, 'alpha': 0.9, 'percentile': 60, 'lambda': 0.5, 'num_classes': 31, 'sat_alpha': 0.9, 'warmup_iters': 400, 'output_path_warmup': './pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup', 'out_file_warmup': <_io.TextIOWrapper name='./pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/log.txt' mode='w' encoding='UTF-8'>, 'out_file': <_io.TextIOWrapper name='./results/office31_ssda/webcam_to_amazon_SSDA_1_baseline/log.txt' mode='w' encoding='UTF-8'>}\n",
            "\u001b[31m==> Step 1: Pre-training on the labeled dataset ...\u001b[0m\n",
            "\u001b[31mMethod: SSDA - File: trainer_warmup.py\u001b[0m\n",
            "\u001b[31m==> Finished pre-training on source!\n",
            "\u001b[0m\n",
            "======== LOAD PRETRAIN ========\n",
            "Loading: ./pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/the_best_G1_pretrained.pth.tar\n",
            "Pretrain weights VisionTransformer loaded.\n",
            "Loading: ./pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/the_best_G2_pretrained.pth.tar\n",
            "Pretrain weights AlexNetBase loaded.\n",
            "Loading: ./pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/the_best_F1_pretrained.pth.tar\n",
            "Pretrain weights Predictor_deep loaded.\n",
            "Loading: ./pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/the_best_F2_pretrained.pth.tar\n",
            "Pretrain weights Predictor_deep loaded.\n",
            "===============================\n",
            "{'DEVICE': device(type='cuda', index=0), 'ndomains': 2, 'output_path': './results/office31_ssda/webcam_to_amazon_SSDA_1_baseline', 'output_name': 'baseline', 'source_iters': 0, 'adapt_iters': 1000, 'test_interval': 100, 'seed': 1, 'warmup': True, 'pretrained_models': './pretrained/', 'lamda': 0.1, 'save_models': True, 'thresh_ViT': 0.6, 'thresh_CNN': 0.9, 'dataset': {'method': 'SSDA', 'data_root': '../Dataset/office31', 'data_label': './dataset/office31_ssda', 'num_workers': 8, 'target_shot': 1, 'use_cgct_mask': True, 'source': {'name': 'webcam', 'batch_size': 26}, 'target': {'name': 'amazon', 'batch_size': 26}, 'prep': {'source_w': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x79b182394b80>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'source_str': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x79b176a928b0>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    <utils.preprocess.RandAugmentMC object at 0x79b176a92640>\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'target_w': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x79b176a928e0>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'target_str': Compose(\n",
            "    <utils.randaugment.RandAugment object at 0x79b176a92970>\n",
            "    <utils.preprocess.ResizeImage object at 0x79b176a92c40>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'test': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x79b176a92c70>\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'val': Compose(\n",
            "    <utils.preprocess.ResizeImage object at 0x79b176a92f40>\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")}, 'name': 'office31_ssda'}, 'optimizer': {'lr': 1.0, 'lr_vit': 0.001, 'lr_cnn': 0.01, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}, 'Architecture': {'Backbone': {'name_1': 'vit', 'pretrained_1': './pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/the_best_G1_pretrained.pth.tar', 'name_2': 'alexnet', 'pretrained_2': './pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/the_best_G2_pretrained.pth.tar'}, 'Classifier': {'name_1': 'MLP', 'pretrained_F1': './pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/the_best_F1_pretrained.pth.tar', 'name_2': 'MLP', 'pretrained_F2': './pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/the_best_F2_pretrained.pth.tar'}, 'class_num': 31}, 'mixup_thresh': 0.7, 'alpha': 0.9, 'percentile': 60, 'lambda': 0.5, 'num_classes': 31, 'sat_alpha': 0.9, 'warmup_iters': 400, 'output_path_warmup': './pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup', 'out_file_warmup': <_io.TextIOWrapper name='./pretrained/office31_ssda/webcam_to_amazon_SSDA_1_pretrained_warmup/log.txt' mode='w' encoding='UTF-8'>, 'out_file': <_io.TextIOWrapper name='./results/office31_ssda/webcam_to_amazon_SSDA_1_baseline/log.txt' mode='w' encoding='UTF-8'>}\n",
            "\u001b[31m==> Starting the adaptation\u001b[0m\n",
            "\u001b[31mMethod: SSDA - File: trainer.py\u001b[0m\n",
            "[Step 0] CNN thresholds: [0.8999999761581421, 0.8999999761581421, 0.9185446500778198, 0.9160698652267456, 0.8288860321044922, 0.9160882830619812, 0.9183399677276611, 0.8999999761581421, 0.8999999761581421, 0.8999999761581421, 0.868892252445221, 0.8999999761581421, 0.907814621925354, 0.8999999761581421, 0.8592780828475952, 0.8623371720314026, 0.8850606083869934, 0.8999999761581421, 0.8999999761581421, 0.8950187563896179, 0.9086470007896423, 0.8912231922149658, 0.8841367959976196, 0.8152652978897095, 0.8999999761581421, 0.9170583486557007, 0.8999999761581421, 0.8962663412094116, 0.8951038718223572, 0.8960469365119934, 0.8999999761581421]\n",
            "\n",
            "[Step 0] ViT thresholds: [0.6000000238418579, 0.6000000238418579, 0.6759107112884521, 0.6759470701217651, 0.5478886365890503, 0.6759229302406311, 0.675930380821228, 0.6586228013038635, 0.6000000238418579, 0.6000000238418579, 0.6758036613464355, 0.6000000238418579, 0.6757391095161438, 0.6300833821296692, 0.6000000238418579, 0.6759455800056458, 0.6751275658607483, 0.6721165180206299, 0.6000000238418579, 0.6000000238418579, 0.6759194135665894, 0.6757364273071289, 0.6759282350540161, 0.6302544474601746, 0.6000000238418579, 0.6758430600166321, 0.6000000238418579, 0.6754115223884583, 0.5916978716850281, 0.6373408436775208, 0.6000000238418579]\n",
            "\n",
            "Iters: (0/1000) \t lr_g1 = 0.000100   lr_g2 = 0.001000   CNN's loss = 0.001567   ViT's Loss = 0.001024   \n",
            "Iters: (20/1000) \t lr_g1 = 0.000100   lr_g2 = 0.000999   CNN's loss = 0.129650   ViT's Loss = 0.000714   \n",
            "Iters: (40/1000) \t lr_g1 = 0.000100   lr_g2 = 0.000997   CNN's loss = 0.241810   ViT's Loss = 0.000759   \n",
            "Iters: (60/1000) \t lr_g1 = 0.000100   lr_g2 = 0.000996   CNN's loss = 0.180952   ViT's Loss = 0.000780   \n",
            "Iters: (80/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000994   CNN's loss = 0.146867   ViT's Loss = 0.000906   \n",
            "100%|█████████████████████████████████████████| 108/108 [00:19<00:00,  5.50it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.86it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 72.0430%  ViT's Accuracy Target Val =  83.8710% \n",
            "\t-- CNN's Accuracy Target Test = 66.9777%  ViT's Accuracy Target Test = 79.1457% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/office31_ssda/webcam_to_amazon_SSDA_1_baseline\n",
            "  -- Saved ViT Branch (G1 + F1) at ./results/office31_ssda/webcam_to_amazon_SSDA_1_baseline\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 72.0430% The best Vit's Acc Target Val = 83.8710% \n",
            "\t-- The best CNN's Acc Target Test = 66.9777% The best ViT's Acc Target Test = 79.1457% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8296 Correct_Pseudo_Labels_CNN = 1563 Total_Pseudo_Labels_CNN = 1884       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.9133 Correct_Pseudo_Labels_ViT = 1897 Total_Pseudo_Labels_ViT = 2077       \n",
            "\u001b[0m\n",
            "[Step 100] CNN thresholds: [0.9043386578559875, 0.9849628210067749, 0.8974297642707825, 0.7549951076507568, 0.6867537498474121, 0.8114991188049316, 0.9353318214416504, 0.6508418321609497, 0.6477073431015015, 0.8431692123413086, 0.8305425047874451, 0.9647970795631409, 0.9286842942237854, 0.7516055703163147, 0.8509042263031006, 0.8716583251953125, 0.8903514742851257, 0.8153378963470459, 0.6350359916687012, 0.7192223072052002, 0.8464081883430481, 0.8350098729133606, 0.783240556716919, 0.6969060301780701, 0.6510598063468933, 0.7315725088119507, 0.679658830165863, 0.7697370648384094, 0.7581056952476501, 0.8186381459236145, 0.5579323172569275]\n",
            "\n",
            "[Step 100] ViT thresholds: [0.9957985877990723, 0.994928240776062, 0.9925245046615601, 0.9769220948219299, 0.7035681009292603, 0.9223705530166626, 0.9752484560012817, 0.7824658155441284, 0.8242741227149963, 0.9873896837234497, 0.9493649005889893, 0.9748332500457764, 0.9768236875534058, 0.7636149525642395, 0.9773273468017578, 0.929189145565033, 0.9739819765090942, 0.9247962236404419, 0.8516397476196289, 0.8913450241088867, 0.9621275067329407, 0.9270433187484741, 0.8880773782730103, 0.6759575009346008, 0.8350685834884644, 0.9816636443138123, 0.9302970170974731, 0.9519407749176025, 0.7847378849983215, 0.7135961651802063, 0.7354773283004761]\n",
            "\n",
            "Iters: (100/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000993   CNN's loss = 0.208150   ViT's Loss = 0.001630   \n",
            "Iters: (120/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000991   CNN's loss = 0.065328   ViT's Loss = 0.001573   \n",
            "Iters: (140/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000990   CNN's loss = 0.239611   ViT's Loss = 0.005706   \n",
            "Iters: (160/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000988   CNN's loss = 0.030931   ViT's Loss = 0.003099   \n",
            "Iters: (180/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000987   CNN's loss = 0.036275   ViT's Loss = 0.002515   \n",
            "100%|█████████████████████████████████████████| 108/108 [00:18<00:00,  5.85it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.97it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 69.8925%  ViT's Accuracy Target Val =  81.7204% \n",
            "\t-- CNN's Accuracy Target Test = 68.7006%  ViT's Accuracy Target Test = 76.8126% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/office31_ssda/webcam_to_amazon_SSDA_1_baseline\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 72.0430% The best Vit's Acc Target Val = 83.8710% \n",
            "\t-- The best CNN's Acc Target Test = 68.7006% The best ViT's Acc Target Test = 79.1457% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8111 Correct_Pseudo_Labels_CNN = 1640 Total_Pseudo_Labels_CNN = 2022       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.8688 Correct_Pseudo_Labels_ViT = 1775 Total_Pseudo_Labels_ViT = 2043       \n",
            "\u001b[0m\n",
            "[Step 200] CNN thresholds: [0.9171829223632812, 0.9910127520561218, 0.9042484760284424, 0.863765299320221, 0.7000624537467957, 0.8470068573951721, 0.9594587683677673, 0.869671106338501, 0.7678605318069458, 0.741243839263916, 0.9303122162818909, 0.9622378945350647, 0.8700401186943054, 0.8013449907302856, 0.8685070872306824, 0.9158517122268677, 0.9118661284446716, 0.8579182624816895, 0.7950382232666016, 0.8241026401519775, 0.8793098330497742, 0.9062122106552124, 0.8611728549003601, 0.6404411792755127, 0.7569402456283569, 0.7669113278388977, 0.7824054956436157, 0.8484537601470947, 0.7559385895729065, 0.7549909949302673, 0.7146893739700317]\n",
            "\n",
            "[Step 200] ViT thresholds: [0.9390040636062622, 0.9970230460166931, 0.9658424854278564, 0.9763897061347961, 0.7603073120117188, 0.7568984627723694, 0.9962584376335144, 0.9029444456100464, 0.7221937775611877, 0.8285272717475891, 0.965785026550293, 0.9488198161125183, 0.9618352651596069, 0.9402777552604675, 0.9698235988616943, 0.8952957391738892, 0.8456267714500427, 0.863390326499939, 0.7932961583137512, 0.951572835445404, 0.9706000089645386, 0.9867472052574158, 0.8930378556251526, 0.5638669729232788, 0.8386743068695068, 0.8986667990684509, 0.8870557546615601, 0.8224911093711853, 0.5897501707077026, 0.7856742739677429, 0.8014028668403625]\n",
            "\n",
            "Iters: (200/1000) \t lr_g1 = 0.000099   lr_g2 = 0.000985   CNN's loss = 0.112401   ViT's Loss = 0.003358   \n",
            "Iters: (220/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000984   CNN's loss = 0.035078   ViT's Loss = 0.005533   \n",
            "Iters: (240/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000982   CNN's loss = 0.042648   ViT's Loss = 0.004026   \n",
            "Iters: (260/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000981   CNN's loss = 0.051487   ViT's Loss = 0.002712   \n",
            "Iters: (280/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000980   CNN's loss = 0.024692   ViT's Loss = 0.005006   \n",
            "100%|█████████████████████████████████████████| 108/108 [00:18<00:00,  5.75it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.94it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 67.7419%  ViT's Accuracy Target Val =  76.3441% \n",
            "\t-- CNN's Accuracy Target Test = 68.0546%  ViT's Accuracy Target Test = 76.4178% \n",
            "\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 72.0430% The best Vit's Acc Target Val = 83.8710% \n",
            "\t-- The best CNN's Acc Target Test = 68.7006% The best ViT's Acc Target Test = 79.1457% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.7952 Correct_Pseudo_Labels_CNN = 1635 Total_Pseudo_Labels_CNN = 2056       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.8512 Correct_Pseudo_Labels_ViT = 1819 Total_Pseudo_Labels_ViT = 2137       \n",
            "\u001b[0m\n",
            "[Step 300] CNN thresholds: [0.8909289836883545, 0.9763652682304382, 0.9636460542678833, 0.8775483965873718, 0.7964842319488525, 0.8547145128250122, 0.9855842590332031, 0.9402906894683838, 0.7016829252243042, 0.7842568159103394, 0.9588860273361206, 0.9144786596298218, 0.8510263562202454, 0.8157512545585632, 0.9265598654747009, 0.8604164123535156, 0.8364604115486145, 0.8692610859870911, 0.8086658120155334, 0.9054985046386719, 0.8040002584457397, 0.9039834141731262, 0.912032425403595, 0.7307999134063721, 0.707097053527832, 0.7532638907432556, 0.8988329172134399, 0.8548970222473145, 0.7656972408294678, 0.7328981161117554, 0.7945474982261658]\n",
            "\n",
            "[Step 300] ViT thresholds: [0.9728057384490967, 0.9462461471557617, 0.990119993686676, 0.9756922721862793, 0.6252780556678772, 0.8249396085739136, 0.9834591150283813, 0.8942368030548096, 0.9792028665542603, 0.9448434114456177, 0.98398357629776, 0.9908512830734253, 0.9663940668106079, 0.7537319660186768, 0.9471989870071411, 0.9661887884140015, 0.8398785591125488, 0.960904061794281, 0.8446833491325378, 0.8834397196769714, 0.9340752363204956, 0.9765416979789734, 0.8500673770904541, 0.6887713670730591, 0.7840244174003601, 0.7890706658363342, 0.9331542253494263, 0.9171111583709717, 0.7207306623458862, 0.7596688866615295, 0.7809140086174011]\n",
            "\n",
            "Iters: (300/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000978   CNN's loss = 0.040646   ViT's Loss = 0.003358   \n",
            "Iters: (320/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000977   CNN's loss = 0.046112   ViT's Loss = 0.001728   \n",
            "Iters: (340/1000) \t lr_g1 = 0.000098   lr_g2 = 0.000975   CNN's loss = 0.033083   ViT's Loss = 0.011461   \n",
            "Iters: (360/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000974   CNN's loss = 0.032846   ViT's Loss = 0.003902   \n",
            "Iters: (380/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000972   CNN's loss = 0.040855   ViT's Loss = 0.006695   \n",
            "100%|█████████████████████████████████████████| 108/108 [00:18<00:00,  5.71it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.83it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 77.4194%  ViT's Accuracy Target Val =  78.4946% \n",
            "\t-- CNN's Accuracy Target Test = 69.6339%  ViT's Accuracy Target Test = 76.6332% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/office31_ssda/webcam_to_amazon_SSDA_1_baseline\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 77.4194% The best Vit's Acc Target Val = 83.8710% \n",
            "\t-- The best CNN's Acc Target Test = 69.6339% The best ViT's Acc Target Test = 79.1457% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8050 Correct_Pseudo_Labels_CNN = 1651 Total_Pseudo_Labels_CNN = 2051       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.8653 Correct_Pseudo_Labels_ViT = 1838 Total_Pseudo_Labels_ViT = 2124       \n",
            "\u001b[0m\n",
            "[Step 400] CNN thresholds: [0.930682361125946, 0.9980282187461853, 0.9448487758636475, 0.9252188801765442, 0.7436771988868713, 0.8625634908676147, 0.9803118109703064, 0.8733893036842346, 0.8368544578552246, 0.8750237822532654, 0.9574917554855347, 0.957399308681488, 0.8965933918952942, 0.8640042543411255, 0.9073007702827454, 0.9083788990974426, 0.8945344090461731, 0.8432510495185852, 0.7791908979415894, 0.8686788082122803, 0.8174642324447632, 0.8670615553855896, 0.8927412033081055, 0.6462482213973999, 0.8522564768791199, 0.8962264657020569, 0.8250701427459717, 0.7523620128631592, 0.8650558590888977, 0.8060183525085449, 0.7422552704811096]\n",
            "\n",
            "[Step 400] ViT thresholds: [0.9044303894042969, 0.9819678068161011, 0.953040599822998, 0.9873713254928589, 0.793391227722168, 0.958692193031311, 0.9968741536140442, 0.9270833134651184, 0.9684750437736511, 0.9162051677703857, 0.9750563502311707, 0.9323103427886963, 0.9099932909011841, 0.9193989634513855, 0.9649752974510193, 0.9774860143661499, 0.9568597674369812, 0.9924412965774536, 0.9624149203300476, 0.8855372071266174, 0.9609998464584351, 0.9430744647979736, 0.9500254392623901, 0.6263825297355652, 0.9381352663040161, 0.9430957436561584, 0.910021960735321, 0.7908645272254944, 0.8448686003684998, 0.8432312607765198, 0.8260623812675476]\n",
            "\n",
            "Iters: (400/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000971   CNN's loss = 0.082177   ViT's Loss = 0.003642   \n",
            "Iters: (420/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000970   CNN's loss = 0.048484   ViT's Loss = 0.007434   \n",
            "Iters: (440/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000968   CNN's loss = 0.044567   ViT's Loss = 0.009726   \n",
            "Iters: (460/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000967   CNN's loss = 0.099210   ViT's Loss = 0.008054   \n",
            "Iters: (480/1000) \t lr_g1 = 0.000097   lr_g2 = 0.000965   CNN's loss = 0.029843   ViT's Loss = 0.008789   \n",
            "100%|█████████████████████████████████████████| 108/108 [00:18<00:00,  5.83it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.88it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 70.9677%  ViT's Accuracy Target Val =  78.4946% \n",
            "\t-- CNN's Accuracy Target Test = 69.9928%  ViT's Accuracy Target Test = 76.2024% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/office31_ssda/webcam_to_amazon_SSDA_1_baseline\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 77.4194% The best Vit's Acc Target Val = 83.8710% \n",
            "\t-- The best CNN's Acc Target Test = 69.9928% The best ViT's Acc Target Test = 79.1457% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8042 Correct_Pseudo_Labels_CNN = 1680 Total_Pseudo_Labels_CNN = 2089       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.8497 Correct_Pseudo_Labels_ViT = 1849 Total_Pseudo_Labels_ViT = 2176       \n",
            "\u001b[0m\n",
            "[Step 500] CNN thresholds: [0.9161790609359741, 0.9965602159500122, 0.9043615460395813, 0.8576160073280334, 0.8138138055801392, 0.8604515790939331, 0.9639292359352112, 0.8591539263725281, 0.803765594959259, 0.8398993611335754, 0.9154348373413086, 0.9807100892066956, 0.8566146492958069, 0.8666853308677673, 0.9695920944213867, 0.9211698174476624, 0.8551232814788818, 0.8966668248176575, 0.733250617980957, 0.8945350050926208, 0.9507853388786316, 0.898511528968811, 0.8598302602767944, 0.8099746108055115, 0.666479229927063, 0.9027557373046875, 0.9452618956565857, 0.9034358859062195, 0.7899136543273926, 0.8566465377807617, 0.6846232414245605]\n",
            "\n",
            "[Step 500] ViT thresholds: [0.989833652973175, 0.9980461597442627, 0.8983287215232849, 0.9865372776985168, 0.8814051747322083, 0.9836130142211914, 0.9728203415870667, 0.9206764101982117, 0.8548263907432556, 0.9604933261871338, 0.9614462852478027, 0.9928252100944519, 0.9558287262916565, 0.9212938547134399, 0.983881413936615, 0.9437075257301331, 0.9527370929718018, 0.9003424644470215, 0.8930397033691406, 0.8322669267654419, 0.9000369906425476, 0.9387052655220032, 0.838108241558075, 0.7985404133796692, 0.6950134038925171, 0.8980871438980103, 0.9342279434204102, 0.9661353826522827, 0.7821105718612671, 0.8073434829711914, 0.8477920293807983]\n",
            "\n",
            "Iters: (500/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000964   CNN's loss = 0.072446   ViT's Loss = 0.004052   \n",
            "Iters: (520/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000963   CNN's loss = 0.026645   ViT's Loss = 0.010309   \n",
            "Iters: (540/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000961   CNN's loss = 0.053680   ViT's Loss = 0.015187   \n",
            "Iters: (560/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000960   CNN's loss = 0.042930   ViT's Loss = 0.003176   \n",
            "Iters: (580/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000959   CNN's loss = 0.010064   ViT's Loss = 0.012393   \n",
            "100%|█████████████████████████████████████████| 108/108 [00:18<00:00,  5.81it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.83it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 73.1183%  ViT's Accuracy Target Val =  77.4194% \n",
            "\t-- CNN's Accuracy Target Test = 70.7107%  ViT's Accuracy Target Test = 74.2642% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/office31_ssda/webcam_to_amazon_SSDA_1_baseline\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 77.4194% The best Vit's Acc Target Val = 83.8710% \n",
            "\t-- The best CNN's Acc Target Test = 70.7107% The best ViT's Acc Target Test = 79.1457% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8057 Correct_Pseudo_Labels_CNN = 1767 Total_Pseudo_Labels_CNN = 2193       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.8268 Correct_Pseudo_Labels_ViT = 1847 Total_Pseudo_Labels_ViT = 2234       \n",
            "\u001b[0m\n",
            "[Step 600] CNN thresholds: [0.9720297455787659, 0.9933744072914124, 0.9818999171257019, 0.859107494354248, 0.7975524663925171, 0.8951065540313721, 0.938400387763977, 0.7967997789382935, 0.850636899471283, 0.7887849807739258, 0.8276041746139526, 0.9896112680435181, 0.9096737504005432, 0.9045929312705994, 0.8586980700492859, 0.8697669506072998, 0.903428852558136, 0.9094560742378235, 0.6859208941459656, 0.8798542022705078, 0.8598377108573914, 0.9071376323699951, 0.9079103469848633, 0.780684769153595, 0.7108271718025208, 0.7492279410362244, 0.8419342041015625, 0.8946796655654907, 0.8037713766098022, 0.7990626692771912, 0.802836537361145]\n",
            "\n",
            "[Step 600] ViT thresholds: [0.9966601133346558, 0.9879614114761353, 0.9116119742393494, 0.9679974317550659, 0.8297701478004456, 0.9888989329338074, 0.9237400889396667, 0.8706445693969727, 0.9405699372291565, 0.8807468414306641, 0.9419705271720886, 0.9658044576644897, 0.9871824383735657, 0.9229530096054077, 0.9040324687957764, 0.9702577590942383, 0.941688597202301, 0.9174344539642334, 0.9233801960945129, 0.9252505898475647, 0.9773786067962646, 0.9795345067977905, 0.9433403015136719, 0.7561447620391846, 0.7297506928443909, 0.8803719282150269, 0.9302215576171875, 0.9257858395576477, 0.8482880592346191, 0.8552439212799072, 0.7716668844223022]\n",
            "\n",
            "Iters: (600/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000957   CNN's loss = 0.058809   ViT's Loss = 0.004791   \n",
            "Iters: (620/1000) \t lr_g1 = 0.000096   lr_g2 = 0.000956   CNN's loss = 0.022027   ViT's Loss = 0.002486   \n",
            "Iters: (640/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000955   CNN's loss = 0.007378   ViT's Loss = 0.003324   \n",
            "Iters: (660/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000953   CNN's loss = 0.012588   ViT's Loss = 0.002232   \n",
            "Iters: (680/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000952   CNN's loss = 0.022011   ViT's Loss = 0.001886   \n",
            "100%|█████████████████████████████████████████| 108/108 [00:18<00:00,  5.81it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.90it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 72.0430%  ViT's Accuracy Target Val =  76.3441% \n",
            "\t-- CNN's Accuracy Target Test = 70.3877%  ViT's Accuracy Target Test = 74.1565% \n",
            "\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 77.4194% The best Vit's Acc Target Val = 83.8710% \n",
            "\t-- The best CNN's Acc Target Test = 70.7107% The best ViT's Acc Target Test = 79.1457% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.7996 Correct_Pseudo_Labels_CNN = 1716 Total_Pseudo_Labels_CNN = 2146       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.8249 Correct_Pseudo_Labels_ViT = 1865 Total_Pseudo_Labels_ViT = 2261       \n",
            "\u001b[0m\n",
            "[Step 700] CNN thresholds: [0.9496180415153503, 0.9769842028617859, 0.9639226198196411, 0.8252115845680237, 0.8587258458137512, 0.9226664304733276, 0.9780893921852112, 0.9161471724510193, 0.7344754934310913, 0.7640631198883057, 0.9171279072761536, 0.9397351145744324, 0.854171633720398, 0.8543826937675476, 0.8532515168190002, 0.9351279735565186, 0.8514973521232605, 0.9463133811950684, 0.8152222633361816, 0.9148496985435486, 0.9018113613128662, 0.8844127058982849, 0.9173744916915894, 0.8093248009681702, 0.8719409108161926, 0.9524927139282227, 0.9015467762947083, 0.856935441493988, 0.8844555616378784, 0.8651266694068909, 0.9010217189788818]\n",
            "\n",
            "[Step 700] ViT thresholds: [0.8588901162147522, 0.9978232383728027, 0.9894182085990906, 0.9363834261894226, 0.8457804918289185, 0.8403570652008057, 0.9833416938781738, 0.9531875848770142, 0.7186713218688965, 0.839458703994751, 0.8385292887687683, 0.9950270056724548, 0.9456941485404968, 0.9484989643096924, 0.9187978506088257, 0.9855512976646423, 0.8741120100021362, 0.9602576494216919, 0.838822603225708, 0.9786412119865417, 0.8998630046844482, 0.9332375526428223, 0.9066867828369141, 0.668138325214386, 0.7957677841186523, 0.9748318195343018, 0.9509449005126953, 0.9680575132369995, 0.8637303709983826, 0.9135702848434448, 0.9704146981239319]\n",
            "\n",
            "Iters: (700/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000951   CNN's loss = 0.061930   ViT's Loss = 0.003106   \n",
            "Iters: (720/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000949   CNN's loss = 0.015940   ViT's Loss = 0.002945   \n",
            "Iters: (740/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000948   CNN's loss = 0.007025   ViT's Loss = 0.002357   \n",
            "Iters: (760/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000947   CNN's loss = 0.095080   ViT's Loss = 0.020958   \n",
            "Iters: (780/1000) \t lr_g1 = 0.000095   lr_g2 = 0.000945   CNN's loss = 0.015995   ViT's Loss = 0.002700   \n",
            "100%|█████████████████████████████████████████| 108/108 [00:18<00:00,  5.74it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.81it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 74.1935%  ViT's Accuracy Target Val =  74.1935% \n",
            "\t-- CNN's Accuracy Target Test = 71.2132%  ViT's Accuracy Target Test = 74.0129% \n",
            "\n",
            "  -- Saved CNN Branch (G2 + F2) at ./results/office31_ssda/webcam_to_amazon_SSDA_1_baseline\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 77.4194% The best Vit's Acc Target Val = 83.8710% \n",
            "\t-- The best CNN's Acc Target Test = 71.2132% The best ViT's Acc Target Test = 79.1457% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8005 Correct_Pseudo_Labels_CNN = 1766 Total_Pseudo_Labels_CNN = 2206       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.8098 Correct_Pseudo_Labels_ViT = 1818 Total_Pseudo_Labels_ViT = 2245       \n",
            "\u001b[0m\n",
            "[Step 800] CNN thresholds: [0.9084140062332153, 0.9968313574790955, 0.9667592644691467, 0.8795303702354431, 0.863296627998352, 0.8971914052963257, 0.9807116985321045, 0.7498434782028198, 0.8584164977073669, 0.7882739305496216, 0.9684498310089111, 0.9921212196350098, 0.9009224772453308, 0.8695014119148254, 0.953177273273468, 0.9700380563735962, 0.910262405872345, 0.9331342577934265, 0.7394630908966064, 0.8756319284439087, 0.9781125783920288, 0.9376649856567383, 0.8243563175201416, 0.7762677669525146, 0.8047568202018738, 0.9131463766098022, 0.8912320137023926, 0.8094472289085388, 0.8695308566093445, 0.8945932984352112, 0.7758828401565552]\n",
            "\n",
            "[Step 800] ViT thresholds: [0.9437274932861328, 0.9989451766014099, 0.9686212539672852, 0.9911433458328247, 0.9052428603172302, 0.9185975193977356, 0.9961341023445129, 0.9728339314460754, 0.9473183751106262, 0.9436842799186707, 0.9921262264251709, 0.9075447916984558, 0.9781403541564941, 0.9095532298088074, 0.906954824924469, 0.9897924661636353, 0.9456540942192078, 0.9793746471405029, 0.817237377166748, 0.9623288512229919, 0.9649487733840942, 0.9875237345695496, 0.9761894941329956, 0.7724835276603699, 0.863309919834137, 0.9722996354103088, 0.8106756806373596, 0.9464974999427795, 0.8907283544540405, 0.889966607093811, 0.7820427417755127]\n",
            "\n",
            "Iters: (800/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000944   CNN's loss = 0.016235   ViT's Loss = 0.002666   \n",
            "Iters: (820/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000943   CNN's loss = 0.023272   ViT's Loss = 0.001416   \n",
            "Iters: (840/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000941   CNN's loss = 0.008037   ViT's Loss = 0.005368   \n",
            "Iters: (860/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000940   CNN's loss = 0.024932   ViT's Loss = 0.002424   \n",
            "Iters: (880/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000939   CNN's loss = 0.008370   ViT's Loss = 0.003687   \n",
            "100%|█████████████████████████████████████████| 108/108 [00:18<00:00,  5.81it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.71it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 72.0430%  ViT's Accuracy Target Val =  77.4194% \n",
            "\t-- CNN's Accuracy Target Test = 71.0696%  ViT's Accuracy Target Test = 75.3769% \n",
            "\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 77.4194% The best Vit's Acc Target Val = 83.8710% \n",
            "\t-- The best CNN's Acc Target Test = 71.2132% The best ViT's Acc Target Test = 79.1457% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.8105 Correct_Pseudo_Labels_CNN = 1724 Total_Pseudo_Labels_CNN = 2127       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.8494 Correct_Pseudo_Labels_ViT = 1828 Total_Pseudo_Labels_ViT = 2152       \n",
            "\u001b[0m\n",
            "[Step 900] CNN thresholds: [0.8723060488700867, 0.9997149705886841, 0.8782064914703369, 0.8354968428611755, 0.8782138228416443, 0.9414926767349243, 0.9853730201721191, 0.968992292881012, 0.8890398740768433, 0.9060454368591309, 0.9342422485351562, 0.9842008948326111, 0.9574018716812134, 0.9192236661911011, 0.9769254326820374, 0.9702397584915161, 0.8526021242141724, 0.8310927748680115, 0.84126216173172, 0.906212329864502, 0.853493332862854, 0.9648382663726807, 0.9772812128067017, 0.7286019921302795, 0.7384129762649536, 0.9361608624458313, 0.8905618786811829, 0.9246626496315002, 0.846447229385376, 0.922035813331604, 0.8363201022148132]\n",
            "\n",
            "[Step 900] ViT thresholds: [0.9103277325630188, 0.9983179569244385, 0.9602699875831604, 0.9687589406967163, 0.8173097968101501, 0.9318705797195435, 0.9959215521812439, 0.9477791786193848, 0.9117363691329956, 0.9225482940673828, 0.9402069449424744, 0.9946711659431458, 0.989504873752594, 0.9600719213485718, 0.9956828355789185, 0.9951841235160828, 0.9515129923820496, 0.9920933246612549, 0.9391847252845764, 0.9557943344116211, 0.9214490056037903, 0.983517587184906, 0.9827964305877686, 0.9152899384498596, 0.828829824924469, 0.9784190654754639, 0.938891589641571, 0.8342812657356262, 0.9002055525779724, 0.9120107293128967, 0.959954023361206]\n",
            "\n",
            "Iters: (900/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000937   CNN's loss = 0.063161   ViT's Loss = 0.004650   \n",
            "Iters: (920/1000) \t lr_g1 = 0.000094   lr_g2 = 0.000936   CNN's loss = 0.046909   ViT's Loss = 0.002451   \n",
            "Iters: (940/1000) \t lr_g1 = 0.000093   lr_g2 = 0.000935   CNN's loss = 0.098105   ViT's Loss = 0.004105   \n",
            "Iters: (960/1000) \t lr_g1 = 0.000093   lr_g2 = 0.000934   CNN's loss = 0.052223   ViT's Loss = 0.004113   \n",
            "Iters: (980/1000) \t lr_g1 = 0.000093   lr_g2 = 0.000932   CNN's loss = 0.022073   ViT's Loss = 0.003314   \n",
            "Iters: (999/1000) \t lr_g1 = 0.000093   lr_g2 = 0.000931   CNN's loss = 0.032454   ViT's Loss = 0.002006   \n",
            "100%|█████████████████████████████████████████| 108/108 [00:18<00:00,  5.78it/s]\n",
            "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.85it/s]\n",
            "  -- Domain task [webcam --> amazon] \n",
            "\t-- CNN's Accuracy Target Val  = 74.1935%  ViT's Accuracy Target Val =  76.3441% \n",
            "\t-- CNN's Accuracy Target Test = 69.8851%  ViT's Accuracy Target Test = 73.0079% \n",
            "\n",
            "\u001b[31m  -- Domain task [webcam --> amazon]: \n",
            "\t-- The best CNN's Acc Target Val = 77.4194% The best Vit's Acc Target Val = 83.8710% \n",
            "\t-- The best CNN's Acc Target Test = 71.2132% The best ViT's Acc Target Test = 79.1457% \n",
            "\t-- Acc_Pseudo_Labels_CNN = 0.7779 Correct_Pseudo_Labels_CNN = 1776 Total_Pseudo_Labels_CNN = 2283       \n",
            "\t-- Acc_Pseudo_Labels_ViT = 0.8085 Correct_Pseudo_Labels_ViT = 1815 Total_Pseudo_Labels_ViT = 2245       \n",
            "\u001b[0m\n",
            "\u001b[31mFinished training and evaluation!\u001b[0m\n"
          ]
        }
      ],
      "execution_count": null
    }
  ]
}